{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Classification using PyTorch - Flowers.ipynb","provenance":[{"file_id":"1EIy8e8EBu-vPjW2tBSLEv9AD3X9Ig1Lk","timestamp":1611363016297}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0891545a4f3345f1a8f4367e887719b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_987a538a31e74c40829633a427389bb5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_57dd1fc335f546e68e03b0288c719319","IPY_MODEL_ef67ce0f5d5d4fc6b11b5bf49402be9a"]}},"987a538a31e74c40829633a427389bb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57dd1fc335f546e68e03b0288c719319":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b311ea77d6774bf3b7d2a4d69d901fc6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd100c9e73904872b41a252ab55bc7b6"}},"ef67ce0f5d5d4fc6b11b5bf49402be9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5543d20a9c2545e982b3f19f8b1ac1ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [00:05&lt;00:00, 94.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cc8760b1c8d4a0897f3fa2ed27c8c35"}},"b311ea77d6774bf3b7d2a4d69d901fc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd100c9e73904872b41a252ab55bc7b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5543d20a9c2545e982b3f19f8b1ac1ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cc8760b1c8d4a0897f3fa2ed27c8c35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"NCY-UjRqITj_"},"source":["## Image Classification using PyTorch\n","Multi-class image classification using transfer learning and hyperparameter optimization for model creation. PyTorch will be used as the deep learning development framework."]},{"cell_type":"code","metadata":{"id":"48Q362WrIxZG"},"source":["# Import libraries\n","import os\n","import time\n","import random\n","import numpy as np\n","from numpy import argmax\n","import pandas as pd\n","import json\n","from collections import OrderedDict, namedtuple\n","from itertools import product\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","import torchvision\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import warnings\n","warnings.filterwarnings('ignore', category=FutureWarning)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoE-mgX1KKfI","executionInfo":{"status":"ok","timestamp":1619260003940,"user_tz":-60,"elapsed":5307,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"365c7d52-7fea-4078-bd17-8fc10701d270"},"source":["# Enable GPU processing\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Device type: {device}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Device type: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZEzNquOLEXO","executionInfo":{"status":"ok","timestamp":1619260132359,"user_tz":-60,"elapsed":133712,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"59fea2a3-20aa-42dd-b415-eb1bf3394dc3"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhavJx5NLU2I","executionInfo":{"status":"ok","timestamp":1619260132362,"user_tz":-60,"elapsed":133710,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"12b5fddd-c1a5-4cc5-cc79-91e27f1c601a"},"source":["# Set random seed\n","seed = 777\n","torch.manual_seed(seed)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f9a6f103970>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"xBVdrUWAL-7G"},"source":["# Define data directory parameters\n","# datadir = '/drive/My Drive/Data/flowers/'\n","datadir = '/drive/My Drive/Colab Notebooks/Datasets/Kaggle/flowers_split/'\n","traindir = datadir + 'train/'\n","validdir = datadir + 'valid/'\n","testdir = datadir + 'test/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mf5YQE6N6qAd","executionInfo":{"status":"ok","timestamp":1619260145390,"user_tz":-60,"elapsed":146728,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"fa8b1152-4e0e-4257-bad1-da698c6e2597"},"source":["# Confirm image class distribution\n","\n","# Empty lists\n","classes = []\n","n_train = []\n","n_valid = []\n","n_test = []\n","\n","# Iterate through each category\n","for d in os.listdir(traindir):\n","    classes.append(d)\n","\n","    # Number of each image\n","    train_imgs = os.listdir(traindir + d)\n","    valid_imgs = os.listdir(validdir + d)\n","    test_imgs = os.listdir(testdir + d)\n","    n_train.append(len(train_imgs))\n","    n_valid.append(len(valid_imgs))\n","    n_test.append(len(test_imgs))\n","\n","print(f'Classes: {classes}')\n","print(f'Training images per class: {n_train}')\n","print(f'Validation images per class: {n_valid}')\n","print(f'Test images per class: {n_test}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classes: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n","Training images per class: [420, 420, 420, 420, 420]\n","Validation images per class: [59, 59, 59, 59, 59]\n","Test images per class: [119, 119, 119, 119, 119]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ElTenber0l7h"},"source":["### Image Augmentation / Transforms"]},{"cell_type":"code","metadata":{"id":"gALNqRZP85D0"},"source":["# Define an image transformations dictionary\n","image_transforms = {\n","    # Training set uses data augmentation\n","    'train':\n","    transforms.Compose([                        \n","        transforms.Resize(size=256),\n","        transforms.RandomAffine(degrees=(0,30)),\n","        transforms.RandomHorizontalFlip(), \n","        transforms.CenterCrop(size=224),       \n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Imagenet standards\n","    ]),\n","    # No image augmentation for the validation and test sets\n","    'val':\n","    transforms.Compose([\n","        transforms.Resize(size=256),\n","        transforms.CenterCrop(size=224),  \n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test':\n","    transforms.Compose([\n","        transforms.Resize(size=256),\n","        transforms.CenterCrop(size=224),  \n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKDVinr73Mcd"},"source":["# Load the data from each folder\n","data = {\n","    'train':\n","    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n","    'val':\n","    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n","    'test':\n","    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbCAfupy1X-G"},"source":["### Create CNN Model"]},{"cell_type":"code","metadata":{"id":"rTTH8Sg35qLo","colab":{"base_uri":"https://localhost:8080/","height":912,"referenced_widgets":["0891545a4f3345f1a8f4367e887719b9","987a538a31e74c40829633a427389bb5","57dd1fc335f546e68e03b0288c719319","ef67ce0f5d5d4fc6b11b5bf49402be9a","b311ea77d6774bf3b7d2a4d69d901fc6","bd100c9e73904872b41a252ab55bc7b6","5543d20a9c2545e982b3f19f8b1ac1ad","0cc8760b1c8d4a0897f3fa2ed27c8c35"]},"executionInfo":{"status":"ok","timestamp":1619260150559,"user_tz":-60,"elapsed":151887,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"228ba112-428e-4469-9e8a-3f160e7a3a34"},"source":["# Review the transfer learning model: using VGG-16\n","review_model = models.vgg16(pretrained=True)\n","print(review_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0891545a4f3345f1a8f4367e887719b9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rRNDatAK_FOV"},"source":["# test_model = nn.Sequential(*list(review_model.children())[:-1])\n","# print(test_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"316i3Yix3KcC"},"source":["# Create our CNN model by modifying the output layer of the transfer learning model\n","def CNN_model(hidden_units, dropout, num_classes):\n","  transfer_model = models.vgg16(pretrained=True)\n","  \n","  # freeze the weights from training in the transfer learning model\n","  for param in transfer_model.parameters():\n","    param.requires_grad = False\n","\n","  # define the overall CNN model\n","  model = transfer_model\n","  model.classifier = nn.Sequential(\n","    nn.Linear(in_features=25088, out_features=4096),\n","    nn.ReLU(inplace=True),\n","    nn.Dropout(dropout, inplace=False),\n","    nn.Linear(in_features=4096, out_features=hidden_units),\n","    nn.ReLU(inplace=True),\n","    nn.Dropout(dropout, inplace=False),\n","    nn.Linear(hidden_units, num_classes),\n","    nn.LogSoftmax(dim=1)    \n","  )\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSj-8e3lApQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619260151051,"user_tz":-60,"elapsed":152367,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"abbe4c7c-91ef-4eca-9ea1-000beb668cdd"},"source":["# Test model creation\n","test_model = CNN_model(256, 0.4, 4)\n","print(test_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.4, inplace=False)\n","    (3): Linear(in_features=4096, out_features=256, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.4, inplace=False)\n","    (6): Linear(in_features=256, out_features=4, bias=True)\n","    (7): LogSoftmax(dim=1)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3ZrcE8iqVTod"},"source":["# Confirm trainable parameters\n","# total_params = sum(p.numel() for p in test_model.parameters())\n","# print(f'Total number of parameters: {total_params:,}')\n","# total_trainable_params = sum(\n","#     p.numel() for p in test_model.parameters() if p.requires_grad)\n","# print(f'Number of trainable parameters: {total_trainable_params:,}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coIoMGBHYmeF"},"source":["### Create Training Execution Code"]},{"cell_type":"code","metadata":{"id":"Cb_McQ6jgRRQ"},"source":["# Define a class to build run execution sets based on a dictionary of hyperparameters\n","class RunBuilder():\n","  @staticmethod\n","  def get_runs(params):\n","    Run = namedtuple('Run', params.keys())\n","    runs = []\n","    for v in product(*params.values()):\n","      runs.append(Run(*v))\n","    return runs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHIF2KW7gSp4"},"source":["# Create a class to manage the training / hyperparameter runs\n","class RunManager():\n","  def __init__(self):\n","    self.epoch_count = 0\n","    self.train_loss = 0\n","    self.train_num_correct = 0\n","    self.val_loss = 0\n","    self.val_num_correct = 0\n","\n","    self.run_params = None\n","    self.run_count = 0\n","    self.run_data = []\n","\n","    self.model = None\n","    self.train_loader = None\n","    self.val_loader = None\n","    self.tb = None\n","\n","  def begin_run(self, run, model, train_loader, val_loader):\n","    self.run_params = run\n","    self.run_count += 1\n","    self.model = model.to(device)\n","    self.train_loader = train_loader\n","    self.val_loader = val_loader\n","    self.tb = SummaryWriter(log_dir=datadir + '/runs', max_queue=20, comment=f'-{run}')\n","    images, labels = next(iter(self.train_loader))\n","    images, labels = images.to(device), labels.to(device)\n","    self.tb.add_graph(self.model, images)\n","\n","  def end_run(self):\n","    self.tb.close()\n","    self.epoch_count = 0\n","\n","  def begin_epoch(self):\n","    self.epoch_count += 1\n","    self.train_loss = 0\n","    self.train_num_correct = 0\n","    self.val_loss = 0\n","    self.val_num_correct = 0\n","\n","  def end_epoch(self):\n","    train_loss = self.train_loss / len(self.train_loader.dataset)\n","    train_accuracy = self.train_num_correct / len(self.train_loader.dataset)\n","    val_loss = self.val_loss / len(self.val_loader.dataset)\n","    val_accuracy = self.val_num_correct / len(self.val_loader.dataset)\n","\n","    self.tb.add_scalar('Train Loss', train_loss, self.epoch_count)\n","    self.tb.add_scalar('Train Accuracy', train_accuracy, self.epoch_count)\n","    self.tb.add_scalar('Val Loss', val_loss, self.epoch_count)\n","    self.tb.add_scalar('Val Accuracy', val_accuracy, self.epoch_count)\n","\n","    for name, param in self.model.named_parameters():\n","      self.tb.add_histogram(name, param, self.epoch_count)\n","      #self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n","\n","    print(f'Epoch: {self.epoch_count}, Train Loss: {train_loss:.3f}, Train Acc: {train_accuracy:.3f}')\n","    print(f'Epoch: {self.epoch_count}, Valid Loss: {val_loss:.3f}, Valid Acc: {val_accuracy:.3f}')\n","    \n","    results = OrderedDict()\n","    results['run'] = self.run_count\n","    results['epoch'] = self.epoch_count\n","    results['train loss'] = train_loss\n","    results['train acc'] = train_accuracy\n","    results['valid loss'] = val_loss\n","    results['valid acc'] = val_accuracy\n","\n","    for k, v in self.run_params._asdict().items():\n","      results[k] = v\n","\n","    self.run_data.append(results)\n","\n","  def track_loss(self, loss, mode):\n","    if mode == 'train':\n","      self.train_loss += loss.item() * self.train_loader.batch_size\n","    elif mode == 'val':\n","      self.val_loss += loss.item() * self.val_loader.batch_size\n","\n","  def track_num_correct(self, preds, labels, mode):\n","    if mode == 'train':\n","      self.train_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n","    elif mode == 'val':\n","      self.val_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n","\n","  def save_output(self, filename):\n","    if filename:\n","      filename = traindir + filename\n","      pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{filename}.csv')\n","      \n","      # with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n","      #   json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n","\n","      print('Results saved to disk')\n","\n","    return pd.DataFrame.from_dict(self.run_data, orient='columns')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7cw959ggTzs"},"source":["# Define training loop execution\n","def execution_loop(filename):\n","  m = RunManager()\n","  for run in RunBuilder.get_runs(params):\n","\n","    # instantiate the neural network model\n","    model = CNN_model(run.hidden_units, run.dropout, run.num_classes)\n","    optimizer = Adam(model.parameters(), lr=run.lr)\n","    \n","    # Define the data loaders\n","    dataloaders = {\n","        'train': DataLoader(data['train'], batch_size=run.batch_size, shuffle=True, num_workers=1),\n","        'val': DataLoader(data['val'], batch_size=run.batch_size, shuffle=False, num_workers=1)\n","    }\n","\n","    train_loader = dataloaders['train']\n","    val_loader = dataloaders['val']  \n","        \n","    m.begin_run(run, model, train_loader, val_loader)\n","    for epoch in range(run.n_epochs):\n","      m.begin_epoch()\n","      for batch in train_loader:\n","        with torch.set_grad_enabled(True):\n","          # get inputs/targets and move tensors to GPU\n","          images, labels = batch[0].to(device), batch[1].to(device)\n","          # clear previous gradients\n","          optimizer.zero_grad()\n","          # make prediction\n","          yhat = model(images)\n","          # calculate the loss\n","          loss = F.nll_loss(yhat, labels)\n","          # perform back prop\n","          loss.backward()\n","          # update model weights\n","          optimizer.step()\n","\n","          m.track_loss(loss, 'train')\n","          m.track_num_correct(yhat, labels, 'train')\n","\n","      else:\n","        with torch.no_grad():\n","          for batch in val_loader:\n","            images, labels = batch[0].to(device), batch[1].to(device)\n","            output = model(images)\n","            loss = F.nll_loss(output, labels)\n","\n","            m.track_loss(loss, 'val')\n","            m.track_num_correct(output, labels, 'val')\n","\n","      m.end_epoch()\n","    m.end_run()\n","  return model, m.save_output(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XkQIcFwZgTLy"},"source":["# Define training run hyperparameters\n","params = OrderedDict(\n","    hidden_units = [256, 512],\n","    dropout = [0.4, 0.5],\n","    num_classes = [5],\n","    lr = [0.001],\n","    batch_size = [25],\n","    n_epochs = [10, 20]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6Defy3JLYKo","executionInfo":{"status":"ok","timestamp":1619261991112,"user_tz":-60,"elapsed":1992407,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"69e1e624-40d0-4d18-c895-d822bb22daba"},"source":["model, history = execution_loop('Run_Results')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 1, Train Loss: 1.031, Train Acc: 0.666\n","Epoch: 1, Valid Loss: 0.598, Valid Acc: 0.810\n","Epoch: 2, Train Loss: 0.509, Train Acc: 0.826\n","Epoch: 2, Valid Loss: 0.561, Valid Acc: 0.817\n","Epoch: 3, Train Loss: 0.419, Train Acc: 0.858\n","Epoch: 3, Valid Loss: 0.667, Valid Acc: 0.749\n","Epoch: 4, Train Loss: 0.359, Train Acc: 0.886\n","Epoch: 4, Valid Loss: 0.524, Valid Acc: 0.844\n","Epoch: 5, Train Loss: 0.300, Train Acc: 0.909\n","Epoch: 5, Valid Loss: 0.680, Valid Acc: 0.783\n","Epoch: 6, Train Loss: 0.236, Train Acc: 0.921\n","Epoch: 6, Valid Loss: 0.856, Valid Acc: 0.803\n","Epoch: 7, Train Loss: 0.213, Train Acc: 0.937\n","Epoch: 7, Valid Loss: 0.814, Valid Acc: 0.820\n","Epoch: 8, Train Loss: 0.237, Train Acc: 0.926\n","Epoch: 8, Valid Loss: 0.876, Valid Acc: 0.831\n","Epoch: 9, Train Loss: 0.197, Train Acc: 0.940\n","Epoch: 9, Valid Loss: 0.863, Valid Acc: 0.837\n","Epoch: 10, Train Loss: 0.182, Train Acc: 0.947\n","Epoch: 10, Valid Loss: 0.910, Valid Acc: 0.763\n","Epoch: 1, Train Loss: 1.127, Train Acc: 0.646\n","Epoch: 1, Valid Loss: 0.655, Valid Acc: 0.797\n","Epoch: 2, Train Loss: 0.575, Train Acc: 0.804\n","Epoch: 2, Valid Loss: 0.568, Valid Acc: 0.803\n","Epoch: 3, Train Loss: 0.455, Train Acc: 0.844\n","Epoch: 3, Valid Loss: 0.654, Valid Acc: 0.769\n","Epoch: 4, Train Loss: 0.475, Train Acc: 0.849\n","Epoch: 4, Valid Loss: 0.523, Valid Acc: 0.803\n","Epoch: 5, Train Loss: 0.323, Train Acc: 0.883\n","Epoch: 5, Valid Loss: 0.622, Valid Acc: 0.834\n","Epoch: 6, Train Loss: 0.315, Train Acc: 0.900\n","Epoch: 6, Valid Loss: 0.823, Valid Acc: 0.793\n","Epoch: 7, Train Loss: 0.326, Train Acc: 0.896\n","Epoch: 7, Valid Loss: 0.868, Valid Acc: 0.820\n","Epoch: 8, Train Loss: 0.295, Train Acc: 0.913\n","Epoch: 8, Valid Loss: 0.752, Valid Acc: 0.824\n","Epoch: 9, Train Loss: 0.274, Train Acc: 0.918\n","Epoch: 9, Valid Loss: 0.660, Valid Acc: 0.851\n","Epoch: 10, Train Loss: 0.212, Train Acc: 0.940\n","Epoch: 10, Valid Loss: 0.998, Valid Acc: 0.763\n","Epoch: 1, Train Loss: 1.065, Train Acc: 0.692\n","Epoch: 1, Valid Loss: 0.695, Valid Acc: 0.749\n","Epoch: 2, Train Loss: 0.461, Train Acc: 0.837\n","Epoch: 2, Valid Loss: 0.570, Valid Acc: 0.824\n","Epoch: 3, Train Loss: 0.367, Train Acc: 0.875\n","Epoch: 3, Valid Loss: 0.696, Valid Acc: 0.780\n","Epoch: 4, Train Loss: 0.309, Train Acc: 0.896\n","Epoch: 4, Valid Loss: 0.696, Valid Acc: 0.797\n","Epoch: 5, Train Loss: 0.321, Train Acc: 0.903\n","Epoch: 5, Valid Loss: 0.657, Valid Acc: 0.827\n","Epoch: 6, Train Loss: 0.232, Train Acc: 0.925\n","Epoch: 6, Valid Loss: 0.596, Valid Acc: 0.847\n","Epoch: 7, Train Loss: 0.243, Train Acc: 0.930\n","Epoch: 7, Valid Loss: 0.632, Valid Acc: 0.827\n","Epoch: 8, Train Loss: 0.211, Train Acc: 0.941\n","Epoch: 8, Valid Loss: 0.903, Valid Acc: 0.824\n","Epoch: 9, Train Loss: 0.210, Train Acc: 0.936\n","Epoch: 9, Valid Loss: 0.980, Valid Acc: 0.783\n","Epoch: 10, Train Loss: 0.173, Train Acc: 0.954\n","Epoch: 10, Valid Loss: 0.781, Valid Acc: 0.847\n","Epoch: 1, Train Loss: 1.096, Train Acc: 0.646\n","Epoch: 1, Valid Loss: 0.553, Valid Acc: 0.800\n","Epoch: 2, Train Loss: 0.539, Train Acc: 0.824\n","Epoch: 2, Valid Loss: 0.627, Valid Acc: 0.797\n","Epoch: 3, Train Loss: 0.472, Train Acc: 0.842\n","Epoch: 3, Valid Loss: 0.665, Valid Acc: 0.800\n","Epoch: 4, Train Loss: 0.386, Train Acc: 0.872\n","Epoch: 4, Valid Loss: 0.809, Valid Acc: 0.807\n","Epoch: 5, Train Loss: 0.360, Train Acc: 0.891\n","Epoch: 5, Valid Loss: 0.721, Valid Acc: 0.773\n","Epoch: 6, Train Loss: 0.317, Train Acc: 0.898\n","Epoch: 6, Valid Loss: 0.712, Valid Acc: 0.834\n","Epoch: 7, Train Loss: 0.299, Train Acc: 0.897\n","Epoch: 7, Valid Loss: 0.756, Valid Acc: 0.797\n","Epoch: 8, Train Loss: 0.216, Train Acc: 0.928\n","Epoch: 8, Valid Loss: 0.972, Valid Acc: 0.817\n","Epoch: 9, Train Loss: 0.243, Train Acc: 0.933\n","Epoch: 9, Valid Loss: 0.988, Valid Acc: 0.786\n","Epoch: 10, Train Loss: 0.273, Train Acc: 0.927\n","Epoch: 10, Valid Loss: 0.784, Valid Acc: 0.824\n","Results saved to disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wZox_GOQQ6mj"},"source":["# View single run loss curves\n","# plt.figure(figsize=(10, 8))\n","# plt.plot(history['train loss'], label='Training', linewidth=3)\n","# plt.plot(history['valid loss'], label='Validation', linewidth=3)\n","# plt.title('Training and Validation Losses', fontsize=16)\n","# plt.ylabel('Average Negative Log Likelihood')\n","# plt.xlabel('Epoch')\n","# plt.legend(loc='upper right')\n","# plt.show();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8hgZffZbgOY"},"source":["# View single run accuracy curves\n","# plt.figure(figsize=(10, 8))\n","# plt.plot(history['train acc'], label='Training', linewidth=3)\n","# plt.plot(history['valid acc'], label='Validation', linewidth=3)\n","# plt.title('Training and Validation Accuracy', fontsize=16)\n","# plt.ylabel('Average Accuracy')\n","# plt.xlabel('Epoch')\n","# plt.legend(loc='lower right')\n","# plt.show();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"af3MMi98Pebo"},"source":["# Function to evaluate the model on the test set\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # evaluate the model on the test set\n","        yhat = model(inputs)\n","        # retrieve numpy array\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        actual = actual.reshape((len(actual), 1))\n","        # round to class values\n","        yhat = yhat.round()\n","        # store\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # calculate accuracy\n","    acc = accuracy_score(actuals, predictions)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"5Ou-1KfaPiv5","executionInfo":{"status":"error","timestamp":1619262313719,"user_tz":-60,"elapsed":1730,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"f0168f0d-914d-4cc5-a93f-d38e7801e714"},"source":["# Determine model accuracy on the test set\n","test_dl = DataLoader(data['test'], batch_size=params['batch_size'][0], shuffle=False, num_workers=1)\n","test_acc = evaluate_model(test_dl, model)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-dc7af0053a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Determine model accuracy on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-fcd12660c965>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(test_dl, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# retrieve numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"]}]},{"cell_type":"code","metadata":{"id":"3ghp7zVUU1lJ"},"source":[""],"execution_count":null,"outputs":[]}]}