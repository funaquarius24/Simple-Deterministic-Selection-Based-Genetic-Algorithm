{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"MNIST_hyperp_opt_PyTorch_BO_test_idea_decrease_lr.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"63ad05ed","executionInfo":{"status":"ok","timestamp":1639918899132,"user_tz":0,"elapsed":8506,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["import torch\n","\n","import torchvision\n","import os\n","from pathlib import Path\n","import time\n","\n","# Import libraries\n","import os\n","import time\n","import random\n","import numpy as np\n","from numpy import argmax\n","import pandas as pd\n","import json\n","from collections import OrderedDict, namedtuple\n","from itertools import product\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","import torchvision\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import warnings\n","warnings.filterwarnings('ignore', category=FutureWarning)"],"id":"63ad05ed","execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install hyperopt\n","!pip install bayesian-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-czGQBgPA7bf","executionInfo":{"status":"ok","timestamp":1639918907535,"user_tz":0,"elapsed":8542,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"88f85a4c-d8b3-4953-8571-c7e11eba4521"},"id":"-czGQBgPA7bf","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.62.3)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (3.12.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.3)\n","Collecting bayesian-optimization\n","  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.0.0)\n","Building wheels for collected packages: bayesian-optimization\n","  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=48743090bf913f39be4580f226e216c6747e7beeef6dc2c8dcaedf96be505993\n","  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n","Successfully built bayesian-optimization\n","Installing collected packages: bayesian-optimization\n","Successfully installed bayesian-optimization-1.2.0\n"]}]},{"cell_type":"code","metadata":{"id":"f139b47f","executionInfo":{"status":"ok","timestamp":1639918907537,"user_tz":0,"elapsed":34,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"id":"f139b47f","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"05966507","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639918951515,"user_tz":0,"elapsed":44002,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"outputId":"1958dcc0-ca65-4e98-999d-2a94b35bcb17"},"source":["if IN_COLAB:\n","\n","    from google.colab import drive\n","    drive._mount('/drive', force_remount=True)\n","    datadir = '/drive/My Drive/Colab Notebooks/Datasets/'\n","    optim_dir = datadir + '/optim_dir/'\n","    results_folder = datadir+'/results/'\n","    Path(results_folder).mkdir(parents=True, exist_ok=True)\n","    Path(optim_dir).mkdir(parents=True, exist_ok=True)\n","else:\n","  results_folder = 'results'\n","  optim_dir = 'optim_dir'\n","  Path(\"results\").mkdir(parents=True, exist_ok=True)\n","  Path(optim_dir).mkdir(parents=True, exist_ok=True)\n","\n","\n","# from opfunu.cec_basic.cec2014_nobias import *\n","# from mealpy.swarm_based.PSO import BasePSO"],"id":"05966507","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}]},{"cell_type":"code","metadata":{"id":"q6QsBP46UdpT","executionInfo":{"status":"ok","timestamp":1639918951519,"user_tz":0,"elapsed":27,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":[""],"id":"q6QsBP46UdpT","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTLb22GaK7kU","executionInfo":{"status":"ok","timestamp":1639918952039,"user_tz":0,"elapsed":541,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89f27b99-8f9c-4640-81de-eb086426f2da"},"source":["import sys\n","if IN_COLAB:\n","  print('yes')\n","  scripts_dir = '/drive/My Drive/Colab Notebooks/scripts/'\n","  sys.path.insert(1, scripts_dir)\n","# from opfunu.cec_basic.cec2014_nobias import *\n","# from mealpy.swarm_based.PSO import BasePSO\n","\n","# insert at 1, 0 is the script path (or '' in REPL)\n","else:\n","    sys.path.insert(1, 'scripts')\n","# from PSO import BasePSO\n","from bayes_opt import BayesianOptimization"],"id":"xTLb22GaK7kU","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["yes\n"]}]},{"cell_type":"code","metadata":{"id":"2rWEYyWGfnM8","executionInfo":{"status":"ok","timestamp":1639918952042,"user_tz":0,"elapsed":46,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":[""],"id":"2rWEYyWGfnM8","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f11a1558","executionInfo":{"status":"ok","timestamp":1639918952045,"user_tz":0,"elapsed":47,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2875153-5124-46ba-837a-f462e0df780d"},"source":["# Enable GPU processing\n","if IN_COLAB:\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(f'Device type: {device}')"],"id":"f11a1558","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Device type: cuda\n"]}]},{"cell_type":"code","metadata":{"id":"d9ee0a48","executionInfo":{"status":"ok","timestamp":1639918952047,"user_tz":0,"elapsed":41,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cae3d72a-442c-4184-e8ac-a554b8425e6f"},"source":["n_epochs = 3\n","batch_size_train = 64\n","batch_size_test = 1000\n","learning_rate = 0.01\n","momentum = 0.5\n","log_interval = 10\n","\n","random_seed = 1\n","torch.backends.cudnn.enabled = False\n","torch.manual_seed(random_seed)\n"],"id":"d9ee0a48","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ff569618ad0>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"c049dc40","executionInfo":{"status":"ok","timestamp":1639918952048,"user_tz":0,"elapsed":35,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Set random seed\n","seed = 777\n","torch.manual_seed(seed)\n","model = None"],"id":"c049dc40","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"7440qCvvGZ10","executionInfo":{"status":"ok","timestamp":1639918952055,"user_tz":0,"elapsed":40,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"353670e8-1de8-482e-8d3c-f05c759dbf59"},"source":["import random\n","def seeding(SEED):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n","    # tf.random.set_seed(SEED)\n","    print('seeding done!!!')\n","seeding(seed)"],"id":"7440qCvvGZ10","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["seeding done!!!\n"]}]},{"cell_type":"code","metadata":{"id":"34ce94cd","executionInfo":{"status":"ok","timestamp":1639918955497,"user_tz":0,"elapsed":3474,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["train_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST(datadir, train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_train, shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","  torchvision.datasets.MNIST(datadir, train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","  batch_size=batch_size_test, shuffle=True)\n","\n","data = {\n","    'train': \n","    torchvision.datasets.MNIST(datadir, train=True, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ])),\n","    'val': \n","    torchvision.datasets.MNIST(datadir, train=False, download=True,\n","                             transform=torchvision.transforms.Compose([\n","                               torchvision.transforms.ToTensor(),\n","                               torchvision.transforms.Normalize(\n","                                 (0.1307,), (0.3081,))\n","                             ]))\n","}"],"id":"34ce94cd","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"421e4c4a","executionInfo":{"status":"ok","timestamp":1639918955911,"user_tz":0,"elapsed":431,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)"],"id":"421e4c4a","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"30a0ebf7","executionInfo":{"status":"ok","timestamp":1639918955915,"user_tz":0,"elapsed":42,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3483005-a416-4461-e0ce-6f19fd6702e6"},"source":["example_data.shape"],"id":"30a0ebf7","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1000, 1, 28, 28])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"b07c879e","executionInfo":{"status":"ok","timestamp":1639918956928,"user_tz":0,"elapsed":1041,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/","height":284},"outputId":"eae7799e-da47-48b8-c0fb-3f1e5e709945"},"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","for i in range(6):\n","    plt.subplot(2,3,i+1)\n","    plt.tight_layout()\n","    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n","    plt.xticks([])\n","    plt.yticks([])\n"],"id":"b07c879e","execution_count":13,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 6 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"113737d3","executionInfo":{"status":"ok","timestamp":1639918956932,"user_tz":0,"elapsed":29,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"id":"113737d3","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"0062fb33","executionInfo":{"status":"ok","timestamp":1639918956933,"user_tz":0,"elapsed":27,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(1600, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        # exit()\n","        x = self.dropout2(x)\n","        \n","        x = self.fc1(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output"],"id":"0062fb33","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"778dceea","executionInfo":{"status":"ok","timestamp":1639918956935,"user_tz":0,"elapsed":25,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["network = Net()\n","optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n","                      momentum=momentum)\n","\n","# If we were using a GPU for training, we should have also sent \n","# the network parameters to the GPU using e.g. network.cuda(). \n","# It is important to transfer the network's parameters to the appropriate \n","# device before passing them to the optimizer, otherwise the optimizer will \n","# not be able to keep track of them in the right way."],"id":"778dceea","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"10f480e9","executionInfo":{"status":"ok","timestamp":1639918956937,"user_tz":0,"elapsed":24,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3f5e932-7395-41a6-b2c2-406d3566873d"},"source":["print(network)"],"id":"10f480e9","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Net(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (dropout1): Dropout(p=0.25, inplace=False)\n","  (dropout2): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=1600, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"b77aca6a","executionInfo":{"status":"ok","timestamp":1639918956938,"user_tz":0,"elapsed":23,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Define a class to build run execution sets based on a dictionary of hyperparameters\n","class RunBuilder():\n","    @staticmethod\n","    def get_runs(params):\n","        Run = namedtuple('Run', params.keys())\n","        runs = []\n","        for v in product(*params.values()):\n","            runs.append(Run(*v))\n","        return runs"],"id":"b77aca6a","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"73a21eb0","executionInfo":{"status":"ok","timestamp":1639918957201,"user_tz":0,"elapsed":11,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Create a class to manage the training / hyperparameter runs\n","class RunManager():\n","  def __init__(self):\n","    self.epoch_count = 0\n","    self.train_loss = 0\n","    self.train_num_correct = 0\n","    self.val_loss = 0\n","    self.val_num_correct = 0\n","\n","    self.run_params = None\n","    self.run_count = 0\n","    self.run_data = []\n","\n","    self.model = None\n","    self.train_loader = None\n","    self.val_loader = None\n","    self.tb = None\n","    \n","    #---\n","    self.results = None\n","\n","  def begin_run(self, run, model, train_loader, val_loader):\n","    self.run_params = run\n","    self.run_count += 1\n","    self.model = model.to(device)\n","    self.train_loader = train_loader\n","    self.val_loader = val_loader\n","    self.tb = SummaryWriter(log_dir='/runs', max_queue=20, comment=f'-{run}')\n","    images, labels = next(iter(self.train_loader))\n","    images, labels = images.to(device), labels.to(device)\n","    self.tb.add_graph(self.model, images)\n","    \n","\n","  def end_run(self):\n","    self.tb.close()\n","    self.epoch_count = 0\n","\n","  def begin_epoch(self):\n","    self.epoch_count += 1\n","    self.train_loss = 0\n","    self.train_num_correct = 0\n","    self.val_loss = 0\n","    self.val_num_correct = 0\n","\n","  def end_epoch(self):\n","    train_loss = self.train_loss / len(self.train_loader.dataset)\n","    train_accuracy = self.train_num_correct / len(self.train_loader.dataset)\n","    val_loss = self.val_loss / len(self.val_loader.dataset)\n","    val_accuracy = self.val_num_correct / len(self.val_loader.dataset)\n","\n","    self.tb.add_scalar('Train Loss', train_loss, self.epoch_count)\n","    self.tb.add_scalar('Train Accuracy', train_accuracy, self.epoch_count)\n","    self.tb.add_scalar('Val Loss', val_loss, self.epoch_count)\n","    self.tb.add_scalar('Val Accuracy', val_accuracy, self.epoch_count)\n","\n","    for name, param in self.model.named_parameters():\n","      self.tb.add_histogram(name, param, self.epoch_count)\n","      #self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n","\n","    print(f'Epoch: {self.epoch_count}, Train Loss: {train_loss:.3f}, Train Acc: {train_accuracy:.4f}')\n","    print(f'Epoch: {self.epoch_count}, Valid Loss: {val_loss:.3f}, Valid Acc: {val_accuracy:.4f}')\n","    \n","    results = OrderedDict()\n","    results['run'] = self.run_count\n","    results['epoch'] = self.epoch_count\n","    results['train loss'] = train_loss\n","    results['train acc'] = train_accuracy\n","    results['valid loss'] = val_loss\n","    results['valid acc'] = val_accuracy\n","    \n","    # ---\n","    self.results = results\n","\n","    for k, v in self.run_params.items():\n","      results[k] = v\n","\n","    self.run_data.append(results)\n","\n","  def track_loss(self, loss, mode):\n","    if mode == 'train':\n","      self.train_loss += loss.item() * self.train_loader.batch_size\n","    elif mode == 'val':\n","      self.val_loss += loss.item() * self.val_loader.batch_size\n","\n","  def track_num_correct(self, preds, labels, mode):\n","    if mode == 'train':\n","      self.train_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n","    elif mode == 'val':\n","      self.val_num_correct += preds.argmax(dim=1).eq(labels).sum().item()\n","\n","  def save_output(self, filename):\n","    if filename:\n","      filename = filename\n","      pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{filename}.csv')\n","      \n","      # with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n","      #   json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n","\n","      # print('Results saved to disk')\n","\n","    return pd.DataFrame.from_dict(self.run_data, orient='columns')\n"],"id":"73a21eb0","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"4587cf04","executionInfo":{"status":"ok","timestamp":1639918957464,"user_tz":0,"elapsed":271,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Define training loop execution\n","def execution_loop(m, model, args): # args is given by the optimizer [lr, batch_size]\n","    agent = {}\n","    agents = []\n","    power = args[0].astype(int)\n","    num = args[0] - power \n","    tmp = num * 10.0**-power\n","    agent['lr'] = round(tmp, 6)\n","    agent['batch_size'] = int(args[1])\n","    agents.append(agent)\n","#     m = RunManager()\n","    for run in agents: # this should be one. a particle in pso\n","\n","        count = 0\n","        prev_valid_accs = []\n","\n","        # instantiate the neural network model\n","        #     model = CNN_model(run.hidden_units, run.dropout, run.num_classes) \n","        optimizer = Adam(model.parameters(), lr=run['lr'])\n","\n","        # Define the data loaders\n","        dataloaders = {\n","            'train': DataLoader(data['train'], batch_size=run['batch_size'], shuffle=True, num_workers=1),\n","            'val': DataLoader(data['val'], batch_size=run['batch_size'], shuffle=False, num_workers=1)\n","        }\n","\n","        train_loader = dataloaders['train']\n","        val_loader = dataloaders['val']  \n","\n","        # print(f'Run Params: {run}')\n","\n","        m.begin_run(run, model, train_loader, val_loader)\n","        for epoch in range(params['n_epochs'][0]):\n","            \n","            if epoch > 2:\n","                \n","                if prev_valid_acc < 0.7:\n","                    break\n","            if epoch > 15:\n","                \n","                if max(prev_valid_accs) < 0.97:\n","                    break\n","            if epoch > 19:\n","                \n","                if max(prev_valid_accs) < 0.98:\n","                    break\n","            if epoch > 8 and prev_valid_accs[-1] <= prev_valid_accs[-2]:\n","                for i in range(2, len(prev_valid_accs)):\n","                    if prev_valid_accs[-1] <= prev_valid_accs[-i]:\n","                        count += 1\n","                        if count > 3:\n","                            optimizer.param_groups[0]['lr'] = run['lr'] * 0.1\n","                            count = 0\n","                            break\n","            m.begin_epoch()\n","            for batch in train_loader:\n","                with torch.set_grad_enabled(True):\n","                    # get inputs/targets and move tensors to GPU\n","                    images, labels = batch[0].to(device), batch[1].to(device)\n","                    # clear previous gradients\n","                    optimizer.zero_grad()\n","                    # make prediction\n","                    yhat = model(images)\n","                    # calculate the loss\n","                    loss = F.nll_loss(yhat, labels)\n","                    # perform back prop\n","                    loss.backward()\n","                    # update model weights\n","                    optimizer.step()\n","\n","                    m.track_loss(loss, 'train')\n","                    m.track_num_correct(yhat, labels, 'train')\n","\n","            else:\n","                with torch.no_grad():\n","                    for batch in val_loader:\n","                        images, labels = batch[0].to(device), batch[1].to(device)\n","                        output = model(images)\n","                        loss = F.nll_loss(output, labels)\n","\n","                        m.track_loss(loss, 'val')\n","                        m.track_num_correct(output, labels, 'val')\n","\n","            m.end_epoch()\n","            prev_valid_acc = m.results['valid acc']\n","            prev_valid_accs.append(prev_valid_acc)\n","    m.end_run()\n","    return model, max(prev_valid_accs)"],"id":"4587cf04","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"68f5bc94","executionInfo":{"status":"ok","timestamp":1639918957468,"user_tz":0,"elapsed":26,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["train_losses = []\n","train_counter = []\n","test_losses = []\n","test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"],"id":"68f5bc94","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"f63f0c6e","executionInfo":{"status":"ok","timestamp":1639918957473,"user_tz":0,"elapsed":28,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Define training run hyperparameters\n","params = {\n","    'hidden_units' : [256],\n","    'dropout' : [0.5],\n","    'num_classes' : [10],\n","    'lr' : [0, 1],\n","    'batch_size' : [20, 2000],\n","    'n_epochs' : [30]\n","}\n","\n","# params = OrderedDict(\n","#     lr = [0, 1],\n","#     batch_size = [20 2000],\n","#     n_epochs = [3]\n","# )"],"id":"f63f0c6e","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"714915ca","executionInfo":{"status":"ok","timestamp":1639918957476,"user_tz":0,"elapsed":31,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["m = RunManager()\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n","filename = f'Run_Results-MNIST-BO-test-idea-lr-FR--{timestr}'\n","# filename = 'Run_Results-MNIST-BBO-test-idea-lr---20210512-083324-cont' # this is for trying to continue from last optim save\n"],"id":"714915ca","execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"672f8bd1","executionInfo":{"status":"ok","timestamp":1639918957479,"user_tz":0,"elapsed":33,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["def run_train_model(agent):\n","    network = Net()\n","    model, valid_acc = execution_loop(m, network, agent)\n","    m.save_output(f'{results_folder}/{filename}')\n","    # print(\"valid acc: \", valid_acc)\n","    return valid_acc * -1"],"id":"672f8bd1","execution_count":24,"outputs":[]},{"cell_type":"code","source":["def run_train_model_proxy(lr, batch_size):\n","    agent = [lr, batch_size]\n","    return run_train_model(agent) * -1"],"metadata":{"id":"OUd0gITMv5Jp","executionInfo":{"status":"ok","timestamp":1639918957486,"user_tz":0,"elapsed":39,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"id":"OUd0gITMv5Jp","execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1lV78LZOldN","executionInfo":{"status":"ok","timestamp":1639918957488,"user_tz":0,"elapsed":40,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# optim_data = None\n","# import pickle\n","# tmp = 'pso_data-20210512-132343-cont.data'\n","# with open(f\"{optim_dir}/{tmp}\", 'rb') as f:\n","#     optim_data = pickle.load(f)\n","\n","# print(optim_data)"],"id":"p1lV78LZOldN","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"84a56449","executionInfo":{"status":"ok","timestamp":1639959390759,"user_tz":0,"elapsed":5550043,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56965271-f28f-4be8-f913-3856bfc8f327"},"source":["verbose = True\n","pop_size = 15   \n","max_iter = 10\n","\n","obj_func = run_train_model_proxy\n","\n","lb = [0, params['batch_size'][0]]\n","ub = [4, params['batch_size'][1]]\n","\n","params_gbm ={\n","    'lr':(0, 4), 'batch_size':(20, 2000)\n","}\n","\n","gbm_bo = BayesianOptimization(f = obj_func, pbounds = params_gbm, random_state=777)\n","gbm_bo.maximize(init_points=15, n_iter=135)\n","\n","# tmp = 'pso_data-20210504-035642.data'\n","# best_pos1, best_fit1, list_loss1 = md2.train(f\"{optim_dir}/{tmp}\", optim_data['epoch_count'], optim_data['v_list'], optim_data['pop'])\n","print(gbm_bo.max)\n","\n","# m.save_output(f'{results_folder}/{filename}')\n","# print('Results saved.')\n"],"id":"84a56449","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch: 11, Train Loss: 0.070, Train Acc: 0.9786\n","Epoch: 11, Valid Loss: 0.077, Valid Acc: 0.9797\n","Epoch: 12, Train Loss: 0.066, Train Acc: 0.9803\n","Epoch: 12, Valid Loss: 0.072, Valid Acc: 0.9815\n","Epoch: 13, Train Loss: 0.064, Train Acc: 0.9806\n","Epoch: 13, Valid Loss: 0.076, Valid Acc: 0.9801\n","Epoch: 14, Train Loss: 0.061, Train Acc: 0.9814\n","Epoch: 14, Valid Loss: 0.070, Valid Acc: 0.9801\n","Epoch: 15, Train Loss: 0.056, Train Acc: 0.9827\n","Epoch: 15, Valid Loss: 0.070, Valid Acc: 0.9801\n","Epoch: 16, Train Loss: 0.057, Train Acc: 0.9826\n","Epoch: 16, Valid Loss: 0.063, Valid Acc: 0.9821\n","Epoch: 17, Train Loss: 0.057, Train Acc: 0.9833\n","Epoch: 17, Valid Loss: 0.065, Valid Acc: 0.9814\n","Epoch: 18, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 18, Valid Loss: 0.063, Valid Acc: 0.9811\n","Epoch: 19, Train Loss: 0.057, Train Acc: 0.9827\n","Epoch: 19, Valid Loss: 0.065, Valid Acc: 0.9824\n","Epoch: 20, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 20, Valid Loss: 0.064, Valid Acc: 0.9847\n","Epoch: 21, Train Loss: 0.056, Train Acc: 0.9832\n","Epoch: 21, Valid Loss: 0.066, Valid Acc: 0.9829\n","Epoch: 22, Train Loss: 0.055, Train Acc: 0.9833\n","Epoch: 22, Valid Loss: 0.065, Valid Acc: 0.9826\n","Epoch: 23, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 23, Valid Loss: 0.064, Valid Acc: 0.9837\n","Epoch: 24, Train Loss: 0.056, Train Acc: 0.9828\n","Epoch: 24, Valid Loss: 0.062, Valid Acc: 0.9843\n","Epoch: 25, Train Loss: 0.055, Train Acc: 0.9841\n","Epoch: 25, Valid Loss: 0.061, Valid Acc: 0.9838\n","Epoch: 26, Train Loss: 0.054, Train Acc: 0.9831\n","Epoch: 26, Valid Loss: 0.062, Valid Acc: 0.9832\n","Epoch: 27, Train Loss: 0.054, Train Acc: 0.9837\n","Epoch: 27, Valid Loss: 0.063, Valid Acc: 0.9840\n","Epoch: 28, Train Loss: 0.053, Train Acc: 0.9841\n","Epoch: 28, Valid Loss: 0.067, Valid Acc: 0.9836\n","Epoch: 29, Train Loss: 0.054, Train Acc: 0.9835\n","Epoch: 29, Valid Loss: 0.063, Valid Acc: 0.9833\n","Epoch: 30, Train Loss: 0.051, Train Acc: 0.9844\n","Epoch: 30, Valid Loss: 0.065, Valid Acc: 0.9832\n","| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9847  \u001b[0m | \u001b[0m 1.387e+0\u001b[0m | \u001b[0m 2.07    \u001b[0m |\n","Epoch: 1, Train Loss: 1.224, Train Acc: 0.6447\n","Epoch: 1, Valid Loss: 0.483, Valid Acc: 0.8540\n","Epoch: 2, Train Loss: 0.369, Train Acc: 0.8883\n","Epoch: 2, Valid Loss: 0.259, Valid Acc: 0.9272\n","Epoch: 3, Train Loss: 0.236, Train Acc: 0.9316\n","Epoch: 3, Valid Loss: 0.185, Valid Acc: 0.9478\n","Epoch: 4, Train Loss: 0.180, Train Acc: 0.9492\n","Epoch: 4, Valid Loss: 0.146, Valid Acc: 0.9581\n","Epoch: 5, Train Loss: 0.149, Train Acc: 0.9557\n","Epoch: 5, Valid Loss: 0.120, Valid Acc: 0.9663\n","Epoch: 6, Train Loss: 0.128, Train Acc: 0.9634\n","Epoch: 6, Valid Loss: 0.115, Valid Acc: 0.9662\n","Epoch: 7, Train Loss: 0.114, Train Acc: 0.9662\n","Epoch: 7, Valid Loss: 0.099, Valid Acc: 0.9701\n","Epoch: 8, Train Loss: 0.103, Train Acc: 0.9701\n","Epoch: 8, Valid Loss: 0.091, Valid Acc: 0.9730\n","Epoch: 9, Train Loss: 0.095, Train Acc: 0.9718\n","Epoch: 9, Valid Loss: 0.082, Valid Acc: 0.9757\n","Epoch: 10, Train Loss: 0.090, Train Acc: 0.9731\n","Epoch: 10, Valid Loss: 0.080, Valid Acc: 0.9750\n","Epoch: 11, Train Loss: 0.084, Train Acc: 0.9751\n","Epoch: 11, Valid Loss: 0.074, Valid Acc: 0.9759\n","Epoch: 12, Train Loss: 0.080, Train Acc: 0.9757\n","Epoch: 12, Valid Loss: 0.074, Valid Acc: 0.9768\n","Epoch: 13, Train Loss: 0.076, Train Acc: 0.9770\n","Epoch: 13, Valid Loss: 0.069, Valid Acc: 0.9782\n","Epoch: 14, Train Loss: 0.071, Train Acc: 0.9787\n","Epoch: 14, Valid Loss: 0.068, Valid Acc: 0.9799\n","Epoch: 15, Train Loss: 0.069, Train Acc: 0.9789\n","Epoch: 15, Valid Loss: 0.063, Valid Acc: 0.9812\n","Epoch: 16, Train Loss: 0.066, Train Acc: 0.9801\n","Epoch: 16, Valid Loss: 0.062, Valid Acc: 0.9811\n","Epoch: 17, Train Loss: 0.064, Train Acc: 0.9808\n","Epoch: 17, Valid Loss: 0.059, Valid Acc: 0.9797\n","Epoch: 18, Train Loss: 0.062, Train Acc: 0.9808\n","Epoch: 18, Valid Loss: 0.058, Valid Acc: 0.9814\n","Epoch: 19, Train Loss: 0.059, Train Acc: 0.9825\n","Epoch: 19, Valid Loss: 0.059, Valid Acc: 0.9803\n","Epoch: 20, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 20, Valid Loss: 0.056, Valid Acc: 0.9832\n","Epoch: 21, Train Loss: 0.061, Train Acc: 0.9819\n","Epoch: 21, Valid Loss: 0.059, Valid Acc: 0.9816\n","Epoch: 22, Train Loss: 0.060, Train Acc: 0.9815\n","Epoch: 22, Valid Loss: 0.060, Valid Acc: 0.9807\n","Epoch: 23, Train Loss: 0.060, Train Acc: 0.9820\n","Epoch: 23, Valid Loss: 0.055, Valid Acc: 0.9836\n","Epoch: 24, Train Loss: 0.059, Train Acc: 0.9825\n","Epoch: 24, Valid Loss: 0.056, Valid Acc: 0.9827\n","Epoch: 25, Train Loss: 0.059, Train Acc: 0.9826\n","Epoch: 25, Valid Loss: 0.055, Valid Acc: 0.9832\n","Epoch: 26, Train Loss: 0.060, Train Acc: 0.9816\n","Epoch: 26, Valid Loss: 0.057, Valid Acc: 0.9828\n","Epoch: 27, Train Loss: 0.058, Train Acc: 0.9830\n","Epoch: 27, Valid Loss: 0.057, Valid Acc: 0.9824\n","Epoch: 28, Train Loss: 0.059, Train Acc: 0.9821\n","Epoch: 28, Valid Loss: 0.054, Valid Acc: 0.9827\n","Epoch: 29, Train Loss: 0.058, Train Acc: 0.9827\n","Epoch: 29, Valid Loss: 0.055, Valid Acc: 0.9821\n","Epoch: 30, Train Loss: 0.061, Train Acc: 0.9817\n","Epoch: 30, Valid Loss: 0.058, Valid Acc: 0.9821\n","| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9836  \u001b[0m | \u001b[0m 1.692e+0\u001b[0m | \u001b[0m 3.505   \u001b[0m |\n","Epoch: 1, Train Loss: 0.782, Train Acc: 0.7781\n","Epoch: 1, Valid Loss: 0.240, Valid Acc: 0.9314\n","Epoch: 2, Train Loss: 0.189, Train Acc: 0.9446\n","Epoch: 2, Valid Loss: 0.132, Valid Acc: 0.9610\n","Epoch: 3, Train Loss: 0.126, Train Acc: 0.9622\n","Epoch: 3, Valid Loss: 0.099, Valid Acc: 0.9693\n","Epoch: 4, Train Loss: 0.103, Train Acc: 0.9690\n","Epoch: 4, Valid Loss: 0.084, Valid Acc: 0.9743\n","Epoch: 5, Train Loss: 0.087, Train Acc: 0.9740\n","Epoch: 5, Valid Loss: 0.071, Valid Acc: 0.9779\n","Epoch: 6, Train Loss: 0.078, Train Acc: 0.9765\n","Epoch: 6, Valid Loss: 0.066, Valid Acc: 0.9784\n","Epoch: 7, Train Loss: 0.072, Train Acc: 0.9783\n","Epoch: 7, Valid Loss: 0.067, Valid Acc: 0.9795\n","Epoch: 8, Train Loss: 0.066, Train Acc: 0.9805\n","Epoch: 8, Valid Loss: 0.064, Valid Acc: 0.9799\n","Epoch: 9, Train Loss: 0.062, Train Acc: 0.9810\n","Epoch: 9, Valid Loss: 0.055, Valid Acc: 0.9836\n","Epoch: 10, Train Loss: 0.058, Train Acc: 0.9826\n","Epoch: 10, Valid Loss: 0.054, Valid Acc: 0.9834\n","Epoch: 11, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 11, Valid Loss: 0.052, Valid Acc: 0.9826\n","Epoch: 12, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 12, Valid Loss: 0.052, Valid Acc: 0.9825\n","Epoch: 13, Train Loss: 0.047, Train Acc: 0.9862\n","Epoch: 13, Valid Loss: 0.051, Valid Acc: 0.9832\n","Epoch: 14, Train Loss: 0.047, Train Acc: 0.9860\n","Epoch: 14, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 15, Train Loss: 0.047, Train Acc: 0.9860\n","Epoch: 15, Valid Loss: 0.047, Valid Acc: 0.9858\n","Epoch: 16, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 16, Valid Loss: 0.046, Valid Acc: 0.9853\n","Epoch: 17, Train Loss: 0.047, Train Acc: 0.9855\n","Epoch: 17, Valid Loss: 0.045, Valid Acc: 0.9850\n","Epoch: 18, Train Loss: 0.046, Train Acc: 0.9863\n","Epoch: 18, Valid Loss: 0.048, Valid Acc: 0.9841\n","Epoch: 19, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 19, Valid Loss: 0.047, Valid Acc: 0.9854\n","Epoch: 20, Train Loss: 0.046, Train Acc: 0.9862\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9843\n","Epoch: 21, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9853\n","Epoch: 22, Train Loss: 0.045, Train Acc: 0.9869\n","Epoch: 22, Valid Loss: 0.047, Valid Acc: 0.9838\n","Epoch: 23, Train Loss: 0.044, Train Acc: 0.9870\n","Epoch: 23, Valid Loss: 0.047, Valid Acc: 0.9844\n","Epoch: 24, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 24, Valid Loss: 0.046, Valid Acc: 0.9853\n","Epoch: 25, Train Loss: 0.045, Train Acc: 0.9867\n","Epoch: 25, Valid Loss: 0.045, Valid Acc: 0.9853\n","Epoch: 26, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 26, Valid Loss: 0.046, Valid Acc: 0.9847\n","Epoch: 27, Train Loss: 0.043, Train Acc: 0.9870\n","Epoch: 27, Valid Loss: 0.045, Valid Acc: 0.9856\n","Epoch: 28, Train Loss: 0.042, Train Acc: 0.9875\n","Epoch: 28, Valid Loss: 0.044, Valid Acc: 0.9855\n","Epoch: 29, Train Loss: 0.042, Train Acc: 0.9874\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9859\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9870\n","Epoch: 30, Valid Loss: 0.043, Valid Acc: 0.9863\n","| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9863  \u001b[0m | \u001b[0m 1.271e+0\u001b[0m | \u001b[0m 3.963   \u001b[0m |\n","Epoch: 1, Train Loss: 4.072, Train Acc: 0.1137\n","Epoch: 1, Valid Loss: 2.377, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.328, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.377, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.328, Train Acc: 0.1108\n","Epoch: 3, Valid Loss: 2.377, Valid Acc: 0.1135\n","| \u001b[0m 26      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.291e+0\u001b[0m | \u001b[0m 1.601   \u001b[0m |\n","Epoch: 1, Train Loss: 1246.427, Train Acc: 0.1010\n","Epoch: 1, Valid Loss: 2.335, Valid Acc: 0.1009\n","Epoch: 2, Train Loss: 2.327, Train Acc: 0.1005\n","Epoch: 2, Valid Loss: 2.322, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.323, Train Acc: 0.1053\n","Epoch: 3, Valid Loss: 2.322, Valid Acc: 0.1135\n","| \u001b[0m 27      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.441e+0\u001b[0m | \u001b[0m 0.8772  \u001b[0m |\n","Epoch: 1, Train Loss: 0.851, Train Acc: 0.7420\n","Epoch: 1, Valid Loss: 0.279, Valid Acc: 0.9217\n","Epoch: 2, Train Loss: 0.215, Train Acc: 0.9360\n","Epoch: 2, Valid Loss: 0.153, Valid Acc: 0.9563\n","Epoch: 3, Train Loss: 0.144, Train Acc: 0.9569\n","Epoch: 3, Valid Loss: 0.115, Valid Acc: 0.9662\n","Epoch: 4, Train Loss: 0.114, Train Acc: 0.9660\n","Epoch: 4, Valid Loss: 0.094, Valid Acc: 0.9727\n","Epoch: 5, Train Loss: 0.095, Train Acc: 0.9713\n","Epoch: 5, Valid Loss: 0.083, Valid Acc: 0.9761\n","Epoch: 6, Train Loss: 0.085, Train Acc: 0.9746\n","Epoch: 6, Valid Loss: 0.073, Valid Acc: 0.9788\n","Epoch: 7, Train Loss: 0.075, Train Acc: 0.9776\n","Epoch: 7, Valid Loss: 0.066, Valid Acc: 0.9795\n","Epoch: 8, Train Loss: 0.071, Train Acc: 0.9788\n","Epoch: 8, Valid Loss: 0.063, Valid Acc: 0.9813\n","Epoch: 9, Train Loss: 0.065, Train Acc: 0.9803\n","Epoch: 9, Valid Loss: 0.061, Valid Acc: 0.9805\n","Epoch: 10, Train Loss: 0.061, Train Acc: 0.9816\n","Epoch: 10, Valid Loss: 0.053, Valid Acc: 0.9834\n","Epoch: 11, Train Loss: 0.058, Train Acc: 0.9828\n","Epoch: 11, Valid Loss: 0.058, Valid Acc: 0.9834\n","Epoch: 12, Train Loss: 0.055, Train Acc: 0.9834\n","Epoch: 12, Valid Loss: 0.052, Valid Acc: 0.9834\n","Epoch: 13, Train Loss: 0.051, Train Acc: 0.9843\n","Epoch: 13, Valid Loss: 0.052, Valid Acc: 0.9843\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9843\n","Epoch: 14, Valid Loss: 0.051, Valid Acc: 0.9834\n","Epoch: 15, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9840\n","Epoch: 16, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 16, Valid Loss: 0.052, Valid Acc: 0.9842\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9853\n","Epoch: 17, Valid Loss: 0.049, Valid Acc: 0.9859\n","Epoch: 18, Train Loss: 0.049, Train Acc: 0.9853\n","Epoch: 18, Valid Loss: 0.050, Valid Acc: 0.9848\n","Epoch: 19, Train Loss: 0.050, Train Acc: 0.9851\n","Epoch: 19, Valid Loss: 0.053, Valid Acc: 0.9826\n","Epoch: 20, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 20, Valid Loss: 0.051, Valid Acc: 0.9845\n","Epoch: 21, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 21, Valid Loss: 0.049, Valid Acc: 0.9853\n","Epoch: 22, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9830\n","Epoch: 23, Train Loss: 0.049, Train Acc: 0.9847\n","Epoch: 23, Valid Loss: 0.050, Valid Acc: 0.9833\n","Epoch: 24, Train Loss: 0.046, Train Acc: 0.9859\n","Epoch: 24, Valid Loss: 0.049, Valid Acc: 0.9837\n","Epoch: 25, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 25, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 26, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 26, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 27, Train Loss: 0.046, Train Acc: 0.9857\n","Epoch: 27, Valid Loss: 0.048, Valid Acc: 0.9848\n","Epoch: 28, Train Loss: 0.045, Train Acc: 0.9870\n","Epoch: 28, Valid Loss: 0.049, Valid Acc: 0.9841\n","Epoch: 29, Train Loss: 0.044, Train Acc: 0.9860\n","Epoch: 29, Valid Loss: 0.050, Valid Acc: 0.9845\n","Epoch: 30, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 30, Valid Loss: 0.047, Valid Acc: 0.9845\n","| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9859  \u001b[0m | \u001b[0m 1.475e+0\u001b[0m | \u001b[0m 3.951   \u001b[0m |\n","Epoch: 1, Train Loss: 459.942, Train Acc: 0.1108\n","Epoch: 1, Valid Loss: 2.681, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.357, Train Acc: 0.1076\n","Epoch: 2, Valid Loss: 2.669, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.351, Train Acc: 0.1063\n","Epoch: 3, Valid Loss: 2.668, Valid Acc: 0.1135\n","| \u001b[0m 29      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.656e+0\u001b[0m | \u001b[0m 0.4413  \u001b[0m |\n","Epoch: 1, Train Loss: 71.063, Train Acc: 0.1052\n","Epoch: 1, Valid Loss: 2.492, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.336, Train Acc: 0.1081\n","Epoch: 2, Valid Loss: 2.490, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.335, Train Acc: 0.1087\n","Epoch: 3, Valid Loss: 2.490, Valid Acc: 0.1032\n","| \u001b[0m 30      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.353e+0\u001b[0m | \u001b[0m 0.3065  \u001b[0m |\n","Epoch: 1, Train Loss: 0.787, Train Acc: 0.7716\n","Epoch: 1, Valid Loss: 0.273, Valid Acc: 0.9265\n","Epoch: 2, Train Loss: 0.194, Train Acc: 0.9425\n","Epoch: 2, Valid Loss: 0.154, Valid Acc: 0.9591\n","Epoch: 3, Train Loss: 0.130, Train Acc: 0.9621\n","Epoch: 3, Valid Loss: 0.116, Valid Acc: 0.9685\n","Epoch: 4, Train Loss: 0.105, Train Acc: 0.9687\n","Epoch: 4, Valid Loss: 0.103, Valid Acc: 0.9723\n","Epoch: 5, Train Loss: 0.092, Train Acc: 0.9722\n","Epoch: 5, Valid Loss: 0.086, Valid Acc: 0.9763\n","Epoch: 6, Train Loss: 0.080, Train Acc: 0.9755\n","Epoch: 6, Valid Loss: 0.081, Valid Acc: 0.9790\n","Epoch: 7, Train Loss: 0.073, Train Acc: 0.9782\n","Epoch: 7, Valid Loss: 0.079, Valid Acc: 0.9786\n","Epoch: 8, Train Loss: 0.067, Train Acc: 0.9794\n","Epoch: 8, Valid Loss: 0.071, Valid Acc: 0.9798\n","Epoch: 9, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 9, Valid Loss: 0.066, Valid Acc: 0.9814\n","Epoch: 10, Train Loss: 0.059, Train Acc: 0.9816\n","Epoch: 10, Valid Loss: 0.063, Valid Acc: 0.9832\n","Epoch: 11, Train Loss: 0.056, Train Acc: 0.9824\n","Epoch: 11, Valid Loss: 0.062, Valid Acc: 0.9817\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9835\n","Epoch: 12, Valid Loss: 0.059, Valid Acc: 0.9837\n","Epoch: 13, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 13, Valid Loss: 0.056, Valid Acc: 0.9833\n","Epoch: 14, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 14, Valid Loss: 0.061, Valid Acc: 0.9832\n","Epoch: 15, Train Loss: 0.045, Train Acc: 0.9865\n","Epoch: 15, Valid Loss: 0.058, Valid Acc: 0.9846\n","Epoch: 16, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 16, Valid Loss: 0.056, Valid Acc: 0.9848\n","Epoch: 17, Train Loss: 0.043, Train Acc: 0.9868\n","Epoch: 17, Valid Loss: 0.054, Valid Acc: 0.9856\n","Epoch: 18, Train Loss: 0.043, Train Acc: 0.9866\n","Epoch: 18, Valid Loss: 0.053, Valid Acc: 0.9846\n","Epoch: 19, Train Loss: 0.044, Train Acc: 0.9868\n","Epoch: 19, Valid Loss: 0.057, Valid Acc: 0.9841\n","Epoch: 20, Train Loss: 0.042, Train Acc: 0.9866\n","Epoch: 20, Valid Loss: 0.050, Valid Acc: 0.9870\n","Epoch: 21, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 21, Valid Loss: 0.055, Valid Acc: 0.9857\n","Epoch: 22, Train Loss: 0.042, Train Acc: 0.9865\n","Epoch: 22, Valid Loss: 0.049, Valid Acc: 0.9860\n","Epoch: 23, Train Loss: 0.043, Train Acc: 0.9872\n","Epoch: 23, Valid Loss: 0.052, Valid Acc: 0.9857\n","Epoch: 24, Train Loss: 0.043, Train Acc: 0.9871\n","Epoch: 24, Valid Loss: 0.053, Valid Acc: 0.9849\n","Epoch: 25, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 25, Valid Loss: 0.053, Valid Acc: 0.9861\n","Epoch: 26, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 26, Valid Loss: 0.050, Valid Acc: 0.9852\n","Epoch: 27, Train Loss: 0.041, Train Acc: 0.9870\n","Epoch: 27, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 28, Train Loss: 0.041, Train Acc: 0.9873\n","Epoch: 28, Valid Loss: 0.046, Valid Acc: 0.9871\n","Epoch: 29, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 29, Valid Loss: 0.051, Valid Acc: 0.9859\n","Epoch: 30, Train Loss: 0.040, Train Acc: 0.9876\n","Epoch: 30, Valid Loss: 0.052, Valid Acc: 0.9845\n","| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 1.2e+03 \u001b[0m | \u001b[0m 3.896   \u001b[0m |\n","Epoch: 1, Train Loss: 209.509, Train Acc: 0.1005\n","Epoch: 1, Valid Loss: 2.765, Valid Acc: 0.0982\n","Epoch: 2, Train Loss: 2.377, Train Acc: 0.1094\n","Epoch: 2, Valid Loss: 2.755, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.373, Train Acc: 0.1096\n","Epoch: 3, Valid Loss: 2.757, Valid Acc: 0.1135\n","| \u001b[0m 32      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.995e+0\u001b[0m | \u001b[0m 0.3553  \u001b[0m |\n","Epoch: 1, Train Loss: 122.444, Train Acc: 0.1036\n","Epoch: 1, Valid Loss: 2.365, Valid Acc: 0.0958\n","Epoch: 2, Train Loss: 2.326, Train Acc: 0.1044\n","Epoch: 2, Valid Loss: 2.364, Valid Acc: 0.0974\n","Epoch: 3, Train Loss: 2.325, Train Acc: 0.1030\n","Epoch: 3, Valid Loss: 2.366, Valid Acc: 0.1028\n","| \u001b[0m 33      \u001b[0m | \u001b[0m 0.1028  \u001b[0m | \u001b[0m 392.2   \u001b[0m | \u001b[0m 0.4296  \u001b[0m |\n","Epoch: 1, Train Loss: 210.697, Train Acc: 0.1070\n","Epoch: 1, Valid Loss: 2.373, Valid Acc: 0.0958\n","Epoch: 2, Train Loss: 2.321, Train Acc: 0.1022\n","Epoch: 2, Valid Loss: 2.381, Valid Acc: 0.0958\n","Epoch: 3, Train Loss: 2.323, Train Acc: 0.1015\n","Epoch: 3, Valid Loss: 2.387, Valid Acc: 0.1135\n","| \u001b[0m 34      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 367.3   \u001b[0m | \u001b[0m 0.6205  \u001b[0m |\n","Epoch: 1, Train Loss: 0.616, Train Acc: 0.8195\n","Epoch: 1, Valid Loss: 0.202, Valid Acc: 0.9417\n","Epoch: 2, Train Loss: 0.175, Train Acc: 0.9474\n","Epoch: 2, Valid Loss: 0.133, Valid Acc: 0.9602\n","Epoch: 3, Train Loss: 0.126, Train Acc: 0.9623\n","Epoch: 3, Valid Loss: 0.103, Valid Acc: 0.9684\n","Epoch: 4, Train Loss: 0.103, Train Acc: 0.9692\n","Epoch: 4, Valid Loss: 0.091, Valid Acc: 0.9723\n","Epoch: 5, Train Loss: 0.088, Train Acc: 0.9741\n","Epoch: 5, Valid Loss: 0.079, Valid Acc: 0.9753\n","Epoch: 6, Train Loss: 0.077, Train Acc: 0.9775\n","Epoch: 6, Valid Loss: 0.071, Valid Acc: 0.9773\n","Epoch: 7, Train Loss: 0.071, Train Acc: 0.9780\n","Epoch: 7, Valid Loss: 0.067, Valid Acc: 0.9784\n","Epoch: 8, Train Loss: 0.065, Train Acc: 0.9802\n","Epoch: 8, Valid Loss: 0.059, Valid Acc: 0.9827\n","Epoch: 9, Train Loss: 0.058, Train Acc: 0.9823\n","Epoch: 9, Valid Loss: 0.053, Valid Acc: 0.9840\n","Epoch: 10, Train Loss: 0.055, Train Acc: 0.9830\n","Epoch: 10, Valid Loss: 0.052, Valid Acc: 0.9830\n","Epoch: 11, Train Loss: 0.053, Train Acc: 0.9839\n","Epoch: 11, Valid Loss: 0.049, Valid Acc: 0.9851\n","Epoch: 12, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 12, Valid Loss: 0.046, Valid Acc: 0.9857\n","Epoch: 13, Train Loss: 0.047, Train Acc: 0.9851\n","Epoch: 13, Valid Loss: 0.047, Valid Acc: 0.9854\n","Epoch: 14, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 14, Valid Loss: 0.047, Valid Acc: 0.9853\n","Epoch: 15, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 15, Valid Loss: 0.044, Valid Acc: 0.9856\n","Epoch: 16, Train Loss: 0.039, Train Acc: 0.9878\n","Epoch: 16, Valid Loss: 0.043, Valid Acc: 0.9859\n","Epoch: 17, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 17, Valid Loss: 0.042, Valid Acc: 0.9857\n","Epoch: 18, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 18, Valid Loss: 0.045, Valid Acc: 0.9849\n","Epoch: 19, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 19, Valid Loss: 0.041, Valid Acc: 0.9870\n","Epoch: 20, Train Loss: 0.039, Train Acc: 0.9880\n","Epoch: 20, Valid Loss: 0.044, Valid Acc: 0.9863\n","Epoch: 21, Train Loss: 0.040, Train Acc: 0.9874\n","Epoch: 21, Valid Loss: 0.042, Valid Acc: 0.9868\n","Epoch: 22, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 22, Valid Loss: 0.042, Valid Acc: 0.9864\n","Epoch: 23, Train Loss: 0.040, Train Acc: 0.9879\n","Epoch: 23, Valid Loss: 0.043, Valid Acc: 0.9868\n","Epoch: 24, Train Loss: 0.040, Train Acc: 0.9880\n","Epoch: 24, Valid Loss: 0.043, Valid Acc: 0.9867\n","Epoch: 25, Train Loss: 0.039, Train Acc: 0.9875\n","Epoch: 25, Valid Loss: 0.041, Valid Acc: 0.9875\n","Epoch: 26, Train Loss: 0.038, Train Acc: 0.9886\n","Epoch: 26, Valid Loss: 0.042, Valid Acc: 0.9863\n","Epoch: 27, Train Loss: 0.039, Train Acc: 0.9883\n","Epoch: 27, Valid Loss: 0.042, Valid Acc: 0.9862\n","Epoch: 28, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 28, Valid Loss: 0.045, Valid Acc: 0.9856\n","Epoch: 29, Train Loss: 0.038, Train Acc: 0.9885\n","Epoch: 29, Valid Loss: 0.041, Valid Acc: 0.9861\n","Epoch: 30, Train Loss: 0.039, Train Acc: 0.9878\n","Epoch: 30, Valid Loss: 0.043, Valid Acc: 0.9857\n","| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9875  \u001b[0m | \u001b[0m 315.3   \u001b[0m | \u001b[0m 3.336   \u001b[0m |\n","Epoch: 1, Train Loss: 0.722, Train Acc: 0.7843\n","Epoch: 1, Valid Loss: 0.273, Valid Acc: 0.9389\n","Epoch: 2, Train Loss: 0.168, Train Acc: 0.9508\n","Epoch: 2, Valid Loss: 0.140, Valid Acc: 0.9664\n","Epoch: 3, Train Loss: 0.117, Train Acc: 0.9653\n","Epoch: 3, Valid Loss: 0.112, Valid Acc: 0.9727\n","Epoch: 4, Train Loss: 0.092, Train Acc: 0.9721\n","Epoch: 4, Valid Loss: 0.089, Valid Acc: 0.9769\n","Epoch: 5, Train Loss: 0.080, Train Acc: 0.9759\n","Epoch: 5, Valid Loss: 0.077, Valid Acc: 0.9801\n","Epoch: 6, Train Loss: 0.070, Train Acc: 0.9787\n","Epoch: 6, Valid Loss: 0.074, Valid Acc: 0.9806\n","Epoch: 7, Train Loss: 0.064, Train Acc: 0.9799\n","Epoch: 7, Valid Loss: 0.064, Valid Acc: 0.9826\n","Epoch: 8, Train Loss: 0.061, Train Acc: 0.9815\n","Epoch: 8, Valid Loss: 0.059, Valid Acc: 0.9825\n","Epoch: 9, Train Loss: 0.055, Train Acc: 0.9833\n","Epoch: 9, Valid Loss: 0.062, Valid Acc: 0.9823\n","Epoch: 10, Train Loss: 0.052, Train Acc: 0.9837\n","Epoch: 10, Valid Loss: 0.058, Valid Acc: 0.9849\n","Epoch: 11, Train Loss: 0.049, Train Acc: 0.9850\n","Epoch: 11, Valid Loss: 0.055, Valid Acc: 0.9845\n","Epoch: 12, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 12, Valid Loss: 0.059, Valid Acc: 0.9862\n","Epoch: 13, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 13, Valid Loss: 0.058, Valid Acc: 0.9848\n","Epoch: 14, Train Loss: 0.042, Train Acc: 0.9876\n","Epoch: 14, Valid Loss: 0.050, Valid Acc: 0.9857\n","Epoch: 15, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 15, Valid Loss: 0.047, Valid Acc: 0.9867\n","Epoch: 16, Train Loss: 0.040, Train Acc: 0.9880\n","Epoch: 16, Valid Loss: 0.047, Valid Acc: 0.9869\n","Epoch: 17, Train Loss: 0.040, Train Acc: 0.9873\n","Epoch: 17, Valid Loss: 0.051, Valid Acc: 0.9852\n","Epoch: 18, Train Loss: 0.039, Train Acc: 0.9884\n","Epoch: 18, Valid Loss: 0.052, Valid Acc: 0.9866\n","Epoch: 19, Train Loss: 0.039, Train Acc: 0.9881\n","Epoch: 19, Valid Loss: 0.049, Valid Acc: 0.9876\n","Epoch: 20, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 20, Valid Loss: 0.053, Valid Acc: 0.9858\n","Epoch: 21, Train Loss: 0.038, Train Acc: 0.9879\n","Epoch: 21, Valid Loss: 0.051, Valid Acc: 0.9854\n","Epoch: 22, Train Loss: 0.039, Train Acc: 0.9874\n","Epoch: 22, Valid Loss: 0.048, Valid Acc: 0.9873\n","Epoch: 23, Train Loss: 0.037, Train Acc: 0.9884\n","Epoch: 23, Valid Loss: 0.049, Valid Acc: 0.9871\n","Epoch: 24, Train Loss: 0.036, Train Acc: 0.9890\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9883\n","Epoch: 25, Train Loss: 0.037, Train Acc: 0.9881\n","Epoch: 25, Valid Loss: 0.055, Valid Acc: 0.9854\n","Epoch: 26, Train Loss: 0.036, Train Acc: 0.9888\n","Epoch: 26, Valid Loss: 0.052, Valid Acc: 0.9862\n","Epoch: 27, Train Loss: 0.036, Train Acc: 0.9888\n","Epoch: 27, Valid Loss: 0.049, Valid Acc: 0.9861\n","Epoch: 28, Train Loss: 0.036, Train Acc: 0.9887\n","Epoch: 28, Valid Loss: 0.049, Valid Acc: 0.9871\n","Epoch: 29, Train Loss: 0.036, Train Acc: 0.9883\n","Epoch: 29, Valid Loss: 0.049, Valid Acc: 0.9874\n","Epoch: 30, Train Loss: 0.036, Train Acc: 0.9885\n","Epoch: 30, Valid Loss: 0.048, Valid Acc: 0.9873\n","| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9883  \u001b[0m | \u001b[0m 1.97e+03\u001b[0m | \u001b[0m 2.214   \u001b[0m |\n","Epoch: 1, Train Loss: 0.862, Train Acc: 0.7559\n","Epoch: 1, Valid Loss: 0.286, Valid Acc: 0.9280\n","Epoch: 2, Train Loss: 0.199, Train Acc: 0.9405\n","Epoch: 2, Valid Loss: 0.161, Valid Acc: 0.9603\n","Epoch: 3, Train Loss: 0.133, Train Acc: 0.9606\n","Epoch: 3, Valid Loss: 0.117, Valid Acc: 0.9700\n","Epoch: 4, Train Loss: 0.106, Train Acc: 0.9681\n","Epoch: 4, Valid Loss: 0.097, Valid Acc: 0.9745\n","Epoch: 5, Train Loss: 0.091, Train Acc: 0.9728\n","Epoch: 5, Valid Loss: 0.087, Valid Acc: 0.9769\n","Epoch: 6, Train Loss: 0.081, Train Acc: 0.9754\n","Epoch: 6, Valid Loss: 0.075, Valid Acc: 0.9802\n","Epoch: 7, Train Loss: 0.072, Train Acc: 0.9781\n","Epoch: 7, Valid Loss: 0.070, Valid Acc: 0.9814\n","Epoch: 8, Train Loss: 0.067, Train Acc: 0.9801\n","Epoch: 8, Valid Loss: 0.069, Valid Acc: 0.9812\n","Epoch: 9, Train Loss: 0.064, Train Acc: 0.9804\n","Epoch: 9, Valid Loss: 0.068, Valid Acc: 0.9822\n","Epoch: 10, Train Loss: 0.060, Train Acc: 0.9825\n","Epoch: 10, Valid Loss: 0.063, Valid Acc: 0.9835\n","Epoch: 11, Train Loss: 0.057, Train Acc: 0.9830\n","Epoch: 11, Valid Loss: 0.062, Valid Acc: 0.9831\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9839\n","Epoch: 12, Valid Loss: 0.066, Valid Acc: 0.9822\n","Epoch: 13, Train Loss: 0.050, Train Acc: 0.9843\n","Epoch: 13, Valid Loss: 0.054, Valid Acc: 0.9824\n","Epoch: 14, Train Loss: 0.049, Train Acc: 0.9853\n","Epoch: 14, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 15, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 15, Valid Loss: 0.055, Valid Acc: 0.9851\n","Epoch: 16, Train Loss: 0.047, Train Acc: 0.9860\n","Epoch: 16, Valid Loss: 0.057, Valid Acc: 0.9850\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9848\n","Epoch: 17, Valid Loss: 0.059, Valid Acc: 0.9845\n","Epoch: 18, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 18, Valid Loss: 0.054, Valid Acc: 0.9858\n","Epoch: 19, Train Loss: 0.049, Train Acc: 0.9851\n","Epoch: 19, Valid Loss: 0.056, Valid Acc: 0.9853\n","Epoch: 20, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 20, Valid Loss: 0.056, Valid Acc: 0.9844\n","Epoch: 21, Train Loss: 0.046, Train Acc: 0.9865\n","Epoch: 21, Valid Loss: 0.056, Valid Acc: 0.9851\n","Epoch: 22, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 22, Valid Loss: 0.051, Valid Acc: 0.9849\n","Epoch: 23, Train Loss: 0.046, Train Acc: 0.9864\n","Epoch: 23, Valid Loss: 0.050, Valid Acc: 0.9851\n","Epoch: 24, Train Loss: 0.045, Train Acc: 0.9861\n","Epoch: 24, Valid Loss: 0.060, Valid Acc: 0.9839\n","Epoch: 25, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 25, Valid Loss: 0.056, Valid Acc: 0.9852\n","Epoch: 26, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 26, Valid Loss: 0.051, Valid Acc: 0.9859\n","Epoch: 27, Train Loss: 0.044, Train Acc: 0.9871\n","Epoch: 27, Valid Loss: 0.052, Valid Acc: 0.9860\n","Epoch: 28, Train Loss: 0.045, Train Acc: 0.9860\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9864\n","Epoch: 29, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 29, Valid Loss: 0.051, Valid Acc: 0.9867\n","Epoch: 30, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 30, Valid Loss: 0.053, Valid Acc: 0.9845\n","| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9867  \u001b[0m | \u001b[0m 1.379e+0\u001b[0m | \u001b[0m 3.949   \u001b[0m |\n","Epoch: 1, Train Loss: 23.592, Train Acc: 0.1048\n","Epoch: 1, Valid Loss: 2.328, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.324, Train Acc: 0.1115\n","Epoch: 2, Valid Loss: 2.324, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.324, Train Acc: 0.1113\n","Epoch: 3, Valid Loss: 2.323, Valid Acc: 0.1028\n","| \u001b[0m 38      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.683e+0\u001b[0m | \u001b[0m 0.187   \u001b[0m |\n","Epoch: 1, Train Loss: 0.558, Train Acc: 0.8372\n","Epoch: 1, Valid Loss: 0.162, Valid Acc: 0.9544\n","Epoch: 2, Train Loss: 0.132, Train Acc: 0.9591\n","Epoch: 2, Valid Loss: 0.095, Valid Acc: 0.9722\n","Epoch: 3, Train Loss: 0.092, Train Acc: 0.9714\n","Epoch: 3, Valid Loss: 0.077, Valid Acc: 0.9768\n","Epoch: 4, Train Loss: 0.076, Train Acc: 0.9768\n","Epoch: 4, Valid Loss: 0.069, Valid Acc: 0.9790\n","Epoch: 5, Train Loss: 0.066, Train Acc: 0.9797\n","Epoch: 5, Valid Loss: 0.058, Valid Acc: 0.9825\n","Epoch: 6, Train Loss: 0.060, Train Acc: 0.9815\n","Epoch: 6, Valid Loss: 0.060, Valid Acc: 0.9821\n","Epoch: 7, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 7, Valid Loss: 0.048, Valid Acc: 0.9865\n","Epoch: 8, Train Loss: 0.049, Train Acc: 0.9845\n","Epoch: 8, Valid Loss: 0.054, Valid Acc: 0.9823\n","Epoch: 9, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 9, Valid Loss: 0.047, Valid Acc: 0.9851\n","Epoch: 10, Train Loss: 0.043, Train Acc: 0.9868\n","Epoch: 10, Valid Loss: 0.041, Valid Acc: 0.9865\n","Epoch: 11, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 11, Valid Loss: 0.044, Valid Acc: 0.9853\n","Epoch: 12, Train Loss: 0.039, Train Acc: 0.9881\n","Epoch: 12, Valid Loss: 0.044, Valid Acc: 0.9866\n","Epoch: 13, Train Loss: 0.036, Train Acc: 0.9883\n","Epoch: 13, Valid Loss: 0.042, Valid Acc: 0.9869\n","Epoch: 14, Train Loss: 0.036, Train Acc: 0.9888\n","Epoch: 14, Valid Loss: 0.042, Valid Acc: 0.9869\n","Epoch: 15, Train Loss: 0.033, Train Acc: 0.9892\n","Epoch: 15, Valid Loss: 0.041, Valid Acc: 0.9858\n","Epoch: 16, Train Loss: 0.030, Train Acc: 0.9904\n","Epoch: 16, Valid Loss: 0.040, Valid Acc: 0.9879\n","Epoch: 17, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 17, Valid Loss: 0.034, Valid Acc: 0.9894\n","Epoch: 18, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 18, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 19, Train Loss: 0.027, Train Acc: 0.9912\n","Epoch: 19, Valid Loss: 0.041, Valid Acc: 0.9880\n","Epoch: 20, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 20, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 21, Train Loss: 0.027, Train Acc: 0.9917\n","Epoch: 21, Valid Loss: 0.039, Valid Acc: 0.9880\n","Epoch: 22, Train Loss: 0.026, Train Acc: 0.9913\n","Epoch: 22, Valid Loss: 0.040, Valid Acc: 0.9871\n","Epoch: 23, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 23, Valid Loss: 0.041, Valid Acc: 0.9881\n","Epoch: 24, Train Loss: 0.025, Train Acc: 0.9917\n","Epoch: 24, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 25, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 25, Valid Loss: 0.040, Valid Acc: 0.9880\n","Epoch: 26, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 26, Valid Loss: 0.036, Valid Acc: 0.9889\n","Epoch: 27, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 27, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 28, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 28, Valid Loss: 0.038, Valid Acc: 0.9882\n","Epoch: 29, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 29, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 30, Valid Loss: 0.037, Valid Acc: 0.9890\n","| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9894  \u001b[0m | \u001b[0m 1.467e+0\u001b[0m | \u001b[0m 2.236   \u001b[0m |\n","Epoch: 1, Train Loss: 0.497, Train Acc: 0.8464\n","Epoch: 1, Valid Loss: 0.142, Valid Acc: 0.9578\n","Epoch: 2, Train Loss: 0.127, Train Acc: 0.9608\n","Epoch: 2, Valid Loss: 0.095, Valid Acc: 0.9715\n","Epoch: 3, Train Loss: 0.097, Train Acc: 0.9705\n","Epoch: 3, Valid Loss: 0.080, Valid Acc: 0.9752\n","Epoch: 4, Train Loss: 0.083, Train Acc: 0.9747\n","Epoch: 4, Valid Loss: 0.080, Valid Acc: 0.9738\n","Epoch: 5, Train Loss: 0.074, Train Acc: 0.9778\n","Epoch: 5, Valid Loss: 0.066, Valid Acc: 0.9791\n","Epoch: 6, Train Loss: 0.067, Train Acc: 0.9794\n","Epoch: 6, Valid Loss: 0.070, Valid Acc: 0.9789\n","Epoch: 7, Train Loss: 0.061, Train Acc: 0.9813\n","Epoch: 7, Valid Loss: 0.067, Valid Acc: 0.9800\n","Epoch: 8, Train Loss: 0.061, Train Acc: 0.9802\n","Epoch: 8, Valid Loss: 0.057, Valid Acc: 0.9818\n","Epoch: 9, Train Loss: 0.059, Train Acc: 0.9819\n","Epoch: 9, Valid Loss: 0.058, Valid Acc: 0.9807\n","Epoch: 10, Train Loss: 0.056, Train Acc: 0.9827\n","Epoch: 10, Valid Loss: 0.056, Valid Acc: 0.9818\n","Epoch: 11, Train Loss: 0.051, Train Acc: 0.9836\n","Epoch: 11, Valid Loss: 0.062, Valid Acc: 0.9801\n","Epoch: 12, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 12, Valid Loss: 0.049, Valid Acc: 0.9843\n","Epoch: 13, Train Loss: 0.044, Train Acc: 0.9857\n","Epoch: 13, Valid Loss: 0.046, Valid Acc: 0.9855\n","Epoch: 14, Train Loss: 0.041, Train Acc: 0.9873\n","Epoch: 14, Valid Loss: 0.048, Valid Acc: 0.9858\n","Epoch: 15, Train Loss: 0.039, Train Acc: 0.9877\n","Epoch: 15, Valid Loss: 0.050, Valid Acc: 0.9843\n","Epoch: 16, Train Loss: 0.039, Train Acc: 0.9874\n","Epoch: 16, Valid Loss: 0.045, Valid Acc: 0.9856\n","Epoch: 17, Train Loss: 0.039, Train Acc: 0.9876\n","Epoch: 17, Valid Loss: 0.048, Valid Acc: 0.9854\n","Epoch: 18, Train Loss: 0.040, Train Acc: 0.9879\n","Epoch: 18, Valid Loss: 0.048, Valid Acc: 0.9857\n","Epoch: 19, Train Loss: 0.038, Train Acc: 0.9880\n","Epoch: 19, Valid Loss: 0.046, Valid Acc: 0.9866\n","Epoch: 20, Train Loss: 0.037, Train Acc: 0.9883\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9860\n","Epoch: 21, Train Loss: 0.037, Train Acc: 0.9880\n","Epoch: 21, Valid Loss: 0.051, Valid Acc: 0.9847\n","Epoch: 22, Train Loss: 0.038, Train Acc: 0.9880\n","Epoch: 22, Valid Loss: 0.045, Valid Acc: 0.9852\n","Epoch: 23, Train Loss: 0.036, Train Acc: 0.9881\n","Epoch: 23, Valid Loss: 0.043, Valid Acc: 0.9865\n","Epoch: 24, Train Loss: 0.036, Train Acc: 0.9886\n","Epoch: 24, Valid Loss: 0.044, Valid Acc: 0.9872\n","Epoch: 25, Train Loss: 0.035, Train Acc: 0.9891\n","Epoch: 25, Valid Loss: 0.047, Valid Acc: 0.9860\n","Epoch: 26, Train Loss: 0.036, Train Acc: 0.9885\n","Epoch: 26, Valid Loss: 0.046, Valid Acc: 0.9859\n","Epoch: 27, Train Loss: 0.035, Train Acc: 0.9890\n","Epoch: 27, Valid Loss: 0.046, Valid Acc: 0.9861\n","Epoch: 28, Train Loss: 0.035, Train Acc: 0.9884\n","Epoch: 28, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 29, Train Loss: 0.034, Train Acc: 0.9890\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9856\n","Epoch: 30, Train Loss: 0.034, Train Acc: 0.9891\n","Epoch: 30, Valid Loss: 0.041, Valid Acc: 0.9877\n","| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9877  \u001b[0m | \u001b[0m 1.262e+0\u001b[0m | \u001b[0m 2.886   \u001b[0m |\n","Epoch: 1, Train Loss: 1.149, Train Acc: 0.6546\n","Epoch: 1, Valid Loss: 0.515, Valid Acc: 0.8529\n","Epoch: 2, Train Loss: 0.397, Train Acc: 0.8779\n","Epoch: 2, Valid Loss: 0.349, Valid Acc: 0.8994\n","Epoch: 3, Train Loss: 0.328, Train Acc: 0.8991\n","Epoch: 3, Valid Loss: 0.351, Valid Acc: 0.9019\n","Epoch: 4, Train Loss: 0.305, Train Acc: 0.9051\n","Epoch: 4, Valid Loss: 0.321, Valid Acc: 0.9080\n","Epoch: 5, Train Loss: 0.288, Train Acc: 0.9107\n","Epoch: 5, Valid Loss: 0.279, Valid Acc: 0.9190\n","Epoch: 6, Train Loss: 0.255, Train Acc: 0.9215\n","Epoch: 6, Valid Loss: 0.222, Valid Acc: 0.9347\n","Epoch: 7, Train Loss: 0.223, Train Acc: 0.9314\n","Epoch: 7, Valid Loss: 0.225, Valid Acc: 0.9337\n","Epoch: 8, Train Loss: 0.220, Train Acc: 0.9332\n","Epoch: 8, Valid Loss: 0.262, Valid Acc: 0.9231\n","Epoch: 9, Train Loss: 0.223, Train Acc: 0.9317\n","Epoch: 9, Valid Loss: 0.230, Valid Acc: 0.9379\n","Epoch: 10, Train Loss: 0.202, Train Acc: 0.9385\n","Epoch: 10, Valid Loss: 0.227, Valid Acc: 0.9439\n","Epoch: 11, Train Loss: 0.197, Train Acc: 0.9381\n","Epoch: 11, Valid Loss: 0.202, Valid Acc: 0.9421\n","Epoch: 12, Train Loss: 0.197, Train Acc: 0.9396\n","Epoch: 12, Valid Loss: 0.209, Valid Acc: 0.9415\n","Epoch: 13, Train Loss: 0.202, Train Acc: 0.9382\n","Epoch: 13, Valid Loss: 0.225, Valid Acc: 0.9407\n","Epoch: 14, Train Loss: 0.183, Train Acc: 0.9447\n","Epoch: 14, Valid Loss: 0.193, Valid Acc: 0.9460\n","Epoch: 15, Train Loss: 0.172, Train Acc: 0.9476\n","Epoch: 15, Valid Loss: 0.189, Valid Acc: 0.9512\n","Epoch: 16, Train Loss: 0.166, Train Acc: 0.9492\n","Epoch: 16, Valid Loss: 0.177, Valid Acc: 0.9530\n","| \u001b[0m 41      \u001b[0m | \u001b[0m 0.953   \u001b[0m | \u001b[0m 1.221e+0\u001b[0m | \u001b[0m 1.189   \u001b[0m |\n","Epoch: 1, Train Loss: 2.377, Train Acc: 0.0994\n","Epoch: 1, Valid Loss: 2.376, Valid Acc: 0.1022\n","Epoch: 2, Train Loss: 2.375, Train Acc: 0.1015\n","Epoch: 2, Valid Loss: 2.379, Valid Acc: 0.0984\n","Epoch: 3, Train Loss: 2.378, Train Acc: 0.0974\n","Epoch: 3, Valid Loss: 2.377, Valid Acc: 0.0983\n","| \u001b[0m 42      \u001b[0m | \u001b[0m 0.1022  \u001b[0m | \u001b[0m 1.7e+03 \u001b[0m | \u001b[0m 4.0     \u001b[0m |\n","Epoch: 1, Train Loss: 683.081, Train Acc: 0.1017\n","Epoch: 1, Valid Loss: 2.482, Valid Acc: 0.1009\n","Epoch: 2, Train Loss: 2.339, Train Acc: 0.1069\n","Epoch: 2, Valid Loss: 2.479, Valid Acc: 0.0974\n","Epoch: 3, Train Loss: 2.339, Train Acc: 0.1072\n","Epoch: 3, Valid Loss: 2.478, Valid Acc: 0.1028\n","| \u001b[0m 43      \u001b[0m | \u001b[0m 0.1028  \u001b[0m | \u001b[0m 1.194e+0\u001b[0m | \u001b[0m 0.6048  \u001b[0m |\n","Epoch: 1, Train Loss: 0.824, Train Acc: 0.7576\n","Epoch: 1, Valid Loss: 0.318, Valid Acc: 0.9175\n","Epoch: 2, Train Loss: 0.219, Train Acc: 0.9349\n","Epoch: 2, Valid Loss: 0.174, Valid Acc: 0.9560\n","Epoch: 3, Train Loss: 0.148, Train Acc: 0.9571\n","Epoch: 3, Valid Loss: 0.139, Valid Acc: 0.9641\n","Epoch: 4, Train Loss: 0.119, Train Acc: 0.9639\n","Epoch: 4, Valid Loss: 0.108, Valid Acc: 0.9715\n","Epoch: 5, Train Loss: 0.100, Train Acc: 0.9702\n","Epoch: 5, Valid Loss: 0.098, Valid Acc: 0.9749\n","Epoch: 6, Train Loss: 0.089, Train Acc: 0.9731\n","Epoch: 6, Valid Loss: 0.085, Valid Acc: 0.9779\n","Epoch: 7, Train Loss: 0.079, Train Acc: 0.9760\n","Epoch: 7, Valid Loss: 0.079, Valid Acc: 0.9787\n","Epoch: 8, Train Loss: 0.073, Train Acc: 0.9779\n","Epoch: 8, Valid Loss: 0.072, Valid Acc: 0.9817\n","Epoch: 9, Train Loss: 0.068, Train Acc: 0.9793\n","Epoch: 9, Valid Loss: 0.070, Valid Acc: 0.9804\n","Epoch: 10, Train Loss: 0.064, Train Acc: 0.9808\n","Epoch: 10, Valid Loss: 0.067, Valid Acc: 0.9817\n","Epoch: 11, Train Loss: 0.061, Train Acc: 0.9817\n","Epoch: 11, Valid Loss: 0.064, Valid Acc: 0.9817\n","Epoch: 12, Train Loss: 0.059, Train Acc: 0.9825\n","Epoch: 12, Valid Loss: 0.063, Valid Acc: 0.9825\n","Epoch: 13, Train Loss: 0.056, Train Acc: 0.9833\n","Epoch: 13, Valid Loss: 0.058, Valid Acc: 0.9825\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9850\n","Epoch: 14, Valid Loss: 0.058, Valid Acc: 0.9845\n","Epoch: 15, Train Loss: 0.050, Train Acc: 0.9843\n","Epoch: 15, Valid Loss: 0.058, Valid Acc: 0.9840\n","Epoch: 16, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 16, Valid Loss: 0.056, Valid Acc: 0.9868\n","Epoch: 17, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 17, Valid Loss: 0.058, Valid Acc: 0.9844\n","Epoch: 18, Train Loss: 0.049, Train Acc: 0.9851\n","Epoch: 18, Valid Loss: 0.053, Valid Acc: 0.9845\n","Epoch: 19, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 19, Valid Loss: 0.053, Valid Acc: 0.9853\n","Epoch: 20, Train Loss: 0.050, Train Acc: 0.9851\n","Epoch: 20, Valid Loss: 0.056, Valid Acc: 0.9847\n","Epoch: 21, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 21, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 22, Train Loss: 0.047, Train Acc: 0.9850\n","Epoch: 22, Valid Loss: 0.058, Valid Acc: 0.9834\n","Epoch: 23, Train Loss: 0.048, Train Acc: 0.9850\n","Epoch: 23, Valid Loss: 0.055, Valid Acc: 0.9850\n","Epoch: 24, Train Loss: 0.047, Train Acc: 0.9851\n","Epoch: 24, Valid Loss: 0.060, Valid Acc: 0.9839\n","Epoch: 25, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 25, Valid Loss: 0.052, Valid Acc: 0.9857\n","Epoch: 26, Train Loss: 0.046, Train Acc: 0.9862\n","Epoch: 26, Valid Loss: 0.050, Valid Acc: 0.9858\n","Epoch: 27, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 27, Valid Loss: 0.054, Valid Acc: 0.9857\n","Epoch: 28, Train Loss: 0.047, Train Acc: 0.9852\n","Epoch: 28, Valid Loss: 0.055, Valid Acc: 0.9848\n","Epoch: 29, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 29, Valid Loss: 0.054, Valid Acc: 0.9838\n","Epoch: 30, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 30, Valid Loss: 0.052, Valid Acc: 0.9853\n","| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 1.206e+0\u001b[0m | \u001b[0m 3.751   \u001b[0m |\n","Epoch: 1, Train Loss: 7.836, Train Acc: 0.1133\n","Epoch: 1, Valid Loss: 2.446, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.311, Train Acc: 0.1111\n","Epoch: 2, Valid Loss: 2.446, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.311, Train Acc: 0.1112\n","Epoch: 3, Valid Loss: 2.446, Valid Acc: 0.1135\n","| \u001b[0m 45      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.182e+0\u001b[0m | \u001b[0m 1.933   \u001b[0m |\n","Epoch: 1, Train Loss: 801.546, Train Acc: 0.1068\n","Epoch: 1, Valid Loss: 2.340, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.338, Train Acc: 0.1084\n","Epoch: 2, Valid Loss: 2.336, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.336, Train Acc: 0.1064\n","Epoch: 3, Valid Loss: 2.334, Valid Acc: 0.1028\n","| \u001b[0m 46      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.267e+0\u001b[0m | \u001b[0m 0.8502  \u001b[0m |\n","Epoch: 1, Train Loss: 0.248, Train Acc: 0.9236\n","Epoch: 1, Valid Loss: 0.105, Valid Acc: 0.9679\n","Epoch: 2, Train Loss: 0.102, Train Acc: 0.9682\n","Epoch: 2, Valid Loss: 0.100, Valid Acc: 0.9705\n","Epoch: 3, Train Loss: 0.085, Train Acc: 0.9739\n","Epoch: 3, Valid Loss: 0.076, Valid Acc: 0.9762\n","Epoch: 4, Train Loss: 0.076, Train Acc: 0.9761\n","Epoch: 4, Valid Loss: 0.070, Valid Acc: 0.9777\n","Epoch: 5, Train Loss: 0.075, Train Acc: 0.9761\n","Epoch: 5, Valid Loss: 0.070, Valid Acc: 0.9793\n","Epoch: 6, Train Loss: 0.070, Train Acc: 0.9781\n","Epoch: 6, Valid Loss: 0.064, Valid Acc: 0.9794\n","Epoch: 7, Train Loss: 0.069, Train Acc: 0.9781\n","Epoch: 7, Valid Loss: 0.068, Valid Acc: 0.9788\n","Epoch: 8, Train Loss: 0.064, Train Acc: 0.9801\n","Epoch: 8, Valid Loss: 0.064, Valid Acc: 0.9817\n","Epoch: 9, Train Loss: 0.064, Train Acc: 0.9791\n","Epoch: 9, Valid Loss: 0.075, Valid Acc: 0.9787\n","Epoch: 10, Train Loss: 0.051, Train Acc: 0.9839\n","Epoch: 10, Valid Loss: 0.055, Valid Acc: 0.9821\n","Epoch: 11, Train Loss: 0.044, Train Acc: 0.9861\n","Epoch: 11, Valid Loss: 0.052, Valid Acc: 0.9836\n","Epoch: 12, Train Loss: 0.039, Train Acc: 0.9873\n","Epoch: 12, Valid Loss: 0.055, Valid Acc: 0.9828\n","Epoch: 13, Train Loss: 0.039, Train Acc: 0.9877\n","Epoch: 13, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 14, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 14, Valid Loss: 0.044, Valid Acc: 0.9860\n","Epoch: 15, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 15, Valid Loss: 0.045, Valid Acc: 0.9866\n","Epoch: 16, Train Loss: 0.035, Train Acc: 0.9886\n","Epoch: 16, Valid Loss: 0.052, Valid Acc: 0.9847\n","Epoch: 17, Train Loss: 0.035, Train Acc: 0.9890\n","Epoch: 17, Valid Loss: 0.051, Valid Acc: 0.9838\n","Epoch: 18, Train Loss: 0.034, Train Acc: 0.9889\n","Epoch: 18, Valid Loss: 0.048, Valid Acc: 0.9848\n","Epoch: 19, Train Loss: 0.034, Train Acc: 0.9890\n","Epoch: 19, Valid Loss: 0.051, Valid Acc: 0.9847\n","Epoch: 20, Train Loss: 0.032, Train Acc: 0.9897\n","Epoch: 20, Valid Loss: 0.050, Valid Acc: 0.9859\n","Epoch: 21, Train Loss: 0.031, Train Acc: 0.9902\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9864\n","Epoch: 22, Train Loss: 0.033, Train Acc: 0.9898\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9842\n","Epoch: 23, Train Loss: 0.032, Train Acc: 0.9895\n","Epoch: 23, Valid Loss: 0.048, Valid Acc: 0.9857\n","Epoch: 24, Train Loss: 0.033, Train Acc: 0.9893\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9859\n","Epoch: 25, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 25, Valid Loss: 0.045, Valid Acc: 0.9874\n","Epoch: 26, Train Loss: 0.031, Train Acc: 0.9899\n","Epoch: 26, Valid Loss: 0.045, Valid Acc: 0.9862\n","Epoch: 27, Train Loss: 0.030, Train Acc: 0.9905\n","Epoch: 27, Valid Loss: 0.052, Valid Acc: 0.9857\n","Epoch: 28, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 28, Valid Loss: 0.053, Valid Acc: 0.9848\n","Epoch: 29, Train Loss: 0.028, Train Acc: 0.9907\n","Epoch: 29, Valid Loss: 0.045, Valid Acc: 0.9869\n","Epoch: 30, Train Loss: 0.028, Train Acc: 0.9903\n","Epoch: 30, Valid Loss: 0.052, Valid Acc: 0.9862\n","| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 311.6   \u001b[0m | \u001b[0m 2.927   \u001b[0m |\n","Epoch: 1, Train Loss: 1.035, Train Acc: 0.6973\n","Epoch: 1, Valid Loss: 0.375, Valid Acc: 0.8890\n","Epoch: 2, Train Loss: 0.296, Train Acc: 0.9119\n","Epoch: 2, Valid Loss: 0.211, Valid Acc: 0.9392\n","Epoch: 3, Train Loss: 0.191, Train Acc: 0.9436\n","Epoch: 3, Valid Loss: 0.159, Valid Acc: 0.9561\n","Epoch: 4, Train Loss: 0.152, Train Acc: 0.9554\n","Epoch: 4, Valid Loss: 0.121, Valid Acc: 0.9656\n","Epoch: 5, Train Loss: 0.127, Train Acc: 0.9618\n","Epoch: 5, Valid Loss: 0.106, Valid Acc: 0.9680\n","Epoch: 6, Train Loss: 0.110, Train Acc: 0.9664\n","Epoch: 6, Valid Loss: 0.096, Valid Acc: 0.9706\n","Epoch: 7, Train Loss: 0.101, Train Acc: 0.9704\n","Epoch: 7, Valid Loss: 0.087, Valid Acc: 0.9750\n","Epoch: 8, Train Loss: 0.093, Train Acc: 0.9716\n","Epoch: 8, Valid Loss: 0.078, Valid Acc: 0.9762\n","Epoch: 9, Train Loss: 0.084, Train Acc: 0.9745\n","Epoch: 9, Valid Loss: 0.079, Valid Acc: 0.9759\n","Epoch: 10, Train Loss: 0.079, Train Acc: 0.9768\n","Epoch: 10, Valid Loss: 0.070, Valid Acc: 0.9791\n","Epoch: 11, Train Loss: 0.075, Train Acc: 0.9774\n","Epoch: 11, Valid Loss: 0.067, Valid Acc: 0.9794\n","Epoch: 12, Train Loss: 0.072, Train Acc: 0.9783\n","Epoch: 12, Valid Loss: 0.065, Valid Acc: 0.9798\n","Epoch: 13, Train Loss: 0.068, Train Acc: 0.9790\n","Epoch: 13, Valid Loss: 0.065, Valid Acc: 0.9806\n","Epoch: 14, Train Loss: 0.065, Train Acc: 0.9805\n","Epoch: 14, Valid Loss: 0.062, Valid Acc: 0.9807\n","Epoch: 15, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 15, Valid Loss: 0.059, Valid Acc: 0.9825\n","Epoch: 16, Train Loss: 0.060, Train Acc: 0.9813\n","Epoch: 16, Valid Loss: 0.053, Valid Acc: 0.9827\n","Epoch: 17, Train Loss: 0.059, Train Acc: 0.9821\n","Epoch: 17, Valid Loss: 0.058, Valid Acc: 0.9820\n","Epoch: 18, Train Loss: 0.057, Train Acc: 0.9824\n","Epoch: 18, Valid Loss: 0.053, Valid Acc: 0.9838\n","Epoch: 19, Train Loss: 0.055, Train Acc: 0.9837\n","Epoch: 19, Valid Loss: 0.053, Valid Acc: 0.9829\n","Epoch: 20, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 20, Valid Loss: 0.055, Valid Acc: 0.9828\n","Epoch: 21, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 21, Valid Loss: 0.052, Valid Acc: 0.9825\n","Epoch: 22, Train Loss: 0.052, Train Acc: 0.9842\n","Epoch: 22, Valid Loss: 0.054, Valid Acc: 0.9832\n","Epoch: 23, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 23, Valid Loss: 0.051, Valid Acc: 0.9837\n","Epoch: 24, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 24, Valid Loss: 0.054, Valid Acc: 0.9823\n","Epoch: 25, Train Loss: 0.050, Train Acc: 0.9845\n","Epoch: 25, Valid Loss: 0.051, Valid Acc: 0.9839\n","Epoch: 26, Train Loss: 0.052, Train Acc: 0.9845\n","Epoch: 26, Valid Loss: 0.053, Valid Acc: 0.9834\n","Epoch: 27, Train Loss: 0.051, Train Acc: 0.9850\n","Epoch: 27, Valid Loss: 0.055, Valid Acc: 0.9824\n","Epoch: 28, Train Loss: 0.050, Train Acc: 0.9850\n","Epoch: 28, Valid Loss: 0.053, Valid Acc: 0.9833\n","Epoch: 29, Train Loss: 0.050, Train Acc: 0.9842\n","Epoch: 29, Valid Loss: 0.053, Valid Acc: 0.9829\n","Epoch: 30, Train Loss: 0.050, Train Acc: 0.9843\n","Epoch: 30, Valid Loss: 0.052, Valid Acc: 0.9841\n","| \u001b[0m 48      \u001b[0m | \u001b[0m 0.9841  \u001b[0m | \u001b[0m 1.258e+0\u001b[0m | \u001b[0m 2.048   \u001b[0m |\n","Epoch: 1, Train Loss: 2348.089, Train Acc: 0.1022\n","Epoch: 1, Valid Loss: 2.539, Valid Acc: 0.1010\n","Epoch: 2, Train Loss: 2.379, Train Acc: 0.1039\n","Epoch: 2, Valid Loss: 2.534, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.322, Train Acc: 0.1067\n","Epoch: 3, Valid Loss: 2.532, Valid Acc: 0.1135\n","| \u001b[0m 49      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.375e+0\u001b[0m | \u001b[0m 0.9175  \u001b[0m |\n","Epoch: 1, Train Loss: 0.944, Train Acc: 0.7261\n","Epoch: 1, Valid Loss: 0.373, Valid Acc: 0.9052\n","Epoch: 2, Train Loss: 0.250, Train Acc: 0.9263\n","Epoch: 2, Valid Loss: 0.204, Valid Acc: 0.9478\n","Epoch: 3, Train Loss: 0.165, Train Acc: 0.9509\n","Epoch: 3, Valid Loss: 0.154, Valid Acc: 0.9614\n","Epoch: 4, Train Loss: 0.130, Train Acc: 0.9610\n","Epoch: 4, Valid Loss: 0.126, Valid Acc: 0.9673\n","Epoch: 5, Train Loss: 0.113, Train Acc: 0.9659\n","Epoch: 5, Valid Loss: 0.109, Valid Acc: 0.9730\n","Epoch: 6, Train Loss: 0.098, Train Acc: 0.9704\n","Epoch: 6, Valid Loss: 0.101, Valid Acc: 0.9737\n","Epoch: 7, Train Loss: 0.089, Train Acc: 0.9737\n","Epoch: 7, Valid Loss: 0.091, Valid Acc: 0.9751\n","Epoch: 8, Train Loss: 0.082, Train Acc: 0.9756\n","Epoch: 8, Valid Loss: 0.087, Valid Acc: 0.9784\n","Epoch: 9, Train Loss: 0.077, Train Acc: 0.9765\n","Epoch: 9, Valid Loss: 0.081, Valid Acc: 0.9789\n","Epoch: 10, Train Loss: 0.072, Train Acc: 0.9783\n","Epoch: 10, Valid Loss: 0.074, Valid Acc: 0.9813\n","Epoch: 11, Train Loss: 0.066, Train Acc: 0.9800\n","Epoch: 11, Valid Loss: 0.068, Valid Acc: 0.9814\n","Epoch: 12, Train Loss: 0.063, Train Acc: 0.9811\n","Epoch: 12, Valid Loss: 0.070, Valid Acc: 0.9815\n","Epoch: 13, Train Loss: 0.060, Train Acc: 0.9825\n","Epoch: 13, Valid Loss: 0.069, Valid Acc: 0.9821\n","Epoch: 14, Train Loss: 0.058, Train Acc: 0.9825\n","Epoch: 14, Valid Loss: 0.062, Valid Acc: 0.9828\n","Epoch: 15, Train Loss: 0.056, Train Acc: 0.9832\n","Epoch: 15, Valid Loss: 0.063, Valid Acc: 0.9836\n","Epoch: 16, Train Loss: 0.052, Train Acc: 0.9842\n","Epoch: 16, Valid Loss: 0.064, Valid Acc: 0.9827\n","Epoch: 17, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 17, Valid Loss: 0.057, Valid Acc: 0.9854\n","Epoch: 18, Train Loss: 0.050, Train Acc: 0.9848\n","Epoch: 18, Valid Loss: 0.058, Valid Acc: 0.9853\n","Epoch: 19, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 19, Valid Loss: 0.061, Valid Acc: 0.9843\n","Epoch: 20, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 20, Valid Loss: 0.055, Valid Acc: 0.9840\n","Epoch: 21, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 21, Valid Loss: 0.057, Valid Acc: 0.9852\n","Epoch: 22, Train Loss: 0.045, Train Acc: 0.9868\n","Epoch: 22, Valid Loss: 0.053, Valid Acc: 0.9860\n","Epoch: 23, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 23, Valid Loss: 0.051, Valid Acc: 0.9858\n","Epoch: 24, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 24, Valid Loss: 0.057, Valid Acc: 0.9853\n","Epoch: 25, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 25, Valid Loss: 0.055, Valid Acc: 0.9857\n","Epoch: 26, Train Loss: 0.044, Train Acc: 0.9862\n","Epoch: 26, Valid Loss: 0.053, Valid Acc: 0.9865\n","Epoch: 27, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 27, Valid Loss: 0.054, Valid Acc: 0.9855\n","Epoch: 28, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 29, Train Loss: 0.043, Train Acc: 0.9867\n","Epoch: 29, Valid Loss: 0.056, Valid Acc: 0.9853\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 30, Valid Loss: 0.057, Valid Acc: 0.9853\n","| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 1.383e+0\u001b[0m | \u001b[0m 3.661   \u001b[0m |\n","Epoch: 1, Train Loss: 1.822, Train Acc: 0.4495\n","Epoch: 1, Valid Loss: 1.393, Valid Acc: 0.6854\n","Epoch: 2, Train Loss: 0.843, Train Acc: 0.7565\n","Epoch: 2, Valid Loss: 0.703, Valid Acc: 0.8328\n","Epoch: 3, Train Loss: 0.490, Train Acc: 0.8535\n","Epoch: 3, Valid Loss: 0.491, Valid Acc: 0.8827\n","Epoch: 4, Train Loss: 0.360, Train Acc: 0.8940\n","Epoch: 4, Valid Loss: 0.384, Valid Acc: 0.9140\n","Epoch: 5, Train Loss: 0.291, Train Acc: 0.9135\n","Epoch: 5, Valid Loss: 0.322, Valid Acc: 0.9277\n","Epoch: 6, Train Loss: 0.247, Train Acc: 0.9290\n","Epoch: 6, Valid Loss: 0.277, Valid Acc: 0.9372\n","Epoch: 7, Train Loss: 0.216, Train Acc: 0.9380\n","Epoch: 7, Valid Loss: 0.240, Valid Acc: 0.9484\n","Epoch: 8, Train Loss: 0.193, Train Acc: 0.9442\n","Epoch: 8, Valid Loss: 0.234, Valid Acc: 0.9505\n","Epoch: 9, Train Loss: 0.176, Train Acc: 0.9490\n","Epoch: 9, Valid Loss: 0.199, Valid Acc: 0.9544\n","Epoch: 10, Train Loss: 0.162, Train Acc: 0.9527\n","Epoch: 10, Valid Loss: 0.189, Valid Acc: 0.9585\n","Epoch: 11, Train Loss: 0.152, Train Acc: 0.9558\n","Epoch: 11, Valid Loss: 0.163, Valid Acc: 0.9621\n","Epoch: 12, Train Loss: 0.143, Train Acc: 0.9584\n","Epoch: 12, Valid Loss: 0.153, Valid Acc: 0.9644\n","Epoch: 13, Train Loss: 0.135, Train Acc: 0.9598\n","Epoch: 13, Valid Loss: 0.157, Valid Acc: 0.9648\n","Epoch: 14, Train Loss: 0.129, Train Acc: 0.9621\n","Epoch: 14, Valid Loss: 0.143, Valid Acc: 0.9675\n","Epoch: 15, Train Loss: 0.124, Train Acc: 0.9634\n","Epoch: 15, Valid Loss: 0.132, Valid Acc: 0.9675\n","Epoch: 16, Train Loss: 0.117, Train Acc: 0.9656\n","Epoch: 16, Valid Loss: 0.131, Valid Acc: 0.9682\n","| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9682  \u001b[0m | \u001b[0m 1.974e+0\u001b[0m | \u001b[0m 3.218   \u001b[0m |\n","Epoch: 1, Train Loss: 1114.562, Train Acc: 0.1028\n","Epoch: 1, Valid Loss: 2.376, Valid Acc: 0.0974\n","Epoch: 2, Train Loss: 2.317, Train Acc: 0.1086\n","Epoch: 2, Valid Loss: 2.371, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.316, Train Acc: 0.1073\n","Epoch: 3, Valid Loss: 2.372, Valid Acc: 0.1135\n","| \u001b[0m 52      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.472e+0\u001b[0m | \u001b[0m 0.7215  \u001b[0m |\n","Epoch: 1, Train Loss: 0.566, Train Acc: 0.8290\n","Epoch: 1, Valid Loss: 0.170, Valid Acc: 0.9454\n","Epoch: 2, Train Loss: 0.150, Train Acc: 0.9544\n","Epoch: 2, Valid Loss: 0.117, Valid Acc: 0.9642\n","Epoch: 3, Train Loss: 0.114, Train Acc: 0.9659\n","Epoch: 3, Valid Loss: 0.105, Valid Acc: 0.9679\n","Epoch: 4, Train Loss: 0.112, Train Acc: 0.9655\n","Epoch: 4, Valid Loss: 0.097, Valid Acc: 0.9686\n","Epoch: 5, Train Loss: 0.109, Train Acc: 0.9651\n","Epoch: 5, Valid Loss: 0.080, Valid Acc: 0.9748\n","Epoch: 6, Train Loss: 0.085, Train Acc: 0.9727\n","Epoch: 6, Valid Loss: 0.071, Valid Acc: 0.9777\n","Epoch: 7, Train Loss: 0.076, Train Acc: 0.9762\n","Epoch: 7, Valid Loss: 0.072, Valid Acc: 0.9774\n","Epoch: 8, Train Loss: 0.073, Train Acc: 0.9783\n","Epoch: 8, Valid Loss: 0.089, Valid Acc: 0.9734\n","Epoch: 9, Train Loss: 0.102, Train Acc: 0.9690\n","Epoch: 9, Valid Loss: 0.085, Valid Acc: 0.9760\n","Epoch: 10, Train Loss: 0.083, Train Acc: 0.9763\n","Epoch: 10, Valid Loss: 0.087, Valid Acc: 0.9727\n","Epoch: 11, Train Loss: 0.076, Train Acc: 0.9758\n","Epoch: 11, Valid Loss: 0.068, Valid Acc: 0.9763\n","Epoch: 12, Train Loss: 0.067, Train Acc: 0.9798\n","Epoch: 12, Valid Loss: 0.070, Valid Acc: 0.9787\n","Epoch: 13, Train Loss: 0.063, Train Acc: 0.9801\n","Epoch: 13, Valid Loss: 0.064, Valid Acc: 0.9798\n","Epoch: 14, Train Loss: 0.059, Train Acc: 0.9811\n","Epoch: 14, Valid Loss: 0.062, Valid Acc: 0.9812\n","Epoch: 15, Train Loss: 0.057, Train Acc: 0.9820\n","Epoch: 15, Valid Loss: 0.062, Valid Acc: 0.9804\n","Epoch: 16, Train Loss: 0.062, Train Acc: 0.9810\n","Epoch: 16, Valid Loss: 0.061, Valid Acc: 0.9818\n","Epoch: 17, Train Loss: 0.059, Train Acc: 0.9817\n","Epoch: 17, Valid Loss: 0.065, Valid Acc: 0.9803\n","Epoch: 18, Train Loss: 0.056, Train Acc: 0.9826\n","Epoch: 18, Valid Loss: 0.066, Valid Acc: 0.9809\n","Epoch: 19, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 19, Valid Loss: 0.066, Valid Acc: 0.9816\n","Epoch: 20, Train Loss: 0.056, Train Acc: 0.9825\n","Epoch: 20, Valid Loss: 0.061, Valid Acc: 0.9806\n","Epoch: 21, Train Loss: 0.056, Train Acc: 0.9823\n","Epoch: 21, Valid Loss: 0.059, Valid Acc: 0.9841\n","Epoch: 22, Train Loss: 0.054, Train Acc: 0.9830\n","Epoch: 22, Valid Loss: 0.060, Valid Acc: 0.9819\n","Epoch: 23, Train Loss: 0.054, Train Acc: 0.9828\n","Epoch: 23, Valid Loss: 0.063, Valid Acc: 0.9807\n","Epoch: 24, Train Loss: 0.057, Train Acc: 0.9831\n","Epoch: 24, Valid Loss: 0.061, Valid Acc: 0.9823\n","Epoch: 25, Train Loss: 0.054, Train Acc: 0.9831\n","Epoch: 25, Valid Loss: 0.058, Valid Acc: 0.9826\n","Epoch: 26, Train Loss: 0.055, Train Acc: 0.9829\n","Epoch: 26, Valid Loss: 0.056, Valid Acc: 0.9820\n","Epoch: 27, Train Loss: 0.052, Train Acc: 0.9831\n","Epoch: 27, Valid Loss: 0.059, Valid Acc: 0.9820\n","Epoch: 28, Train Loss: 0.051, Train Acc: 0.9835\n","Epoch: 28, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 29, Train Loss: 0.053, Train Acc: 0.9835\n","Epoch: 29, Valid Loss: 0.057, Valid Acc: 0.9832\n","Epoch: 30, Train Loss: 0.054, Train Acc: 0.9824\n","Epoch: 30, Valid Loss: 0.058, Valid Acc: 0.9816\n","| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9841  \u001b[0m | \u001b[0m 1.464e+0\u001b[0m | \u001b[0m 2.988   \u001b[0m |\n","Epoch: 1, Train Loss: 0.592, Train Acc: 0.8163\n","Epoch: 1, Valid Loss: 0.185, Valid Acc: 0.9544\n","Epoch: 2, Train Loss: 0.127, Train Acc: 0.9611\n","Epoch: 2, Valid Loss: 0.113, Valid Acc: 0.9701\n","Epoch: 3, Train Loss: 0.088, Train Acc: 0.9730\n","Epoch: 3, Valid Loss: 0.083, Valid Acc: 0.9765\n","Epoch: 4, Train Loss: 0.074, Train Acc: 0.9775\n","Epoch: 4, Valid Loss: 0.074, Valid Acc: 0.9827\n","Epoch: 5, Train Loss: 0.064, Train Acc: 0.9799\n","Epoch: 5, Valid Loss: 0.063, Valid Acc: 0.9833\n","Epoch: 6, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 6, Valid Loss: 0.063, Valid Acc: 0.9833\n","Epoch: 7, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 7, Valid Loss: 0.058, Valid Acc: 0.9819\n","Epoch: 8, Train Loss: 0.052, Train Acc: 0.9839\n","Epoch: 8, Valid Loss: 0.055, Valid Acc: 0.9840\n","Epoch: 9, Train Loss: 0.048, Train Acc: 0.9850\n","Epoch: 9, Valid Loss: 0.059, Valid Acc: 0.9842\n","Epoch: 10, Train Loss: 0.045, Train Acc: 0.9856\n","Epoch: 10, Valid Loss: 0.057, Valid Acc: 0.9829\n","Epoch: 11, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 11, Valid Loss: 0.049, Valid Acc: 0.9863\n","Epoch: 12, Train Loss: 0.038, Train Acc: 0.9878\n","Epoch: 12, Valid Loss: 0.054, Valid Acc: 0.9864\n","Epoch: 13, Train Loss: 0.038, Train Acc: 0.9883\n","Epoch: 13, Valid Loss: 0.052, Valid Acc: 0.9872\n","Epoch: 14, Train Loss: 0.036, Train Acc: 0.9892\n","Epoch: 14, Valid Loss: 0.049, Valid Acc: 0.9866\n","Epoch: 15, Train Loss: 0.035, Train Acc: 0.9889\n","Epoch: 15, Valid Loss: 0.048, Valid Acc: 0.9855\n","Epoch: 16, Train Loss: 0.035, Train Acc: 0.9892\n","Epoch: 16, Valid Loss: 0.044, Valid Acc: 0.9875\n","Epoch: 17, Train Loss: 0.036, Train Acc: 0.9886\n","Epoch: 17, Valid Loss: 0.050, Valid Acc: 0.9870\n","Epoch: 18, Train Loss: 0.035, Train Acc: 0.9891\n","Epoch: 18, Valid Loss: 0.044, Valid Acc: 0.9880\n","Epoch: 19, Train Loss: 0.034, Train Acc: 0.9892\n","Epoch: 19, Valid Loss: 0.047, Valid Acc: 0.9857\n","Epoch: 20, Train Loss: 0.033, Train Acc: 0.9896\n","Epoch: 20, Valid Loss: 0.044, Valid Acc: 0.9869\n","Epoch: 21, Train Loss: 0.033, Train Acc: 0.9897\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9860\n","Epoch: 22, Train Loss: 0.033, Train Acc: 0.9896\n","Epoch: 22, Valid Loss: 0.047, Valid Acc: 0.9879\n","Epoch: 23, Train Loss: 0.032, Train Acc: 0.9897\n","Epoch: 23, Valid Loss: 0.050, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.032, Train Acc: 0.9902\n","Epoch: 24, Valid Loss: 0.052, Valid Acc: 0.9867\n","Epoch: 25, Train Loss: 0.033, Train Acc: 0.9898\n","Epoch: 25, Valid Loss: 0.043, Valid Acc: 0.9885\n","Epoch: 26, Train Loss: 0.032, Train Acc: 0.9902\n","Epoch: 26, Valid Loss: 0.048, Valid Acc: 0.9872\n","Epoch: 27, Train Loss: 0.032, Train Acc: 0.9904\n","Epoch: 27, Valid Loss: 0.042, Valid Acc: 0.9879\n","Epoch: 28, Train Loss: 0.031, Train Acc: 0.9903\n","Epoch: 28, Valid Loss: 0.048, Valid Acc: 0.9863\n","Epoch: 29, Train Loss: 0.030, Train Acc: 0.9906\n","Epoch: 29, Valid Loss: 0.047, Valid Acc: 0.9872\n","Epoch: 30, Train Loss: 0.030, Train Acc: 0.9901\n","Epoch: 30, Valid Loss: 0.049, Valid Acc: 0.9878\n","| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 1.966e+0\u001b[0m | \u001b[0m 2.637   \u001b[0m |\n","Epoch: 1, Train Loss: 0.434, Train Acc: 0.8640\n","Epoch: 1, Valid Loss: 0.123, Valid Acc: 0.9694\n","Epoch: 2, Train Loss: 0.102, Train Acc: 0.9694\n","Epoch: 2, Valid Loss: 0.086, Valid Acc: 0.9789\n","Epoch: 3, Train Loss: 0.078, Train Acc: 0.9765\n","Epoch: 3, Valid Loss: 0.071, Valid Acc: 0.9797\n","Epoch: 4, Train Loss: 0.066, Train Acc: 0.9790\n","Epoch: 4, Valid Loss: 0.063, Valid Acc: 0.9816\n","Epoch: 5, Train Loss: 0.059, Train Acc: 0.9817\n","Epoch: 5, Valid Loss: 0.062, Valid Acc: 0.9824\n","Epoch: 6, Train Loss: 0.051, Train Acc: 0.9843\n","Epoch: 6, Valid Loss: 0.057, Valid Acc: 0.9831\n","Epoch: 7, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 7, Valid Loss: 0.049, Valid Acc: 0.9856\n","Epoch: 8, Train Loss: 0.045, Train Acc: 0.9857\n","Epoch: 8, Valid Loss: 0.048, Valid Acc: 0.9858\n","Epoch: 9, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 9, Valid Loss: 0.045, Valid Acc: 0.9874\n","Epoch: 10, Train Loss: 0.039, Train Acc: 0.9876\n","Epoch: 10, Valid Loss: 0.044, Valid Acc: 0.9875\n","Epoch: 11, Train Loss: 0.037, Train Acc: 0.9883\n","Epoch: 11, Valid Loss: 0.048, Valid Acc: 0.9856\n","Epoch: 12, Train Loss: 0.032, Train Acc: 0.9897\n","Epoch: 12, Valid Loss: 0.040, Valid Acc: 0.9874\n","Epoch: 13, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 13, Valid Loss: 0.039, Valid Acc: 0.9886\n","Epoch: 14, Train Loss: 0.029, Train Acc: 0.9905\n","Epoch: 14, Valid Loss: 0.037, Valid Acc: 0.9892\n","Epoch: 15, Train Loss: 0.029, Train Acc: 0.9901\n","Epoch: 15, Valid Loss: 0.042, Valid Acc: 0.9879\n","Epoch: 16, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 16, Valid Loss: 0.038, Valid Acc: 0.9881\n","Epoch: 17, Train Loss: 0.028, Train Acc: 0.9914\n","Epoch: 17, Valid Loss: 0.037, Valid Acc: 0.9886\n","Epoch: 18, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 18, Valid Loss: 0.040, Valid Acc: 0.9871\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 19, Valid Loss: 0.036, Valid Acc: 0.9882\n","Epoch: 20, Train Loss: 0.028, Train Acc: 0.9907\n","Epoch: 20, Valid Loss: 0.037, Valid Acc: 0.9893\n","Epoch: 21, Train Loss: 0.026, Train Acc: 0.9914\n","Epoch: 21, Valid Loss: 0.041, Valid Acc: 0.9875\n","Epoch: 22, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 22, Valid Loss: 0.036, Valid Acc: 0.9896\n","Epoch: 23, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 24, Valid Loss: 0.038, Valid Acc: 0.9880\n","Epoch: 25, Train Loss: 0.025, Train Acc: 0.9918\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9890\n","Epoch: 26, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 26, Valid Loss: 0.042, Valid Acc: 0.9883\n","Epoch: 27, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 27, Valid Loss: 0.039, Valid Acc: 0.9887\n","Epoch: 28, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 28, Valid Loss: 0.035, Valid Acc: 0.9883\n","Epoch: 29, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 29, Valid Loss: 0.038, Valid Acc: 0.9890\n","Epoch: 30, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 30, Valid Loss: 0.037, Valid Acc: 0.9886\n","| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9896  \u001b[0m | \u001b[0m 1.225e+0\u001b[0m | \u001b[0m 2.334   \u001b[0m |\n","Epoch: 1, Train Loss: 0.977, Train Acc: 0.7210\n","Epoch: 1, Valid Loss: 0.369, Valid Acc: 0.9009\n","Epoch: 2, Train Loss: 0.249, Train Acc: 0.9264\n","Epoch: 2, Valid Loss: 0.201, Valid Acc: 0.9479\n","Epoch: 3, Train Loss: 0.162, Train Acc: 0.9526\n","Epoch: 3, Valid Loss: 0.146, Valid Acc: 0.9629\n","Epoch: 4, Train Loss: 0.127, Train Acc: 0.9621\n","Epoch: 4, Valid Loss: 0.118, Valid Acc: 0.9693\n","Epoch: 5, Train Loss: 0.105, Train Acc: 0.9683\n","Epoch: 5, Valid Loss: 0.101, Valid Acc: 0.9731\n","Epoch: 6, Train Loss: 0.093, Train Acc: 0.9729\n","Epoch: 6, Valid Loss: 0.089, Valid Acc: 0.9773\n","Epoch: 7, Train Loss: 0.084, Train Acc: 0.9745\n","Epoch: 7, Valid Loss: 0.087, Valid Acc: 0.9769\n","Epoch: 8, Train Loss: 0.078, Train Acc: 0.9762\n","Epoch: 8, Valid Loss: 0.076, Valid Acc: 0.9800\n","Epoch: 9, Train Loss: 0.072, Train Acc: 0.9783\n","Epoch: 9, Valid Loss: 0.072, Valid Acc: 0.9807\n","Epoch: 10, Train Loss: 0.067, Train Acc: 0.9798\n","Epoch: 10, Valid Loss: 0.068, Valid Acc: 0.9804\n","Epoch: 11, Train Loss: 0.062, Train Acc: 0.9813\n","Epoch: 11, Valid Loss: 0.068, Valid Acc: 0.9821\n","Epoch: 12, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 12, Valid Loss: 0.065, Valid Acc: 0.9828\n","Epoch: 13, Train Loss: 0.057, Train Acc: 0.9825\n","Epoch: 13, Valid Loss: 0.063, Valid Acc: 0.9829\n","Epoch: 14, Train Loss: 0.054, Train Acc: 0.9831\n","Epoch: 14, Valid Loss: 0.057, Valid Acc: 0.9840\n","Epoch: 15, Train Loss: 0.052, Train Acc: 0.9840\n","Epoch: 15, Valid Loss: 0.060, Valid Acc: 0.9839\n","Epoch: 16, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 16, Valid Loss: 0.057, Valid Acc: 0.9853\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9849\n","Epoch: 17, Valid Loss: 0.053, Valid Acc: 0.9860\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9857\n","Epoch: 18, Valid Loss: 0.051, Valid Acc: 0.9852\n","Epoch: 19, Train Loss: 0.044, Train Acc: 0.9869\n","Epoch: 19, Valid Loss: 0.051, Valid Acc: 0.9872\n","Epoch: 20, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 20, Valid Loss: 0.053, Valid Acc: 0.9848\n","Epoch: 21, Train Loss: 0.044, Train Acc: 0.9864\n","Epoch: 21, Valid Loss: 0.050, Valid Acc: 0.9857\n","Epoch: 22, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9862\n","Epoch: 23, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 23, Valid Loss: 0.051, Valid Acc: 0.9867\n","Epoch: 24, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 24, Valid Loss: 0.049, Valid Acc: 0.9866\n","Epoch: 25, Train Loss: 0.042, Train Acc: 0.9871\n","Epoch: 25, Valid Loss: 0.052, Valid Acc: 0.9851\n","Epoch: 26, Train Loss: 0.042, Train Acc: 0.9871\n","Epoch: 26, Valid Loss: 0.056, Valid Acc: 0.9845\n","Epoch: 27, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 27, Valid Loss: 0.050, Valid Acc: 0.9859\n","Epoch: 28, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 28, Valid Loss: 0.051, Valid Acc: 0.9855\n","Epoch: 29, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 29, Valid Loss: 0.047, Valid Acc: 0.9873\n","Epoch: 30, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 30, Valid Loss: 0.053, Valid Acc: 0.9848\n","| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9873  \u001b[0m | \u001b[0m 1.366e+0\u001b[0m | \u001b[0m 3.649   \u001b[0m |\n","Epoch: 1, Train Loss: 1.226, Train Acc: 0.6538\n","Epoch: 1, Valid Loss: 0.480, Valid Acc: 0.8563\n","Epoch: 2, Train Loss: 0.365, Train Acc: 0.8919\n","Epoch: 2, Valid Loss: 0.259, Valid Acc: 0.9241\n","Epoch: 3, Train Loss: 0.233, Train Acc: 0.9321\n","Epoch: 3, Valid Loss: 0.182, Valid Acc: 0.9481\n","Epoch: 4, Train Loss: 0.178, Train Acc: 0.9483\n","Epoch: 4, Valid Loss: 0.145, Valid Acc: 0.9591\n","Epoch: 5, Train Loss: 0.152, Train Acc: 0.9564\n","Epoch: 5, Valid Loss: 0.124, Valid Acc: 0.9638\n","Epoch: 6, Train Loss: 0.131, Train Acc: 0.9611\n","Epoch: 6, Valid Loss: 0.114, Valid Acc: 0.9660\n","Epoch: 7, Train Loss: 0.119, Train Acc: 0.9652\n","Epoch: 7, Valid Loss: 0.102, Valid Acc: 0.9693\n","Epoch: 8, Train Loss: 0.107, Train Acc: 0.9682\n","Epoch: 8, Valid Loss: 0.096, Valid Acc: 0.9712\n","Epoch: 9, Train Loss: 0.101, Train Acc: 0.9701\n","Epoch: 9, Valid Loss: 0.087, Valid Acc: 0.9729\n","Epoch: 10, Train Loss: 0.092, Train Acc: 0.9728\n","Epoch: 10, Valid Loss: 0.081, Valid Acc: 0.9762\n","Epoch: 11, Train Loss: 0.087, Train Acc: 0.9737\n","Epoch: 11, Valid Loss: 0.078, Valid Acc: 0.9767\n","Epoch: 12, Train Loss: 0.084, Train Acc: 0.9746\n","Epoch: 12, Valid Loss: 0.073, Valid Acc: 0.9786\n","Epoch: 13, Train Loss: 0.079, Train Acc: 0.9755\n","Epoch: 13, Valid Loss: 0.071, Valid Acc: 0.9785\n","Epoch: 14, Train Loss: 0.078, Train Acc: 0.9767\n","Epoch: 14, Valid Loss: 0.074, Valid Acc: 0.9773\n","Epoch: 15, Train Loss: 0.074, Train Acc: 0.9771\n","Epoch: 15, Valid Loss: 0.068, Valid Acc: 0.9793\n","Epoch: 16, Train Loss: 0.071, Train Acc: 0.9786\n","Epoch: 16, Valid Loss: 0.066, Valid Acc: 0.9789\n","Epoch: 17, Train Loss: 0.070, Train Acc: 0.9791\n","Epoch: 17, Valid Loss: 0.062, Valid Acc: 0.9818\n","Epoch: 18, Train Loss: 0.065, Train Acc: 0.9806\n","Epoch: 18, Valid Loss: 0.060, Valid Acc: 0.9808\n","Epoch: 19, Train Loss: 0.066, Train Acc: 0.9798\n","Epoch: 19, Valid Loss: 0.063, Valid Acc: 0.9810\n","Epoch: 20, Train Loss: 0.067, Train Acc: 0.9798\n","Epoch: 20, Valid Loss: 0.062, Valid Acc: 0.9806\n","Epoch: 21, Train Loss: 0.068, Train Acc: 0.9803\n","Epoch: 21, Valid Loss: 0.060, Valid Acc: 0.9823\n","Epoch: 22, Train Loss: 0.066, Train Acc: 0.9797\n","Epoch: 22, Valid Loss: 0.062, Valid Acc: 0.9809\n","Epoch: 23, Train Loss: 0.065, Train Acc: 0.9800\n","Epoch: 23, Valid Loss: 0.062, Valid Acc: 0.9814\n","Epoch: 24, Train Loss: 0.065, Train Acc: 0.9804\n","Epoch: 24, Valid Loss: 0.062, Valid Acc: 0.9799\n","Epoch: 25, Train Loss: 0.066, Train Acc: 0.9808\n","Epoch: 25, Valid Loss: 0.061, Valid Acc: 0.9809\n","Epoch: 26, Train Loss: 0.066, Train Acc: 0.9802\n","Epoch: 26, Valid Loss: 0.062, Valid Acc: 0.9807\n","Epoch: 27, Train Loss: 0.064, Train Acc: 0.9801\n","Epoch: 27, Valid Loss: 0.059, Valid Acc: 0.9814\n","Epoch: 28, Train Loss: 0.064, Train Acc: 0.9801\n","Epoch: 28, Valid Loss: 0.059, Valid Acc: 0.9803\n","Epoch: 29, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 29, Valid Loss: 0.058, Valid Acc: 0.9824\n","Epoch: 30, Train Loss: 0.063, Train Acc: 0.9812\n","Epoch: 30, Valid Loss: 0.059, Valid Acc: 0.9808\n","| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9824  \u001b[0m | \u001b[0m 1.275e+0\u001b[0m | \u001b[0m 3.352   \u001b[0m |\n","Epoch: 1, Train Loss: 1.067, Train Acc: 0.6871\n","Epoch: 1, Valid Loss: 0.394, Valid Acc: 0.8855\n","Epoch: 2, Train Loss: 0.308, Train Acc: 0.9069\n","Epoch: 2, Valid Loss: 0.225, Valid Acc: 0.9370\n","Epoch: 3, Train Loss: 0.205, Train Acc: 0.9394\n","Epoch: 3, Valid Loss: 0.164, Valid Acc: 0.9526\n","Epoch: 4, Train Loss: 0.162, Train Acc: 0.9518\n","Epoch: 4, Valid Loss: 0.138, Valid Acc: 0.9590\n","Epoch: 5, Train Loss: 0.134, Train Acc: 0.9596\n","Epoch: 5, Valid Loss: 0.119, Valid Acc: 0.9644\n","Epoch: 6, Train Loss: 0.118, Train Acc: 0.9652\n","Epoch: 6, Valid Loss: 0.099, Valid Acc: 0.9718\n","Epoch: 7, Train Loss: 0.109, Train Acc: 0.9673\n","Epoch: 7, Valid Loss: 0.097, Valid Acc: 0.9702\n","Epoch: 8, Train Loss: 0.098, Train Acc: 0.9708\n","Epoch: 8, Valid Loss: 0.085, Valid Acc: 0.9748\n","Epoch: 9, Train Loss: 0.091, Train Acc: 0.9728\n","Epoch: 9, Valid Loss: 0.077, Valid Acc: 0.9772\n","Epoch: 10, Train Loss: 0.084, Train Acc: 0.9747\n","Epoch: 10, Valid Loss: 0.074, Valid Acc: 0.9784\n","Epoch: 11, Train Loss: 0.080, Train Acc: 0.9760\n","Epoch: 11, Valid Loss: 0.071, Valid Acc: 0.9773\n","Epoch: 12, Train Loss: 0.076, Train Acc: 0.9772\n","Epoch: 12, Valid Loss: 0.070, Valid Acc: 0.9786\n","Epoch: 13, Train Loss: 0.072, Train Acc: 0.9785\n","Epoch: 13, Valid Loss: 0.067, Valid Acc: 0.9780\n","Epoch: 14, Train Loss: 0.068, Train Acc: 0.9798\n","Epoch: 14, Valid Loss: 0.065, Valid Acc: 0.9813\n","Epoch: 15, Train Loss: 0.066, Train Acc: 0.9799\n","Epoch: 15, Valid Loss: 0.062, Valid Acc: 0.9816\n","Epoch: 16, Train Loss: 0.064, Train Acc: 0.9808\n","Epoch: 16, Valid Loss: 0.058, Valid Acc: 0.9814\n","Epoch: 17, Train Loss: 0.060, Train Acc: 0.9819\n","Epoch: 17, Valid Loss: 0.058, Valid Acc: 0.9820\n","Epoch: 18, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 18, Valid Loss: 0.059, Valid Acc: 0.9830\n","Epoch: 19, Train Loss: 0.058, Train Acc: 0.9832\n","Epoch: 19, Valid Loss: 0.055, Valid Acc: 0.9843\n","Epoch: 20, Train Loss: 0.059, Train Acc: 0.9817\n","Epoch: 20, Valid Loss: 0.056, Valid Acc: 0.9842\n","Epoch: 21, Train Loss: 0.058, Train Acc: 0.9819\n","Epoch: 21, Valid Loss: 0.055, Valid Acc: 0.9830\n","Epoch: 22, Train Loss: 0.057, Train Acc: 0.9830\n","Epoch: 22, Valid Loss: 0.056, Valid Acc: 0.9823\n","Epoch: 23, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 23, Valid Loss: 0.056, Valid Acc: 0.9818\n","Epoch: 24, Train Loss: 0.058, Train Acc: 0.9822\n","Epoch: 24, Valid Loss: 0.055, Valid Acc: 0.9836\n","Epoch: 25, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 25, Valid Loss: 0.059, Valid Acc: 0.9806\n","Epoch: 26, Train Loss: 0.058, Train Acc: 0.9825\n","Epoch: 26, Valid Loss: 0.056, Valid Acc: 0.9826\n","Epoch: 27, Train Loss: 0.058, Train Acc: 0.9822\n","Epoch: 27, Valid Loss: 0.054, Valid Acc: 0.9828\n","Epoch: 28, Train Loss: 0.056, Train Acc: 0.9827\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9812\n","Epoch: 29, Train Loss: 0.057, Train Acc: 0.9824\n","Epoch: 29, Valid Loss: 0.057, Valid Acc: 0.9815\n","Epoch: 30, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 30, Valid Loss: 0.056, Valid Acc: 0.9826\n","| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9843  \u001b[0m | \u001b[0m 1.48e+03\u001b[0m | \u001b[0m 3.576   \u001b[0m |\n","Epoch: 1, Train Loss: 2.861, Train Acc: 0.3857\n","Epoch: 1, Valid Loss: 1.507, Valid Acc: 0.5622\n","Epoch: 2, Train Loss: 1.309, Train Acc: 0.5792\n","Epoch: 2, Valid Loss: 1.272, Valid Acc: 0.6374\n","Epoch: 3, Train Loss: 1.028, Train Acc: 0.6777\n","Epoch: 3, Valid Loss: 0.856, Valid Acc: 0.7564\n","Epoch: 4, Train Loss: 0.849, Train Acc: 0.7402\n","Epoch: 4, Valid Loss: 0.715, Valid Acc: 0.8114\n","Epoch: 5, Train Loss: 0.516, Train Acc: 0.8422\n","Epoch: 5, Valid Loss: 0.496, Valid Acc: 0.8752\n","Epoch: 6, Train Loss: 0.374, Train Acc: 0.8874\n","Epoch: 6, Valid Loss: 0.321, Valid Acc: 0.9085\n","Epoch: 7, Train Loss: 0.283, Train Acc: 0.9143\n","Epoch: 7, Valid Loss: 0.248, Valid Acc: 0.9288\n","Epoch: 8, Train Loss: 0.241, Train Acc: 0.9264\n","Epoch: 8, Valid Loss: 0.238, Valid Acc: 0.9337\n","Epoch: 9, Train Loss: 0.221, Train Acc: 0.9345\n","Epoch: 9, Valid Loss: 0.221, Valid Acc: 0.9454\n","Epoch: 10, Train Loss: 0.213, Train Acc: 0.9357\n","Epoch: 10, Valid Loss: 0.222, Valid Acc: 0.9431\n","Epoch: 11, Train Loss: 0.203, Train Acc: 0.9388\n","Epoch: 11, Valid Loss: 0.216, Valid Acc: 0.9451\n","Epoch: 12, Train Loss: 0.207, Train Acc: 0.9382\n","Epoch: 12, Valid Loss: 0.222, Valid Acc: 0.9358\n","Epoch: 13, Train Loss: 0.177, Train Acc: 0.9455\n","Epoch: 13, Valid Loss: 0.170, Valid Acc: 0.9511\n","Epoch: 14, Train Loss: 0.162, Train Acc: 0.9498\n","Epoch: 14, Valid Loss: 0.161, Valid Acc: 0.9551\n","Epoch: 15, Train Loss: 0.156, Train Acc: 0.9516\n","Epoch: 15, Valid Loss: 0.151, Valid Acc: 0.9559\n","Epoch: 16, Train Loss: 0.157, Train Acc: 0.9537\n","Epoch: 16, Valid Loss: 0.157, Valid Acc: 0.9558\n","| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9559  \u001b[0m | \u001b[0m 1.247e+0\u001b[0m | \u001b[0m 1.399   \u001b[0m |\n","Epoch: 1, Train Loss: 1.604, Train Acc: 0.5802\n","Epoch: 1, Valid Loss: 0.887, Valid Acc: 0.7333\n","Epoch: 2, Train Loss: 0.756, Train Acc: 0.7599\n","Epoch: 2, Valid Loss: 0.711, Valid Acc: 0.7915\n","Epoch: 3, Train Loss: 0.666, Train Acc: 0.7896\n","Epoch: 3, Valid Loss: 0.655, Valid Acc: 0.8158\n","Epoch: 4, Train Loss: 0.626, Train Acc: 0.8035\n","Epoch: 4, Valid Loss: 0.635, Valid Acc: 0.8193\n","Epoch: 5, Train Loss: 0.584, Train Acc: 0.8181\n","Epoch: 5, Valid Loss: 0.609, Valid Acc: 0.8231\n","Epoch: 6, Train Loss: 0.563, Train Acc: 0.8257\n","Epoch: 6, Valid Loss: 0.574, Valid Acc: 0.8410\n","Epoch: 7, Train Loss: 0.524, Train Acc: 0.8369\n","Epoch: 7, Valid Loss: 0.572, Valid Acc: 0.8357\n","Epoch: 8, Train Loss: 0.478, Train Acc: 0.8492\n","Epoch: 8, Valid Loss: 0.492, Valid Acc: 0.8665\n","Epoch: 9, Train Loss: 0.415, Train Acc: 0.8705\n","Epoch: 9, Valid Loss: 0.449, Valid Acc: 0.8756\n","Epoch: 10, Train Loss: 0.379, Train Acc: 0.8827\n","Epoch: 10, Valid Loss: 0.396, Valid Acc: 0.8917\n","Epoch: 11, Train Loss: 0.364, Train Acc: 0.8890\n","Epoch: 11, Valid Loss: 0.376, Valid Acc: 0.8969\n","Epoch: 12, Train Loss: 0.365, Train Acc: 0.8883\n","Epoch: 12, Valid Loss: 0.384, Valid Acc: 0.8926\n","Epoch: 13, Train Loss: 0.334, Train Acc: 0.8979\n","Epoch: 13, Valid Loss: 0.334, Valid Acc: 0.9070\n","Epoch: 14, Train Loss: 0.280, Train Acc: 0.9163\n","Epoch: 14, Valid Loss: 0.283, Valid Acc: 0.9281\n","Epoch: 15, Train Loss: 0.251, Train Acc: 0.9235\n","Epoch: 15, Valid Loss: 0.257, Valid Acc: 0.9322\n","Epoch: 16, Train Loss: 0.226, Train Acc: 0.9311\n","Epoch: 16, Valid Loss: 0.252, Valid Acc: 0.9332\n","| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9332  \u001b[0m | \u001b[0m 1.204e+0\u001b[0m | \u001b[0m 0.02824 \u001b[0m |\n","Epoch: 1, Train Loss: 42.912, Train Acc: 0.1085\n","Epoch: 1, Valid Loss: 2.557, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.320, Train Acc: 0.1113\n","Epoch: 2, Valid Loss: 2.556, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.320, Train Acc: 0.1096\n","Epoch: 3, Valid Loss: 2.557, Valid Acc: 0.1135\n","| \u001b[0m 61      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.234e+0\u001b[0m | \u001b[0m 0.1895  \u001b[0m |\n","Epoch: 1, Train Loss: 0.798, Train Acc: 0.7585\n","Epoch: 1, Valid Loss: 0.289, Valid Acc: 0.9278\n","Epoch: 2, Train Loss: 0.203, Train Acc: 0.9412\n","Epoch: 2, Valid Loss: 0.165, Valid Acc: 0.9602\n","Epoch: 3, Train Loss: 0.138, Train Acc: 0.9601\n","Epoch: 3, Valid Loss: 0.127, Valid Acc: 0.9684\n","Epoch: 4, Train Loss: 0.111, Train Acc: 0.9669\n","Epoch: 4, Valid Loss: 0.108, Valid Acc: 0.9734\n","Epoch: 5, Train Loss: 0.095, Train Acc: 0.9716\n","Epoch: 5, Valid Loss: 0.092, Valid Acc: 0.9762\n","Epoch: 6, Train Loss: 0.085, Train Acc: 0.9751\n","Epoch: 6, Valid Loss: 0.077, Valid Acc: 0.9815\n","Epoch: 7, Train Loss: 0.075, Train Acc: 0.9777\n","Epoch: 7, Valid Loss: 0.077, Valid Acc: 0.9796\n","Epoch: 8, Train Loss: 0.071, Train Acc: 0.9786\n","Epoch: 8, Valid Loss: 0.069, Valid Acc: 0.9821\n","Epoch: 9, Train Loss: 0.066, Train Acc: 0.9793\n","Epoch: 9, Valid Loss: 0.067, Valid Acc: 0.9825\n","Epoch: 10, Train Loss: 0.059, Train Acc: 0.9821\n","Epoch: 10, Valid Loss: 0.066, Valid Acc: 0.9815\n","Epoch: 11, Train Loss: 0.059, Train Acc: 0.9828\n","Epoch: 11, Valid Loss: 0.061, Valid Acc: 0.9842\n","Epoch: 12, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 12, Valid Loss: 0.061, Valid Acc: 0.9825\n","Epoch: 13, Train Loss: 0.052, Train Acc: 0.9850\n","Epoch: 13, Valid Loss: 0.055, Valid Acc: 0.9833\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 14, Valid Loss: 0.056, Valid Acc: 0.9840\n","Epoch: 15, Train Loss: 0.051, Train Acc: 0.9840\n","Epoch: 15, Valid Loss: 0.056, Valid Acc: 0.9833\n","Epoch: 16, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 16, Valid Loss: 0.055, Valid Acc: 0.9845\n","Epoch: 17, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 17, Valid Loss: 0.054, Valid Acc: 0.9838\n","Epoch: 18, Train Loss: 0.051, Train Acc: 0.9849\n","Epoch: 18, Valid Loss: 0.057, Valid Acc: 0.9841\n","Epoch: 19, Train Loss: 0.049, Train Acc: 0.9855\n","Epoch: 19, Valid Loss: 0.054, Valid Acc: 0.9855\n","Epoch: 20, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 20, Valid Loss: 0.057, Valid Acc: 0.9845\n","Epoch: 21, Train Loss: 0.047, Train Acc: 0.9856\n","Epoch: 21, Valid Loss: 0.057, Valid Acc: 0.9840\n","Epoch: 22, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 22, Valid Loss: 0.056, Valid Acc: 0.9853\n","Epoch: 23, Train Loss: 0.047, Train Acc: 0.9861\n","Epoch: 23, Valid Loss: 0.056, Valid Acc: 0.9842\n","Epoch: 24, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 24, Valid Loss: 0.054, Valid Acc: 0.9847\n","Epoch: 25, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 25, Valid Loss: 0.059, Valid Acc: 0.9843\n","Epoch: 26, Train Loss: 0.049, Train Acc: 0.9850\n","Epoch: 26, Valid Loss: 0.053, Valid Acc: 0.9854\n","Epoch: 27, Train Loss: 0.046, Train Acc: 0.9863\n","Epoch: 27, Valid Loss: 0.055, Valid Acc: 0.9849\n","Epoch: 28, Train Loss: 0.046, Train Acc: 0.9863\n","Epoch: 28, Valid Loss: 0.053, Valid Acc: 0.9844\n","Epoch: 29, Train Loss: 0.045, Train Acc: 0.9861\n","Epoch: 29, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 30, Train Loss: 0.046, Train Acc: 0.9860\n","Epoch: 30, Valid Loss: 0.050, Valid Acc: 0.9842\n","| \u001b[0m 62      \u001b[0m | \u001b[0m 0.9855  \u001b[0m | \u001b[0m 1.216e+0\u001b[0m | \u001b[0m 3.87    \u001b[0m |\n","Epoch: 1, Train Loss: 0.399, Train Acc: 0.8798\n","Epoch: 1, Valid Loss: 0.127, Valid Acc: 0.9650\n","Epoch: 2, Train Loss: 0.114, Train Acc: 0.9652\n","Epoch: 2, Valid Loss: 0.088, Valid Acc: 0.9738\n","Epoch: 3, Train Loss: 0.085, Train Acc: 0.9740\n","Epoch: 3, Valid Loss: 0.077, Valid Acc: 0.9766\n","Epoch: 4, Train Loss: 0.072, Train Acc: 0.9779\n","Epoch: 4, Valid Loss: 0.067, Valid Acc: 0.9789\n","Epoch: 5, Train Loss: 0.063, Train Acc: 0.9810\n","Epoch: 5, Valid Loss: 0.055, Valid Acc: 0.9837\n","Epoch: 6, Train Loss: 0.057, Train Acc: 0.9822\n","Epoch: 6, Valid Loss: 0.051, Valid Acc: 0.9852\n","Epoch: 7, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 7, Valid Loss: 0.051, Valid Acc: 0.9840\n","Epoch: 8, Train Loss: 0.049, Train Acc: 0.9846\n","Epoch: 8, Valid Loss: 0.047, Valid Acc: 0.9846\n","Epoch: 9, Train Loss: 0.047, Train Acc: 0.9856\n","Epoch: 9, Valid Loss: 0.047, Valid Acc: 0.9847\n","Epoch: 10, Train Loss: 0.043, Train Acc: 0.9863\n","Epoch: 10, Valid Loss: 0.044, Valid Acc: 0.9867\n","Epoch: 11, Train Loss: 0.042, Train Acc: 0.9861\n","Epoch: 11, Valid Loss: 0.048, Valid Acc: 0.9835\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9885\n","Epoch: 12, Valid Loss: 0.042, Valid Acc: 0.9867\n","Epoch: 13, Train Loss: 0.035, Train Acc: 0.9888\n","Epoch: 13, Valid Loss: 0.040, Valid Acc: 0.9876\n","Epoch: 14, Train Loss: 0.034, Train Acc: 0.9893\n","Epoch: 14, Valid Loss: 0.037, Valid Acc: 0.9889\n","Epoch: 15, Train Loss: 0.034, Train Acc: 0.9897\n","Epoch: 15, Valid Loss: 0.044, Valid Acc: 0.9862\n","Epoch: 16, Train Loss: 0.034, Train Acc: 0.9894\n","Epoch: 16, Valid Loss: 0.045, Valid Acc: 0.9864\n","Epoch: 17, Train Loss: 0.033, Train Acc: 0.9899\n","Epoch: 17, Valid Loss: 0.042, Valid Acc: 0.9867\n","Epoch: 18, Train Loss: 0.032, Train Acc: 0.9899\n","Epoch: 18, Valid Loss: 0.043, Valid Acc: 0.9875\n","Epoch: 19, Train Loss: 0.033, Train Acc: 0.9896\n","Epoch: 19, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 20, Train Loss: 0.031, Train Acc: 0.9904\n","Epoch: 20, Valid Loss: 0.038, Valid Acc: 0.9870\n","Epoch: 21, Train Loss: 0.032, Train Acc: 0.9901\n","Epoch: 21, Valid Loss: 0.042, Valid Acc: 0.9865\n","Epoch: 22, Train Loss: 0.032, Train Acc: 0.9899\n","Epoch: 22, Valid Loss: 0.041, Valid Acc: 0.9871\n","Epoch: 23, Train Loss: 0.030, Train Acc: 0.9903\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9874\n","Epoch: 24, Train Loss: 0.030, Train Acc: 0.9907\n","Epoch: 24, Valid Loss: 0.039, Valid Acc: 0.9877\n","Epoch: 25, Train Loss: 0.031, Train Acc: 0.9903\n","Epoch: 25, Valid Loss: 0.042, Valid Acc: 0.9880\n","Epoch: 26, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 26, Valid Loss: 0.040, Valid Acc: 0.9888\n","Epoch: 27, Train Loss: 0.030, Train Acc: 0.9907\n","Epoch: 27, Valid Loss: 0.042, Valid Acc: 0.9864\n","Epoch: 28, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 28, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 29, Train Loss: 0.030, Train Acc: 0.9908\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9853\n","Epoch: 30, Train Loss: 0.029, Train Acc: 0.9909\n","Epoch: 30, Valid Loss: 0.038, Valid Acc: 0.9873\n","| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9889  \u001b[0m | \u001b[0m 353.6   \u001b[0m | \u001b[0m 3.796   \u001b[0m |\n","Epoch: 1, Train Loss: 2.366, Train Acc: 0.0954\n","Epoch: 1, Valid Loss: 2.370, Valid Acc: 0.0916\n","Epoch: 2, Train Loss: 2.367, Train Acc: 0.0955\n","Epoch: 2, Valid Loss: 2.370, Valid Acc: 0.0941\n","Epoch: 3, Train Loss: 2.367, Train Acc: 0.0953\n","Epoch: 3, Valid Loss: 2.366, Valid Acc: 0.0939\n","| \u001b[0m 64      \u001b[0m | \u001b[0m 0.0941  \u001b[0m | \u001b[0m 1.669e+0\u001b[0m | \u001b[0m 4.0     \u001b[0m |\n","Epoch: 1, Train Loss: 4.248, Train Acc: 0.1066\n","Epoch: 1, Valid Loss: 2.370, Valid Acc: 0.1032\n","Epoch: 2, Train Loss: 2.319, Train Acc: 0.1073\n","Epoch: 2, Valid Loss: 2.373, Valid Acc: 0.0980\n","Epoch: 3, Train Loss: 2.318, Train Acc: 0.1073\n","Epoch: 3, Valid Loss: 2.381, Valid Acc: 0.1010\n","| \u001b[0m 65      \u001b[0m | \u001b[0m 0.1032  \u001b[0m | \u001b[0m 355.4   \u001b[0m | \u001b[0m 0.1218  \u001b[0m |\n","Epoch: 1, Train Loss: 15.781, Train Acc: 0.1045\n","Epoch: 1, Valid Loss: 2.341, Valid Acc: 0.0982\n","Epoch: 2, Train Loss: 2.319, Train Acc: 0.1033\n","Epoch: 2, Valid Loss: 2.342, Valid Acc: 0.0982\n","Epoch: 3, Train Loss: 2.318, Train Acc: 0.1052\n","Epoch: 3, Valid Loss: 2.343, Valid Acc: 0.0982\n","| \u001b[0m 66      \u001b[0m | \u001b[0m 0.0982  \u001b[0m | \u001b[0m 317.7   \u001b[0m | \u001b[0m 0.2915  \u001b[0m |\n","Epoch: 1, Train Loss: 0.647, Train Acc: 0.8108\n","Epoch: 1, Valid Loss: 0.223, Valid Acc: 0.9433\n","Epoch: 2, Train Loss: 0.160, Train Acc: 0.9529\n","Epoch: 2, Valid Loss: 0.133, Valid Acc: 0.9654\n","Epoch: 3, Train Loss: 0.109, Train Acc: 0.9670\n","Epoch: 3, Valid Loss: 0.103, Valid Acc: 0.9732\n","Epoch: 4, Train Loss: 0.092, Train Acc: 0.9722\n","Epoch: 4, Valid Loss: 0.090, Valid Acc: 0.9761\n","Epoch: 5, Train Loss: 0.079, Train Acc: 0.9757\n","Epoch: 5, Valid Loss: 0.076, Valid Acc: 0.9801\n","Epoch: 6, Train Loss: 0.069, Train Acc: 0.9795\n","Epoch: 6, Valid Loss: 0.076, Valid Acc: 0.9800\n","Epoch: 7, Train Loss: 0.067, Train Acc: 0.9796\n","Epoch: 7, Valid Loss: 0.068, Valid Acc: 0.9816\n","Epoch: 8, Train Loss: 0.058, Train Acc: 0.9822\n","Epoch: 8, Valid Loss: 0.062, Valid Acc: 0.9829\n","Epoch: 9, Train Loss: 0.055, Train Acc: 0.9833\n","Epoch: 9, Valid Loss: 0.058, Valid Acc: 0.9838\n","Epoch: 10, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 10, Valid Loss: 0.056, Valid Acc: 0.9851\n","Epoch: 11, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 11, Valid Loss: 0.060, Valid Acc: 0.9839\n","Epoch: 12, Train Loss: 0.047, Train Acc: 0.9853\n","Epoch: 12, Valid Loss: 0.056, Valid Acc: 0.9842\n","Epoch: 13, Train Loss: 0.047, Train Acc: 0.9853\n","Epoch: 13, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 14, Train Loss: 0.043, Train Acc: 0.9868\n","Epoch: 14, Valid Loss: 0.053, Valid Acc: 0.9867\n","Epoch: 15, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9859\n","Epoch: 16, Train Loss: 0.040, Train Acc: 0.9873\n","Epoch: 16, Valid Loss: 0.049, Valid Acc: 0.9856\n","Epoch: 17, Train Loss: 0.036, Train Acc: 0.9887\n","Epoch: 17, Valid Loss: 0.046, Valid Acc: 0.9880\n","Epoch: 18, Train Loss: 0.035, Train Acc: 0.9890\n","Epoch: 18, Valid Loss: 0.043, Valid Acc: 0.9867\n","Epoch: 19, Train Loss: 0.034, Train Acc: 0.9891\n","Epoch: 19, Valid Loss: 0.045, Valid Acc: 0.9889\n","Epoch: 20, Train Loss: 0.033, Train Acc: 0.9900\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9869\n","Epoch: 21, Train Loss: 0.034, Train Acc: 0.9892\n","Epoch: 21, Valid Loss: 0.044, Valid Acc: 0.9891\n","Epoch: 22, Train Loss: 0.033, Train Acc: 0.9899\n","Epoch: 22, Valid Loss: 0.051, Valid Acc: 0.9868\n","Epoch: 23, Train Loss: 0.033, Train Acc: 0.9894\n","Epoch: 23, Valid Loss: 0.044, Valid Acc: 0.9896\n","Epoch: 24, Train Loss: 0.034, Train Acc: 0.9891\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9893\n","Epoch: 25, Train Loss: 0.033, Train Acc: 0.9896\n","Epoch: 25, Valid Loss: 0.044, Valid Acc: 0.9886\n","Epoch: 26, Train Loss: 0.032, Train Acc: 0.9900\n","Epoch: 26, Valid Loss: 0.044, Valid Acc: 0.9887\n","Epoch: 27, Train Loss: 0.032, Train Acc: 0.9900\n","Epoch: 27, Valid Loss: 0.043, Valid Acc: 0.9886\n","Epoch: 28, Train Loss: 0.031, Train Acc: 0.9901\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9877\n","Epoch: 29, Train Loss: 0.031, Train Acc: 0.9907\n","Epoch: 29, Valid Loss: 0.048, Valid Acc: 0.9876\n","Epoch: 30, Train Loss: 0.033, Train Acc: 0.9897\n","Epoch: 30, Valid Loss: 0.044, Valid Acc: 0.9876\n","| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9896  \u001b[0m | \u001b[0m 1.208e+0\u001b[0m | \u001b[0m 1.013   \u001b[0m |\n","Epoch: 1, Train Loss: 77.634, Train Acc: 0.1044\n","Epoch: 1, Valid Loss: 2.522, Valid Acc: 0.0958\n","Epoch: 2, Train Loss: 2.309, Train Acc: 0.1088\n","Epoch: 2, Valid Loss: 2.517, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.309, Train Acc: 0.1084\n","Epoch: 3, Valid Loss: 2.521, Valid Acc: 0.1010\n","| \u001b[0m 68      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.367e+0\u001b[0m | \u001b[0m 0.2756  \u001b[0m |\n","Epoch: 1, Train Loss: 0.887, Train Acc: 0.7366\n","Epoch: 1, Valid Loss: 0.342, Valid Acc: 0.9080\n","Epoch: 2, Train Loss: 0.238, Train Acc: 0.9288\n","Epoch: 2, Valid Loss: 0.192, Valid Acc: 0.9495\n","Epoch: 3, Train Loss: 0.156, Train Acc: 0.9542\n","Epoch: 3, Valid Loss: 0.135, Valid Acc: 0.9654\n","Epoch: 4, Train Loss: 0.122, Train Acc: 0.9635\n","Epoch: 4, Valid Loss: 0.113, Valid Acc: 0.9701\n","Epoch: 5, Train Loss: 0.103, Train Acc: 0.9687\n","Epoch: 5, Valid Loss: 0.102, Valid Acc: 0.9732\n","Epoch: 6, Train Loss: 0.094, Train Acc: 0.9711\n","Epoch: 6, Valid Loss: 0.097, Valid Acc: 0.9757\n","Epoch: 7, Train Loss: 0.084, Train Acc: 0.9745\n","Epoch: 7, Valid Loss: 0.084, Valid Acc: 0.9792\n","Epoch: 8, Train Loss: 0.077, Train Acc: 0.9772\n","Epoch: 8, Valid Loss: 0.080, Valid Acc: 0.9806\n","Epoch: 9, Train Loss: 0.071, Train Acc: 0.9787\n","Epoch: 9, Valid Loss: 0.074, Valid Acc: 0.9802\n","Epoch: 10, Train Loss: 0.067, Train Acc: 0.9797\n","Epoch: 10, Valid Loss: 0.073, Valid Acc: 0.9809\n","Epoch: 11, Train Loss: 0.064, Train Acc: 0.9802\n","Epoch: 11, Valid Loss: 0.070, Valid Acc: 0.9800\n","Epoch: 12, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 12, Valid Loss: 0.065, Valid Acc: 0.9819\n","Epoch: 13, Train Loss: 0.059, Train Acc: 0.9819\n","Epoch: 13, Valid Loss: 0.066, Valid Acc: 0.9817\n","Epoch: 14, Train Loss: 0.059, Train Acc: 0.9822\n","Epoch: 14, Valid Loss: 0.063, Valid Acc: 0.9819\n","Epoch: 15, Train Loss: 0.058, Train Acc: 0.9814\n","Epoch: 15, Valid Loss: 0.063, Valid Acc: 0.9823\n","Epoch: 16, Train Loss: 0.057, Train Acc: 0.9824\n","Epoch: 16, Valid Loss: 0.064, Valid Acc: 0.9832\n","Epoch: 17, Train Loss: 0.058, Train Acc: 0.9821\n","Epoch: 17, Valid Loss: 0.064, Valid Acc: 0.9831\n","Epoch: 18, Train Loss: 0.056, Train Acc: 0.9832\n","Epoch: 18, Valid Loss: 0.066, Valid Acc: 0.9822\n","Epoch: 19, Train Loss: 0.056, Train Acc: 0.9831\n","Epoch: 19, Valid Loss: 0.066, Valid Acc: 0.9812\n","Epoch: 20, Train Loss: 0.056, Train Acc: 0.9833\n","Epoch: 20, Valid Loss: 0.063, Valid Acc: 0.9830\n","Epoch: 21, Train Loss: 0.056, Train Acc: 0.9822\n","Epoch: 21, Valid Loss: 0.061, Valid Acc: 0.9841\n","Epoch: 22, Train Loss: 0.054, Train Acc: 0.9834\n","Epoch: 22, Valid Loss: 0.061, Valid Acc: 0.9835\n","Epoch: 23, Train Loss: 0.055, Train Acc: 0.9829\n","Epoch: 23, Valid Loss: 0.063, Valid Acc: 0.9817\n","Epoch: 24, Train Loss: 0.055, Train Acc: 0.9829\n","Epoch: 24, Valid Loss: 0.062, Valid Acc: 0.9827\n","Epoch: 25, Train Loss: 0.053, Train Acc: 0.9832\n","Epoch: 25, Valid Loss: 0.061, Valid Acc: 0.9825\n","Epoch: 26, Train Loss: 0.055, Train Acc: 0.9831\n","Epoch: 26, Valid Loss: 0.062, Valid Acc: 0.9826\n","Epoch: 27, Train Loss: 0.053, Train Acc: 0.9841\n","Epoch: 27, Valid Loss: 0.062, Valid Acc: 0.9835\n","Epoch: 28, Train Loss: 0.053, Train Acc: 0.9840\n","Epoch: 28, Valid Loss: 0.064, Valid Acc: 0.9834\n","Epoch: 29, Train Loss: 0.053, Train Acc: 0.9838\n","Epoch: 29, Valid Loss: 0.060, Valid Acc: 0.9832\n","Epoch: 30, Train Loss: 0.052, Train Acc: 0.9836\n","Epoch: 30, Valid Loss: 0.063, Valid Acc: 0.9825\n","| \u001b[0m 69      \u001b[0m | \u001b[0m 0.9841  \u001b[0m | \u001b[0m 1.203e+0\u001b[0m | \u001b[0m 3.708   \u001b[0m |\n","Epoch: 1, Train Loss: 1117.948, Train Acc: 0.0989\n","Epoch: 1, Valid Loss: 2.526, Valid Acc: 0.0980\n","Epoch: 2, Train Loss: 2.336, Train Acc: 0.1078\n","Epoch: 2, Valid Loss: 2.522, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.341, Train Acc: 0.1042\n","Epoch: 3, Valid Loss: 2.527, Valid Acc: 0.0980\n","| \u001b[0m 70      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.216e+0\u001b[0m | \u001b[0m 0.7599  \u001b[0m |\n","Epoch: 1, Train Loss: 0.849, Train Acc: 0.7435\n","Epoch: 1, Valid Loss: 0.316, Valid Acc: 0.9196\n","Epoch: 2, Train Loss: 0.228, Train Acc: 0.9319\n","Epoch: 2, Valid Loss: 0.184, Valid Acc: 0.9526\n","Epoch: 3, Train Loss: 0.150, Train Acc: 0.9552\n","Epoch: 3, Valid Loss: 0.131, Valid Acc: 0.9657\n","Epoch: 4, Train Loss: 0.119, Train Acc: 0.9647\n","Epoch: 4, Valid Loss: 0.109, Valid Acc: 0.9702\n","Epoch: 5, Train Loss: 0.100, Train Acc: 0.9705\n","Epoch: 5, Valid Loss: 0.098, Valid Acc: 0.9742\n","Epoch: 6, Train Loss: 0.091, Train Acc: 0.9722\n","Epoch: 6, Valid Loss: 0.083, Valid Acc: 0.9778\n","Epoch: 7, Train Loss: 0.079, Train Acc: 0.9757\n","Epoch: 7, Valid Loss: 0.078, Valid Acc: 0.9766\n","Epoch: 8, Train Loss: 0.075, Train Acc: 0.9774\n","Epoch: 8, Valid Loss: 0.073, Valid Acc: 0.9782\n","Epoch: 9, Train Loss: 0.069, Train Acc: 0.9788\n","Epoch: 9, Valid Loss: 0.071, Valid Acc: 0.9792\n","Epoch: 10, Train Loss: 0.065, Train Acc: 0.9796\n","Epoch: 10, Valid Loss: 0.069, Valid Acc: 0.9813\n","Epoch: 11, Train Loss: 0.062, Train Acc: 0.9812\n","Epoch: 11, Valid Loss: 0.064, Valid Acc: 0.9824\n","Epoch: 12, Train Loss: 0.058, Train Acc: 0.9824\n","Epoch: 12, Valid Loss: 0.065, Valid Acc: 0.9816\n","Epoch: 13, Train Loss: 0.057, Train Acc: 0.9825\n","Epoch: 13, Valid Loss: 0.062, Valid Acc: 0.9840\n","Epoch: 14, Train Loss: 0.053, Train Acc: 0.9841\n","Epoch: 14, Valid Loss: 0.056, Valid Acc: 0.9846\n","Epoch: 15, Train Loss: 0.054, Train Acc: 0.9834\n","Epoch: 15, Valid Loss: 0.056, Valid Acc: 0.9841\n","Epoch: 16, Train Loss: 0.050, Train Acc: 0.9843\n","Epoch: 16, Valid Loss: 0.056, Valid Acc: 0.9844\n","Epoch: 17, Train Loss: 0.046, Train Acc: 0.9860\n","Epoch: 17, Valid Loss: 0.051, Valid Acc: 0.9855\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9854\n","Epoch: 18, Valid Loss: 0.053, Valid Acc: 0.9857\n","Epoch: 19, Train Loss: 0.044, Train Acc: 0.9863\n","Epoch: 19, Valid Loss: 0.048, Valid Acc: 0.9856\n","Epoch: 20, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 20, Valid Loss: 0.052, Valid Acc: 0.9850\n","Epoch: 21, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 21, Valid Loss: 0.048, Valid Acc: 0.9862\n","Epoch: 22, Train Loss: 0.040, Train Acc: 0.9881\n","Epoch: 22, Valid Loss: 0.050, Valid Acc: 0.9862\n","Epoch: 23, Train Loss: 0.039, Train Acc: 0.9880\n","Epoch: 23, Valid Loss: 0.049, Valid Acc: 0.9862\n","Epoch: 24, Train Loss: 0.041, Train Acc: 0.9867\n","Epoch: 24, Valid Loss: 0.050, Valid Acc: 0.9862\n","Epoch: 25, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 25, Valid Loss: 0.050, Valid Acc: 0.9866\n","Epoch: 26, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 26, Valid Loss: 0.044, Valid Acc: 0.9881\n","Epoch: 27, Train Loss: 0.039, Train Acc: 0.9877\n","Epoch: 27, Valid Loss: 0.048, Valid Acc: 0.9859\n","Epoch: 28, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 28, Valid Loss: 0.045, Valid Acc: 0.9876\n","Epoch: 29, Train Loss: 0.039, Train Acc: 0.9882\n","Epoch: 29, Valid Loss: 0.047, Valid Acc: 0.9862\n","Epoch: 30, Train Loss: 0.039, Train Acc: 0.9881\n","Epoch: 30, Valid Loss: 0.044, Valid Acc: 0.9874\n","| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9881  \u001b[0m | \u001b[0m 1.209e+0\u001b[0m | \u001b[0m 3.749   \u001b[0m |\n","Epoch: 1, Train Loss: 0.420, Train Acc: 0.8690\n","Epoch: 1, Valid Loss: 0.129, Valid Acc: 0.9689\n","Epoch: 2, Train Loss: 0.096, Train Acc: 0.9709\n","Epoch: 2, Valid Loss: 0.090, Valid Acc: 0.9755\n","Epoch: 3, Train Loss: 0.073, Train Acc: 0.9776\n","Epoch: 3, Valid Loss: 0.069, Valid Acc: 0.9802\n","Epoch: 4, Train Loss: 0.063, Train Acc: 0.9813\n","Epoch: 4, Valid Loss: 0.062, Valid Acc: 0.9823\n","Epoch: 5, Train Loss: 0.056, Train Acc: 0.9820\n","Epoch: 5, Valid Loss: 0.062, Valid Acc: 0.9850\n","Epoch: 6, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 6, Valid Loss: 0.056, Valid Acc: 0.9854\n","Epoch: 7, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 7, Valid Loss: 0.057, Valid Acc: 0.9847\n","Epoch: 8, Train Loss: 0.045, Train Acc: 0.9860\n","Epoch: 8, Valid Loss: 0.059, Valid Acc: 0.9834\n","Epoch: 9, Train Loss: 0.042, Train Acc: 0.9863\n","Epoch: 9, Valid Loss: 0.055, Valid Acc: 0.9855\n","Epoch: 10, Train Loss: 0.038, Train Acc: 0.9876\n","Epoch: 10, Valid Loss: 0.053, Valid Acc: 0.9855\n","Epoch: 11, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 11, Valid Loss: 0.049, Valid Acc: 0.9858\n","Epoch: 12, Train Loss: 0.036, Train Acc: 0.9890\n","Epoch: 12, Valid Loss: 0.054, Valid Acc: 0.9842\n","Epoch: 13, Train Loss: 0.029, Train Acc: 0.9905\n","Epoch: 13, Valid Loss: 0.040, Valid Acc: 0.9901\n","Epoch: 14, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 14, Valid Loss: 0.046, Valid Acc: 0.9878\n","Epoch: 15, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 15, Valid Loss: 0.043, Valid Acc: 0.9889\n","Epoch: 16, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 16, Valid Loss: 0.047, Valid Acc: 0.9889\n","Epoch: 17, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 17, Valid Loss: 0.046, Valid Acc: 0.9880\n","Epoch: 18, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 18, Valid Loss: 0.040, Valid Acc: 0.9882\n","Epoch: 19, Train Loss: 0.025, Train Acc: 0.9923\n","Epoch: 19, Valid Loss: 0.042, Valid Acc: 0.9882\n","Epoch: 20, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 20, Valid Loss: 0.038, Valid Acc: 0.9891\n","Epoch: 21, Train Loss: 0.024, Train Acc: 0.9925\n","Epoch: 21, Valid Loss: 0.042, Valid Acc: 0.9889\n","Epoch: 22, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 22, Valid Loss: 0.043, Valid Acc: 0.9892\n","Epoch: 23, Train Loss: 0.022, Train Acc: 0.9930\n","Epoch: 23, Valid Loss: 0.040, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 24, Valid Loss: 0.041, Valid Acc: 0.9883\n","Epoch: 25, Train Loss: 0.022, Train Acc: 0.9934\n","Epoch: 25, Valid Loss: 0.044, Valid Acc: 0.9885\n","Epoch: 26, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9880\n","Epoch: 27, Train Loss: 0.022, Train Acc: 0.9928\n","Epoch: 27, Valid Loss: 0.044, Valid Acc: 0.9888\n","Epoch: 28, Train Loss: 0.021, Train Acc: 0.9931\n","Epoch: 28, Valid Loss: 0.041, Valid Acc: 0.9887\n","Epoch: 29, Train Loss: 0.022, Train Acc: 0.9927\n","Epoch: 29, Valid Loss: 0.043, Valid Acc: 0.9879\n","Epoch: 30, Train Loss: 0.021, Train Acc: 0.9930\n","Epoch: 30, Valid Loss: 0.043, Valid Acc: 0.9890\n","| \u001b[95m 72      \u001b[0m | \u001b[95m 0.9901  \u001b[0m | \u001b[95m 1.384e+0\u001b[0m | \u001b[95m 1.044   \u001b[0m |\n","Epoch: 1, Train Loss: 0.779, Train Acc: 0.7704\n","Epoch: 1, Valid Loss: 0.285, Valid Acc: 0.9303\n","Epoch: 2, Train Loss: 0.198, Train Acc: 0.9425\n","Epoch: 2, Valid Loss: 0.154, Valid Acc: 0.9629\n","Epoch: 3, Train Loss: 0.133, Train Acc: 0.9605\n","Epoch: 3, Valid Loss: 0.117, Valid Acc: 0.9690\n","Epoch: 4, Train Loss: 0.104, Train Acc: 0.9696\n","Epoch: 4, Valid Loss: 0.101, Valid Acc: 0.9734\n","Epoch: 5, Train Loss: 0.091, Train Acc: 0.9728\n","Epoch: 5, Valid Loss: 0.085, Valid Acc: 0.9775\n","Epoch: 6, Train Loss: 0.081, Train Acc: 0.9762\n","Epoch: 6, Valid Loss: 0.073, Valid Acc: 0.9791\n","Epoch: 7, Train Loss: 0.073, Train Acc: 0.9780\n","Epoch: 7, Valid Loss: 0.071, Valid Acc: 0.9796\n","Epoch: 8, Train Loss: 0.067, Train Acc: 0.9792\n","Epoch: 8, Valid Loss: 0.066, Valid Acc: 0.9815\n","Epoch: 9, Train Loss: 0.064, Train Acc: 0.9802\n","Epoch: 9, Valid Loss: 0.062, Valid Acc: 0.9824\n","Epoch: 10, Train Loss: 0.058, Train Acc: 0.9823\n","Epoch: 10, Valid Loss: 0.060, Valid Acc: 0.9831\n","Epoch: 11, Train Loss: 0.059, Train Acc: 0.9827\n","Epoch: 11, Valid Loss: 0.060, Valid Acc: 0.9828\n","Epoch: 12, Train Loss: 0.054, Train Acc: 0.9835\n","Epoch: 12, Valid Loss: 0.056, Valid Acc: 0.9842\n","Epoch: 13, Train Loss: 0.050, Train Acc: 0.9847\n","Epoch: 13, Valid Loss: 0.057, Valid Acc: 0.9835\n","Epoch: 14, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 14, Valid Loss: 0.053, Valid Acc: 0.9855\n","Epoch: 15, Train Loss: 0.045, Train Acc: 0.9861\n","Epoch: 15, Valid Loss: 0.050, Valid Acc: 0.9855\n","Epoch: 16, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 16, Valid Loss: 0.051, Valid Acc: 0.9861\n","Epoch: 17, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 17, Valid Loss: 0.048, Valid Acc: 0.9859\n","Epoch: 18, Train Loss: 0.041, Train Acc: 0.9875\n","Epoch: 18, Valid Loss: 0.041, Valid Acc: 0.9869\n","Epoch: 19, Train Loss: 0.040, Train Acc: 0.9883\n","Epoch: 19, Valid Loss: 0.045, Valid Acc: 0.9867\n","Epoch: 20, Train Loss: 0.039, Train Acc: 0.9881\n","Epoch: 20, Valid Loss: 0.044, Valid Acc: 0.9878\n","Epoch: 21, Train Loss: 0.038, Train Acc: 0.9882\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9863\n","Epoch: 22, Train Loss: 0.038, Train Acc: 0.9884\n","Epoch: 22, Valid Loss: 0.043, Valid Acc: 0.9872\n","Epoch: 23, Train Loss: 0.038, Train Acc: 0.9879\n","Epoch: 23, Valid Loss: 0.047, Valid Acc: 0.9864\n","Epoch: 24, Train Loss: 0.038, Train Acc: 0.9883\n","Epoch: 24, Valid Loss: 0.044, Valid Acc: 0.9864\n","Epoch: 25, Train Loss: 0.037, Train Acc: 0.9887\n","Epoch: 25, Valid Loss: 0.045, Valid Acc: 0.9877\n","Epoch: 26, Train Loss: 0.037, Train Acc: 0.9888\n","Epoch: 26, Valid Loss: 0.043, Valid Acc: 0.9885\n","Epoch: 27, Train Loss: 0.036, Train Acc: 0.9887\n","Epoch: 27, Valid Loss: 0.043, Valid Acc: 0.9868\n","Epoch: 28, Train Loss: 0.037, Train Acc: 0.9885\n","Epoch: 28, Valid Loss: 0.044, Valid Acc: 0.9864\n","Epoch: 29, Train Loss: 0.036, Train Acc: 0.9889\n","Epoch: 29, Valid Loss: 0.050, Valid Acc: 0.9861\n","Epoch: 30, Train Loss: 0.038, Train Acc: 0.9887\n","Epoch: 30, Valid Loss: 0.046, Valid Acc: 0.9873\n","| \u001b[0m 73      \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 1.222e+0\u001b[0m | \u001b[0m 3.964   \u001b[0m |\n","Epoch: 1, Train Loss: 24.081, Train Acc: 0.1148\n","Epoch: 1, Valid Loss: 2.732, Valid Acc: 0.1010\n","Epoch: 2, Train Loss: 2.351, Train Acc: 0.1053\n","Epoch: 2, Valid Loss: 2.726, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.349, Train Acc: 0.1109\n","Epoch: 3, Valid Loss: 2.727, Valid Acc: 0.1135\n","| \u001b[0m 74      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.975e+0\u001b[0m | \u001b[0m 0.2053  \u001b[0m |\n","Epoch: 1, Train Loss: 253.592, Train Acc: 0.1052\n","Epoch: 1, Valid Loss: 2.311, Valid Acc: 0.1032\n","Epoch: 2, Train Loss: 2.313, Train Acc: 0.1074\n","Epoch: 2, Valid Loss: 2.311, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.314, Train Acc: 0.1079\n","Epoch: 3, Valid Loss: 2.314, Valid Acc: 0.1028\n","| \u001b[0m 75      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.255e+0\u001b[0m | \u001b[0m 0.4593  \u001b[0m |\n","Epoch: 1, Train Loss: 1.013, Train Acc: 0.7156\n","Epoch: 1, Valid Loss: 0.373, Valid Acc: 0.9013\n","Epoch: 2, Train Loss: 0.252, Train Acc: 0.9244\n","Epoch: 2, Valid Loss: 0.205, Valid Acc: 0.9511\n","Epoch: 3, Train Loss: 0.166, Train Acc: 0.9518\n","Epoch: 3, Valid Loss: 0.153, Valid Acc: 0.9620\n","Epoch: 4, Train Loss: 0.130, Train Acc: 0.9621\n","Epoch: 4, Valid Loss: 0.126, Valid Acc: 0.9679\n","Epoch: 5, Train Loss: 0.111, Train Acc: 0.9671\n","Epoch: 5, Valid Loss: 0.107, Valid Acc: 0.9718\n","Epoch: 6, Train Loss: 0.100, Train Acc: 0.9708\n","Epoch: 6, Valid Loss: 0.093, Valid Acc: 0.9748\n","Epoch: 7, Train Loss: 0.089, Train Acc: 0.9734\n","Epoch: 7, Valid Loss: 0.095, Valid Acc: 0.9752\n","Epoch: 8, Train Loss: 0.082, Train Acc: 0.9755\n","Epoch: 8, Valid Loss: 0.083, Valid Acc: 0.9777\n","Epoch: 9, Train Loss: 0.076, Train Acc: 0.9774\n","Epoch: 9, Valid Loss: 0.084, Valid Acc: 0.9775\n","Epoch: 10, Train Loss: 0.072, Train Acc: 0.9790\n","Epoch: 10, Valid Loss: 0.071, Valid Acc: 0.9808\n","Epoch: 11, Train Loss: 0.068, Train Acc: 0.9792\n","Epoch: 11, Valid Loss: 0.069, Valid Acc: 0.9817\n","Epoch: 12, Train Loss: 0.064, Train Acc: 0.9811\n","Epoch: 12, Valid Loss: 0.067, Valid Acc: 0.9825\n","Epoch: 13, Train Loss: 0.061, Train Acc: 0.9814\n","Epoch: 13, Valid Loss: 0.066, Valid Acc: 0.9819\n","Epoch: 14, Train Loss: 0.060, Train Acc: 0.9821\n","Epoch: 14, Valid Loss: 0.060, Valid Acc: 0.9817\n","Epoch: 15, Train Loss: 0.056, Train Acc: 0.9830\n","Epoch: 15, Valid Loss: 0.062, Valid Acc: 0.9831\n","Epoch: 16, Train Loss: 0.054, Train Acc: 0.9841\n","Epoch: 16, Valid Loss: 0.065, Valid Acc: 0.9834\n","Epoch: 17, Train Loss: 0.055, Train Acc: 0.9834\n","Epoch: 17, Valid Loss: 0.062, Valid Acc: 0.9832\n","Epoch: 18, Train Loss: 0.054, Train Acc: 0.9839\n","Epoch: 18, Valid Loss: 0.063, Valid Acc: 0.9822\n","Epoch: 19, Train Loss: 0.054, Train Acc: 0.9840\n","Epoch: 19, Valid Loss: 0.059, Valid Acc: 0.9841\n","Epoch: 20, Train Loss: 0.053, Train Acc: 0.9842\n","Epoch: 20, Valid Loss: 0.059, Valid Acc: 0.9845\n","Epoch: 21, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 21, Valid Loss: 0.059, Valid Acc: 0.9836\n","Epoch: 22, Train Loss: 0.053, Train Acc: 0.9840\n","Epoch: 22, Valid Loss: 0.060, Valid Acc: 0.9826\n","Epoch: 23, Train Loss: 0.052, Train Acc: 0.9845\n","Epoch: 23, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 24, Train Loss: 0.053, Train Acc: 0.9843\n","Epoch: 24, Valid Loss: 0.059, Valid Acc: 0.9818\n","Epoch: 25, Train Loss: 0.052, Train Acc: 0.9843\n","Epoch: 25, Valid Loss: 0.058, Valid Acc: 0.9845\n","Epoch: 26, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 26, Valid Loss: 0.060, Valid Acc: 0.9834\n","Epoch: 27, Train Loss: 0.053, Train Acc: 0.9842\n","Epoch: 27, Valid Loss: 0.058, Valid Acc: 0.9843\n","Epoch: 28, Train Loss: 0.051, Train Acc: 0.9849\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 29, Train Loss: 0.050, Train Acc: 0.9853\n","Epoch: 29, Valid Loss: 0.058, Valid Acc: 0.9833\n","Epoch: 30, Train Loss: 0.051, Train Acc: 0.9852\n","Epoch: 30, Valid Loss: 0.065, Valid Acc: 0.9835\n","| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9846  \u001b[0m | \u001b[0m 1.385e+0\u001b[0m | \u001b[0m 3.64    \u001b[0m |\n","Epoch: 1, Train Loss: 7.155, Train Acc: 0.1132\n","Epoch: 1, Valid Loss: 2.589, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.348, Train Acc: 0.1106\n","Epoch: 2, Valid Loss: 2.589, Valid Acc: 0.1010\n","Epoch: 3, Train Loss: 2.348, Train Acc: 0.1091\n","Epoch: 3, Valid Loss: 2.587, Valid Acc: 0.1135\n","| \u001b[0m 77      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.25e+03\u001b[0m | \u001b[0m 1.981   \u001b[0m |\n","Epoch: 1, Train Loss: 0.481, Train Acc: 0.8533\n","Epoch: 1, Valid Loss: 0.138, Valid Acc: 0.9658\n","Epoch: 2, Train Loss: 0.116, Train Acc: 0.9668\n","Epoch: 2, Valid Loss: 0.087, Valid Acc: 0.9766\n","Epoch: 3, Train Loss: 0.085, Train Acc: 0.9746\n","Epoch: 3, Valid Loss: 0.072, Valid Acc: 0.9802\n","Epoch: 4, Train Loss: 0.074, Train Acc: 0.9785\n","Epoch: 4, Valid Loss: 0.068, Valid Acc: 0.9828\n","Epoch: 5, Train Loss: 0.064, Train Acc: 0.9802\n","Epoch: 5, Valid Loss: 0.064, Valid Acc: 0.9818\n","Epoch: 6, Train Loss: 0.057, Train Acc: 0.9827\n","Epoch: 6, Valid Loss: 0.059, Valid Acc: 0.9831\n","Epoch: 7, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 7, Valid Loss: 0.054, Valid Acc: 0.9839\n","Epoch: 8, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 8, Valid Loss: 0.060, Valid Acc: 0.9848\n","Epoch: 9, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 9, Valid Loss: 0.050, Valid Acc: 0.9844\n","Epoch: 10, Train Loss: 0.045, Train Acc: 0.9856\n","Epoch: 10, Valid Loss: 0.054, Valid Acc: 0.9849\n","Epoch: 11, Train Loss: 0.044, Train Acc: 0.9864\n","Epoch: 11, Valid Loss: 0.057, Valid Acc: 0.9840\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9885\n","Epoch: 12, Valid Loss: 0.044, Valid Acc: 0.9877\n","Epoch: 13, Train Loss: 0.033, Train Acc: 0.9899\n","Epoch: 13, Valid Loss: 0.043, Valid Acc: 0.9881\n","Epoch: 14, Train Loss: 0.032, Train Acc: 0.9898\n","Epoch: 14, Valid Loss: 0.042, Valid Acc: 0.9872\n","Epoch: 15, Train Loss: 0.031, Train Acc: 0.9899\n","Epoch: 15, Valid Loss: 0.045, Valid Acc: 0.9871\n","Epoch: 16, Train Loss: 0.031, Train Acc: 0.9905\n","Epoch: 16, Valid Loss: 0.042, Valid Acc: 0.9882\n","Epoch: 17, Train Loss: 0.031, Train Acc: 0.9903\n","Epoch: 17, Valid Loss: 0.042, Valid Acc: 0.9888\n","Epoch: 18, Train Loss: 0.029, Train Acc: 0.9908\n","Epoch: 18, Valid Loss: 0.038, Valid Acc: 0.9878\n","Epoch: 19, Train Loss: 0.030, Train Acc: 0.9904\n","Epoch: 19, Valid Loss: 0.043, Valid Acc: 0.9876\n","Epoch: 20, Train Loss: 0.029, Train Acc: 0.9911\n","Epoch: 20, Valid Loss: 0.041, Valid Acc: 0.9879\n","Epoch: 21, Train Loss: 0.029, Train Acc: 0.9910\n","Epoch: 21, Valid Loss: 0.042, Valid Acc: 0.9867\n","Epoch: 22, Train Loss: 0.030, Train Acc: 0.9906\n","Epoch: 22, Valid Loss: 0.039, Valid Acc: 0.9889\n","Epoch: 23, Train Loss: 0.030, Train Acc: 0.9909\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9895\n","Epoch: 24, Train Loss: 0.029, Train Acc: 0.9913\n","Epoch: 24, Valid Loss: 0.039, Valid Acc: 0.9886\n","Epoch: 25, Train Loss: 0.029, Train Acc: 0.9911\n","Epoch: 25, Valid Loss: 0.038, Valid Acc: 0.9883\n","Epoch: 26, Train Loss: 0.027, Train Acc: 0.9919\n","Epoch: 26, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 27, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 27, Valid Loss: 0.041, Valid Acc: 0.9885\n","Epoch: 28, Train Loss: 0.028, Train Acc: 0.9907\n","Epoch: 28, Valid Loss: 0.041, Valid Acc: 0.9894\n","Epoch: 29, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 29, Valid Loss: 0.040, Valid Acc: 0.9880\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 30, Valid Loss: 0.040, Valid Acc: 0.9885\n","| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9895  \u001b[0m | \u001b[0m 1.223e+0\u001b[0m | \u001b[0m 2.438   \u001b[0m |\n","Epoch: 1, Train Loss: 1.668, Train Acc: 0.5661\n","Epoch: 1, Valid Loss: 0.788, Valid Acc: 0.7774\n","Epoch: 2, Train Loss: 0.459, Train Acc: 0.8583\n","Epoch: 2, Valid Loss: 0.325, Valid Acc: 0.9091\n","Epoch: 3, Train Loss: 0.272, Train Acc: 0.9180\n","Epoch: 3, Valid Loss: 0.265, Valid Acc: 0.9259\n","Epoch: 4, Train Loss: 0.217, Train Acc: 0.9355\n","Epoch: 4, Valid Loss: 0.195, Valid Acc: 0.9478\n","Epoch: 5, Train Loss: 0.183, Train Acc: 0.9452\n","Epoch: 5, Valid Loss: 0.192, Valid Acc: 0.9456\n","Epoch: 6, Train Loss: 0.163, Train Acc: 0.9504\n","Epoch: 6, Valid Loss: 0.183, Valid Acc: 0.9510\n","Epoch: 7, Train Loss: 0.154, Train Acc: 0.9535\n","Epoch: 7, Valid Loss: 0.156, Valid Acc: 0.9563\n","Epoch: 8, Train Loss: 0.148, Train Acc: 0.9561\n","Epoch: 8, Valid Loss: 0.155, Valid Acc: 0.9562\n","Epoch: 9, Train Loss: 0.141, Train Acc: 0.9575\n","Epoch: 9, Valid Loss: 0.177, Valid Acc: 0.9529\n","Epoch: 10, Train Loss: 0.140, Train Acc: 0.9580\n","Epoch: 10, Valid Loss: 0.136, Valid Acc: 0.9652\n","Epoch: 11, Train Loss: 0.140, Train Acc: 0.9584\n","Epoch: 11, Valid Loss: 0.162, Valid Acc: 0.9583\n","Epoch: 12, Train Loss: 0.134, Train Acc: 0.9605\n","Epoch: 12, Valid Loss: 0.133, Valid Acc: 0.9623\n","Epoch: 13, Train Loss: 0.127, Train Acc: 0.9620\n","Epoch: 13, Valid Loss: 0.144, Valid Acc: 0.9628\n","Epoch: 14, Train Loss: 0.128, Train Acc: 0.9609\n","Epoch: 14, Valid Loss: 0.136, Valid Acc: 0.9625\n","Epoch: 15, Train Loss: 0.107, Train Acc: 0.9673\n","Epoch: 15, Valid Loss: 0.116, Valid Acc: 0.9691\n","Epoch: 16, Train Loss: 0.104, Train Acc: 0.9685\n","Epoch: 16, Valid Loss: 0.114, Valid Acc: 0.9683\n","| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9691  \u001b[0m | \u001b[0m 1.206e+0\u001b[0m | \u001b[0m 1.331   \u001b[0m |\n","Epoch: 1, Train Loss: 1.478, Train Acc: 0.5817\n","Epoch: 1, Valid Loss: 0.685, Valid Acc: 0.7993\n","Epoch: 2, Train Loss: 0.504, Train Acc: 0.8481\n","Epoch: 2, Valid Loss: 0.360, Valid Acc: 0.8988\n","Epoch: 3, Train Loss: 0.315, Train Acc: 0.9081\n","Epoch: 3, Valid Loss: 0.250, Valid Acc: 0.9289\n","Epoch: 4, Train Loss: 0.236, Train Acc: 0.9321\n","Epoch: 4, Valid Loss: 0.191, Valid Acc: 0.9440\n","Epoch: 5, Train Loss: 0.191, Train Acc: 0.9449\n","Epoch: 5, Valid Loss: 0.164, Valid Acc: 0.9533\n","Epoch: 6, Train Loss: 0.161, Train Acc: 0.9533\n","Epoch: 6, Valid Loss: 0.138, Valid Acc: 0.9595\n","Epoch: 7, Train Loss: 0.144, Train Acc: 0.9575\n","Epoch: 7, Valid Loss: 0.122, Valid Acc: 0.9654\n","Epoch: 8, Train Loss: 0.131, Train Acc: 0.9617\n","Epoch: 8, Valid Loss: 0.114, Valid Acc: 0.9668\n","Epoch: 9, Train Loss: 0.118, Train Acc: 0.9653\n","Epoch: 9, Valid Loss: 0.102, Valid Acc: 0.9706\n","Epoch: 10, Train Loss: 0.110, Train Acc: 0.9677\n","Epoch: 10, Valid Loss: 0.099, Valid Acc: 0.9698\n","Epoch: 11, Train Loss: 0.105, Train Acc: 0.9685\n","Epoch: 11, Valid Loss: 0.093, Valid Acc: 0.9715\n","Epoch: 12, Train Loss: 0.098, Train Acc: 0.9708\n","Epoch: 12, Valid Loss: 0.081, Valid Acc: 0.9755\n","Epoch: 13, Train Loss: 0.092, Train Acc: 0.9723\n","Epoch: 13, Valid Loss: 0.083, Valid Acc: 0.9740\n","Epoch: 14, Train Loss: 0.089, Train Acc: 0.9733\n","Epoch: 14, Valid Loss: 0.072, Valid Acc: 0.9785\n","Epoch: 15, Train Loss: 0.085, Train Acc: 0.9746\n","Epoch: 15, Valid Loss: 0.072, Valid Acc: 0.9776\n","Epoch: 16, Train Loss: 0.081, Train Acc: 0.9750\n","Epoch: 16, Valid Loss: 0.072, Valid Acc: 0.9780\n","Epoch: 17, Train Loss: 0.078, Train Acc: 0.9765\n","Epoch: 17, Valid Loss: 0.068, Valid Acc: 0.9791\n","Epoch: 18, Train Loss: 0.076, Train Acc: 0.9774\n","Epoch: 18, Valid Loss: 0.071, Valid Acc: 0.9798\n","Epoch: 19, Train Loss: 0.073, Train Acc: 0.9781\n","Epoch: 19, Valid Loss: 0.068, Valid Acc: 0.9790\n","Epoch: 20, Train Loss: 0.072, Train Acc: 0.9779\n","Epoch: 20, Valid Loss: 0.065, Valid Acc: 0.9799\n","| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9799  \u001b[0m | \u001b[0m 1.26e+03\u001b[0m | \u001b[0m 3.265   \u001b[0m |\n","Epoch: 1, Train Loss: 979.551, Train Acc: 0.0987\n","Epoch: 1, Valid Loss: 2.349, Valid Acc: 0.1032\n","Epoch: 2, Train Loss: 2.328, Train Acc: 0.1060\n","Epoch: 2, Valid Loss: 2.324, Valid Acc: 0.0974\n","Epoch: 3, Train Loss: 2.325, Train Acc: 0.1035\n","Epoch: 3, Valid Loss: 2.322, Valid Acc: 0.1135\n","| \u001b[0m 81      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.26e+03\u001b[0m | \u001b[0m 0.9481  \u001b[0m |\n","Epoch: 1, Train Loss: 3.960, Train Acc: 0.4312\n","Epoch: 1, Valid Loss: 1.082, Valid Acc: 0.6811\n","Epoch: 2, Train Loss: 1.171, Train Acc: 0.6057\n","Epoch: 2, Valid Loss: 1.141, Valid Acc: 0.6341\n","Epoch: 3, Train Loss: 0.905, Train Acc: 0.6902\n","Epoch: 3, Valid Loss: 0.807, Valid Acc: 0.7561\n","Epoch: 4, Train Loss: 0.700, Train Acc: 0.7694\n","Epoch: 4, Valid Loss: 0.671, Valid Acc: 0.7931\n","Epoch: 5, Train Loss: 0.646, Train Acc: 0.7870\n","Epoch: 5, Valid Loss: 0.632, Valid Acc: 0.8038\n","Epoch: 6, Train Loss: 2.221, Train Acc: 0.3279\n","Epoch: 6, Valid Loss: 2.521, Valid Acc: 0.0958\n","| \u001b[0m 82      \u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m 1.21e+03\u001b[0m | \u001b[0m 1.922   \u001b[0m |\n","Epoch: 1, Train Loss: 0.701, Train Acc: 0.7899\n","Epoch: 1, Valid Loss: 0.243, Valid Acc: 0.9363\n","Epoch: 2, Train Loss: 0.175, Train Acc: 0.9476\n","Epoch: 2, Valid Loss: 0.140, Valid Acc: 0.9643\n","Epoch: 3, Train Loss: 0.121, Train Acc: 0.9630\n","Epoch: 3, Valid Loss: 0.107, Valid Acc: 0.9709\n","Epoch: 4, Train Loss: 0.097, Train Acc: 0.9706\n","Epoch: 4, Valid Loss: 0.084, Valid Acc: 0.9780\n","Epoch: 5, Train Loss: 0.083, Train Acc: 0.9751\n","Epoch: 5, Valid Loss: 0.079, Valid Acc: 0.9784\n","Epoch: 6, Train Loss: 0.072, Train Acc: 0.9785\n","Epoch: 6, Valid Loss: 0.073, Valid Acc: 0.9784\n","Epoch: 7, Train Loss: 0.067, Train Acc: 0.9796\n","Epoch: 7, Valid Loss: 0.060, Valid Acc: 0.9823\n","Epoch: 8, Train Loss: 0.063, Train Acc: 0.9809\n","Epoch: 8, Valid Loss: 0.060, Valid Acc: 0.9827\n","Epoch: 9, Train Loss: 0.057, Train Acc: 0.9825\n","Epoch: 9, Valid Loss: 0.059, Valid Acc: 0.9846\n","Epoch: 10, Train Loss: 0.055, Train Acc: 0.9840\n","Epoch: 10, Valid Loss: 0.059, Valid Acc: 0.9839\n","Epoch: 11, Train Loss: 0.051, Train Acc: 0.9839\n","Epoch: 11, Valid Loss: 0.052, Valid Acc: 0.9851\n","Epoch: 12, Train Loss: 0.049, Train Acc: 0.9850\n","Epoch: 12, Valid Loss: 0.056, Valid Acc: 0.9849\n","Epoch: 13, Train Loss: 0.046, Train Acc: 0.9858\n","Epoch: 13, Valid Loss: 0.052, Valid Acc: 0.9859\n","Epoch: 14, Train Loss: 0.045, Train Acc: 0.9860\n","Epoch: 14, Valid Loss: 0.050, Valid Acc: 0.9857\n","Epoch: 15, Train Loss: 0.043, Train Acc: 0.9861\n","Epoch: 15, Valid Loss: 0.048, Valid Acc: 0.9873\n","Epoch: 16, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 16, Valid Loss: 0.045, Valid Acc: 0.9877\n","Epoch: 17, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 17, Valid Loss: 0.050, Valid Acc: 0.9873\n","Epoch: 18, Train Loss: 0.037, Train Acc: 0.9886\n","Epoch: 18, Valid Loss: 0.040, Valid Acc: 0.9875\n","Epoch: 19, Train Loss: 0.036, Train Acc: 0.9882\n","Epoch: 19, Valid Loss: 0.042, Valid Acc: 0.9872\n","Epoch: 20, Train Loss: 0.035, Train Acc: 0.9887\n","Epoch: 20, Valid Loss: 0.045, Valid Acc: 0.9873\n","Epoch: 21, Train Loss: 0.035, Train Acc: 0.9894\n","Epoch: 21, Valid Loss: 0.047, Valid Acc: 0.9873\n","Epoch: 22, Train Loss: 0.034, Train Acc: 0.9894\n","Epoch: 22, Valid Loss: 0.044, Valid Acc: 0.9872\n","Epoch: 23, Train Loss: 0.035, Train Acc: 0.9891\n","Epoch: 23, Valid Loss: 0.048, Valid Acc: 0.9864\n","Epoch: 24, Train Loss: 0.036, Train Acc: 0.9890\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9859\n","Epoch: 25, Train Loss: 0.035, Train Acc: 0.9890\n","Epoch: 25, Valid Loss: 0.044, Valid Acc: 0.9878\n","Epoch: 26, Train Loss: 0.034, Train Acc: 0.9895\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9867\n","Epoch: 27, Train Loss: 0.034, Train Acc: 0.9887\n","Epoch: 27, Valid Loss: 0.044, Valid Acc: 0.9863\n","Epoch: 28, Train Loss: 0.034, Train Acc: 0.9891\n","Epoch: 28, Valid Loss: 0.045, Valid Acc: 0.9890\n","Epoch: 29, Train Loss: 0.034, Train Acc: 0.9894\n","Epoch: 29, Valid Loss: 0.045, Valid Acc: 0.9878\n","Epoch: 30, Train Loss: 0.034, Train Acc: 0.9891\n","Epoch: 30, Valid Loss: 0.047, Valid Acc: 0.9869\n","| \u001b[0m 83      \u001b[0m | \u001b[0m 0.989   \u001b[0m | \u001b[0m 1.202e+0\u001b[0m | \u001b[0m 2.102   \u001b[0m |\n","Epoch: 1, Train Loss: 0.871, Train Acc: 0.7417\n","Epoch: 1, Valid Loss: 0.296, Valid Acc: 0.9117\n","Epoch: 2, Train Loss: 0.238, Train Acc: 0.9288\n","Epoch: 2, Valid Loss: 0.169, Valid Acc: 0.9522\n","Epoch: 3, Train Loss: 0.159, Train Acc: 0.9529\n","Epoch: 3, Valid Loss: 0.124, Valid Acc: 0.9650\n","Epoch: 4, Train Loss: 0.125, Train Acc: 0.9631\n","Epoch: 4, Valid Loss: 0.102, Valid Acc: 0.9672\n","Epoch: 5, Train Loss: 0.106, Train Acc: 0.9684\n","Epoch: 5, Valid Loss: 0.089, Valid Acc: 0.9726\n","Epoch: 6, Train Loss: 0.094, Train Acc: 0.9720\n","Epoch: 6, Valid Loss: 0.085, Valid Acc: 0.9749\n","Epoch: 7, Train Loss: 0.085, Train Acc: 0.9742\n","Epoch: 7, Valid Loss: 0.075, Valid Acc: 0.9769\n","Epoch: 8, Train Loss: 0.077, Train Acc: 0.9772\n","Epoch: 8, Valid Loss: 0.067, Valid Acc: 0.9803\n","Epoch: 9, Train Loss: 0.073, Train Acc: 0.9780\n","Epoch: 9, Valid Loss: 0.067, Valid Acc: 0.9791\n","Epoch: 10, Train Loss: 0.067, Train Acc: 0.9795\n","Epoch: 10, Valid Loss: 0.058, Valid Acc: 0.9804\n","Epoch: 11, Train Loss: 0.064, Train Acc: 0.9809\n","Epoch: 11, Valid Loss: 0.059, Valid Acc: 0.9816\n","Epoch: 12, Train Loss: 0.060, Train Acc: 0.9811\n","Epoch: 12, Valid Loss: 0.059, Valid Acc: 0.9819\n","Epoch: 13, Train Loss: 0.057, Train Acc: 0.9826\n","Epoch: 13, Valid Loss: 0.057, Valid Acc: 0.9818\n","Epoch: 14, Train Loss: 0.053, Train Acc: 0.9836\n","Epoch: 14, Valid Loss: 0.055, Valid Acc: 0.9819\n","Epoch: 15, Train Loss: 0.054, Train Acc: 0.9836\n","Epoch: 15, Valid Loss: 0.050, Valid Acc: 0.9840\n","Epoch: 16, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 16, Valid Loss: 0.051, Valid Acc: 0.9834\n","Epoch: 17, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 17, Valid Loss: 0.053, Valid Acc: 0.9816\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 18, Valid Loss: 0.046, Valid Acc: 0.9849\n","Epoch: 19, Train Loss: 0.046, Train Acc: 0.9857\n","Epoch: 19, Valid Loss: 0.051, Valid Acc: 0.9826\n","Epoch: 20, Train Loss: 0.044, Train Acc: 0.9869\n","Epoch: 20, Valid Loss: 0.050, Valid Acc: 0.9843\n","Epoch: 21, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 21, Valid Loss: 0.047, Valid Acc: 0.9854\n","Epoch: 22, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 22, Valid Loss: 0.050, Valid Acc: 0.9832\n","Epoch: 23, Train Loss: 0.044, Train Acc: 0.9864\n","Epoch: 23, Valid Loss: 0.048, Valid Acc: 0.9836\n","Epoch: 24, Train Loss: 0.043, Train Acc: 0.9871\n","Epoch: 24, Valid Loss: 0.047, Valid Acc: 0.9851\n","Epoch: 25, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 25, Valid Loss: 0.052, Valid Acc: 0.9839\n","Epoch: 26, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9848\n","Epoch: 27, Train Loss: 0.043, Train Acc: 0.9867\n","Epoch: 27, Valid Loss: 0.047, Valid Acc: 0.9847\n","Epoch: 28, Train Loss: 0.043, Train Acc: 0.9870\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9843\n","Epoch: 29, Train Loss: 0.043, Train Acc: 0.9872\n","Epoch: 29, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9867\n","Epoch: 30, Valid Loss: 0.047, Valid Acc: 0.9862\n","| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9862  \u001b[0m | \u001b[0m 1.257e+0\u001b[0m | \u001b[0m 3.676   \u001b[0m |\n","Epoch: 1, Train Loss: 1.616, Train Acc: 0.5448\n","Epoch: 1, Valid Loss: 0.781, Valid Acc: 0.7937\n","Epoch: 2, Train Loss: 0.535, Train Acc: 0.8429\n","Epoch: 2, Valid Loss: 0.379, Valid Acc: 0.8969\n","Epoch: 3, Train Loss: 0.329, Train Acc: 0.9044\n","Epoch: 3, Valid Loss: 0.265, Valid Acc: 0.9261\n","Epoch: 4, Train Loss: 0.246, Train Acc: 0.9276\n","Epoch: 4, Valid Loss: 0.207, Valid Acc: 0.9408\n","Epoch: 5, Train Loss: 0.199, Train Acc: 0.9425\n","Epoch: 5, Valid Loss: 0.172, Valid Acc: 0.9531\n","Epoch: 6, Train Loss: 0.169, Train Acc: 0.9512\n","Epoch: 6, Valid Loss: 0.144, Valid Acc: 0.9591\n","Epoch: 7, Train Loss: 0.148, Train Acc: 0.9573\n","Epoch: 7, Valid Loss: 0.132, Valid Acc: 0.9630\n","Epoch: 8, Train Loss: 0.133, Train Acc: 0.9608\n","Epoch: 8, Valid Loss: 0.118, Valid Acc: 0.9669\n","Epoch: 9, Train Loss: 0.122, Train Acc: 0.9639\n","Epoch: 9, Valid Loss: 0.109, Valid Acc: 0.9698\n","Epoch: 10, Train Loss: 0.111, Train Acc: 0.9675\n","Epoch: 10, Valid Loss: 0.098, Valid Acc: 0.9712\n","Epoch: 11, Train Loss: 0.106, Train Acc: 0.9683\n","Epoch: 11, Valid Loss: 0.096, Valid Acc: 0.9716\n","Epoch: 12, Train Loss: 0.099, Train Acc: 0.9705\n","Epoch: 12, Valid Loss: 0.089, Valid Acc: 0.9746\n","Epoch: 13, Train Loss: 0.093, Train Acc: 0.9726\n","Epoch: 13, Valid Loss: 0.083, Valid Acc: 0.9745\n","Epoch: 14, Train Loss: 0.089, Train Acc: 0.9741\n","Epoch: 14, Valid Loss: 0.079, Valid Acc: 0.9755\n","Epoch: 15, Train Loss: 0.084, Train Acc: 0.9747\n","Epoch: 15, Valid Loss: 0.079, Valid Acc: 0.9765\n","Epoch: 16, Train Loss: 0.082, Train Acc: 0.9755\n","Epoch: 16, Valid Loss: 0.077, Valid Acc: 0.9779\n","Epoch: 17, Train Loss: 0.076, Train Acc: 0.9776\n","Epoch: 17, Valid Loss: 0.072, Valid Acc: 0.9783\n","Epoch: 18, Train Loss: 0.075, Train Acc: 0.9782\n","Epoch: 18, Valid Loss: 0.069, Valid Acc: 0.9783\n","Epoch: 19, Train Loss: 0.071, Train Acc: 0.9785\n","Epoch: 19, Valid Loss: 0.065, Valid Acc: 0.9793\n","Epoch: 20, Train Loss: 0.070, Train Acc: 0.9794\n","Epoch: 20, Valid Loss: 0.066, Valid Acc: 0.9808\n","Epoch: 21, Train Loss: 0.068, Train Acc: 0.9800\n","Epoch: 21, Valid Loss: 0.064, Valid Acc: 0.9805\n","Epoch: 22, Train Loss: 0.065, Train Acc: 0.9807\n","Epoch: 22, Valid Loss: 0.064, Valid Acc: 0.9812\n","Epoch: 23, Train Loss: 0.063, Train Acc: 0.9807\n","Epoch: 23, Valid Loss: 0.061, Valid Acc: 0.9820\n","Epoch: 24, Train Loss: 0.063, Train Acc: 0.9810\n","Epoch: 24, Valid Loss: 0.057, Valid Acc: 0.9827\n","Epoch: 25, Train Loss: 0.060, Train Acc: 0.9817\n","Epoch: 25, Valid Loss: 0.060, Valid Acc: 0.9813\n","Epoch: 26, Train Loss: 0.058, Train Acc: 0.9823\n","Epoch: 26, Valid Loss: 0.058, Valid Acc: 0.9818\n","Epoch: 27, Train Loss: 0.058, Train Acc: 0.9831\n","Epoch: 27, Valid Loss: 0.059, Valid Acc: 0.9815\n","Epoch: 28, Train Loss: 0.058, Train Acc: 0.9828\n","Epoch: 28, Valid Loss: 0.057, Valid Acc: 0.9831\n","Epoch: 29, Train Loss: 0.058, Train Acc: 0.9827\n","Epoch: 29, Valid Loss: 0.053, Valid Acc: 0.9842\n","Epoch: 30, Train Loss: 0.057, Train Acc: 0.9828\n","Epoch: 30, Valid Loss: 0.055, Valid Acc: 0.9827\n","| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9842  \u001b[0m | \u001b[0m 1.478e+0\u001b[0m | \u001b[0m 3.315   \u001b[0m |\n","Epoch: 1, Train Loss: 0.445, Train Acc: 0.8629\n","Epoch: 1, Valid Loss: 0.123, Valid Acc: 0.9624\n","Epoch: 2, Train Loss: 0.111, Train Acc: 0.9669\n","Epoch: 2, Valid Loss: 0.082, Valid Acc: 0.9750\n","Epoch: 3, Train Loss: 0.083, Train Acc: 0.9746\n","Epoch: 3, Valid Loss: 0.069, Valid Acc: 0.9789\n","Epoch: 4, Train Loss: 0.070, Train Acc: 0.9784\n","Epoch: 4, Valid Loss: 0.063, Valid Acc: 0.9816\n","Epoch: 5, Train Loss: 0.062, Train Acc: 0.9810\n","Epoch: 5, Valid Loss: 0.057, Valid Acc: 0.9816\n","Epoch: 6, Train Loss: 0.056, Train Acc: 0.9830\n","Epoch: 6, Valid Loss: 0.054, Valid Acc: 0.9838\n","Epoch: 7, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 7, Valid Loss: 0.052, Valid Acc: 0.9846\n","Epoch: 8, Train Loss: 0.050, Train Acc: 0.9850\n","Epoch: 8, Valid Loss: 0.052, Valid Acc: 0.9843\n","Epoch: 9, Train Loss: 0.046, Train Acc: 0.9855\n","Epoch: 9, Valid Loss: 0.048, Valid Acc: 0.9862\n","Epoch: 10, Train Loss: 0.046, Train Acc: 0.9857\n","Epoch: 10, Valid Loss: 0.045, Valid Acc: 0.9853\n","Epoch: 11, Train Loss: 0.041, Train Acc: 0.9870\n","Epoch: 11, Valid Loss: 0.046, Valid Acc: 0.9855\n","Epoch: 12, Train Loss: 0.040, Train Acc: 0.9873\n","Epoch: 12, Valid Loss: 0.045, Valid Acc: 0.9867\n","Epoch: 13, Train Loss: 0.035, Train Acc: 0.9884\n","Epoch: 13, Valid Loss: 0.045, Valid Acc: 0.9863\n","Epoch: 14, Train Loss: 0.036, Train Acc: 0.9884\n","Epoch: 14, Valid Loss: 0.050, Valid Acc: 0.9849\n","Epoch: 15, Train Loss: 0.031, Train Acc: 0.9901\n","Epoch: 15, Valid Loss: 0.039, Valid Acc: 0.9890\n","Epoch: 16, Train Loss: 0.030, Train Acc: 0.9906\n","Epoch: 16, Valid Loss: 0.034, Valid Acc: 0.9884\n","Epoch: 17, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 17, Valid Loss: 0.040, Valid Acc: 0.9876\n","Epoch: 18, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 18, Valid Loss: 0.038, Valid Acc: 0.9879\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9921\n","Epoch: 19, Valid Loss: 0.039, Valid Acc: 0.9867\n","Epoch: 20, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 20, Valid Loss: 0.040, Valid Acc: 0.9877\n","Epoch: 21, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 21, Valid Loss: 0.038, Valid Acc: 0.9884\n","Epoch: 22, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 22, Valid Loss: 0.036, Valid Acc: 0.9890\n","Epoch: 23, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 24, Train Loss: 0.025, Train Acc: 0.9916\n","Epoch: 24, Valid Loss: 0.036, Valid Acc: 0.9883\n","Epoch: 25, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 25, Valid Loss: 0.040, Valid Acc: 0.9875\n","Epoch: 26, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 26, Valid Loss: 0.035, Valid Acc: 0.9887\n","Epoch: 27, Train Loss: 0.024, Train Acc: 0.9927\n","Epoch: 27, Valid Loss: 0.036, Valid Acc: 0.9895\n","Epoch: 28, Train Loss: 0.022, Train Acc: 0.9928\n","Epoch: 28, Valid Loss: 0.040, Valid Acc: 0.9875\n","Epoch: 29, Train Loss: 0.023, Train Acc: 0.9922\n","Epoch: 29, Valid Loss: 0.035, Valid Acc: 0.9892\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 30, Valid Loss: 0.037, Valid Acc: 0.9888\n","| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9895  \u001b[0m | \u001b[0m 1.273e+0\u001b[0m | \u001b[0m 2.488   \u001b[0m |\n","Epoch: 1, Train Loss: 2.099, Train Acc: 0.4436\n","Epoch: 1, Valid Loss: 1.494, Valid Acc: 0.6254\n","Epoch: 2, Train Loss: 1.206, Train Acc: 0.6398\n","Epoch: 2, Valid Loss: 1.324, Valid Acc: 0.6609\n","Epoch: 3, Train Loss: 1.109, Train Acc: 0.6558\n","Epoch: 3, Valid Loss: 1.198, Valid Acc: 0.6779\n","| \u001b[0m 87      \u001b[0m | \u001b[0m 0.6779  \u001b[0m | \u001b[0m 1.963e+0\u001b[0m | \u001b[0m 1.24    \u001b[0m |\n","Epoch: 1, Train Loss: 1621.805, Train Acc: 0.0994\n","Epoch: 1, Valid Loss: 2.584, Valid Acc: 0.0980\n","Epoch: 2, Train Loss: 2.343, Train Acc: 0.1060\n","Epoch: 2, Valid Loss: 2.580, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.342, Train Acc: 0.1060\n","Epoch: 3, Valid Loss: 2.589, Valid Acc: 0.1032\n","| \u001b[0m 88      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.244e+0\u001b[0m | \u001b[0m 0.8259  \u001b[0m |\n","Epoch: 1, Train Loss: 2.024, Train Acc: 0.3885\n","Epoch: 1, Valid Loss: 1.824, Valid Acc: 0.6609\n","Epoch: 2, Train Loss: 1.149, Train Acc: 0.7189\n","Epoch: 2, Valid Loss: 0.920, Valid Acc: 0.7919\n","Epoch: 3, Train Loss: 0.649, Train Acc: 0.8134\n","Epoch: 3, Valid Loss: 0.618, Valid Acc: 0.8586\n","Epoch: 4, Train Loss: 0.471, Train Acc: 0.8621\n","Epoch: 4, Valid Loss: 0.494, Valid Acc: 0.8872\n","Epoch: 5, Train Loss: 0.377, Train Acc: 0.8905\n","Epoch: 5, Valid Loss: 0.405, Valid Acc: 0.9068\n","Epoch: 6, Train Loss: 0.317, Train Acc: 0.9071\n","Epoch: 6, Valid Loss: 0.354, Valid Acc: 0.9210\n","Epoch: 7, Train Loss: 0.277, Train Acc: 0.9193\n","Epoch: 7, Valid Loss: 0.313, Valid Acc: 0.9321\n","Epoch: 8, Train Loss: 0.247, Train Acc: 0.9286\n","Epoch: 8, Valid Loss: 0.277, Valid Acc: 0.9368\n","Epoch: 9, Train Loss: 0.219, Train Acc: 0.9369\n","Epoch: 9, Valid Loss: 0.255, Valid Acc: 0.9438\n","Epoch: 10, Train Loss: 0.202, Train Acc: 0.9410\n","Epoch: 10, Valid Loss: 0.228, Valid Acc: 0.9501\n","Epoch: 11, Train Loss: 0.185, Train Acc: 0.9451\n","Epoch: 11, Valid Loss: 0.206, Valid Acc: 0.9546\n","Epoch: 12, Train Loss: 0.173, Train Acc: 0.9502\n","Epoch: 12, Valid Loss: 0.193, Valid Acc: 0.9563\n","Epoch: 13, Train Loss: 0.164, Train Acc: 0.9522\n","Epoch: 13, Valid Loss: 0.182, Valid Acc: 0.9612\n","Epoch: 14, Train Loss: 0.152, Train Acc: 0.9567\n","Epoch: 14, Valid Loss: 0.173, Valid Acc: 0.9604\n","Epoch: 15, Train Loss: 0.143, Train Acc: 0.9587\n","Epoch: 15, Valid Loss: 0.163, Valid Acc: 0.9631\n","Epoch: 16, Train Loss: 0.139, Train Acc: 0.9589\n","Epoch: 16, Valid Loss: 0.158, Valid Acc: 0.9645\n","| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9645  \u001b[0m | \u001b[0m 1.968e+0\u001b[0m | \u001b[0m 3.167   \u001b[0m |\n","Epoch: 1, Train Loss: 0.555, Train Acc: 0.8307\n","Epoch: 1, Valid Loss: 0.179, Valid Acc: 0.9552\n","Epoch: 2, Train Loss: 0.125, Train Acc: 0.9624\n","Epoch: 2, Valid Loss: 0.104, Valid Acc: 0.9722\n","Epoch: 3, Train Loss: 0.089, Train Acc: 0.9737\n","Epoch: 3, Valid Loss: 0.085, Valid Acc: 0.9780\n","Epoch: 4, Train Loss: 0.073, Train Acc: 0.9781\n","Epoch: 4, Valid Loss: 0.073, Valid Acc: 0.9796\n","Epoch: 5, Train Loss: 0.063, Train Acc: 0.9812\n","Epoch: 5, Valid Loss: 0.063, Valid Acc: 0.9843\n","Epoch: 6, Train Loss: 0.057, Train Acc: 0.9822\n","Epoch: 6, Valid Loss: 0.060, Valid Acc: 0.9850\n","Epoch: 7, Train Loss: 0.052, Train Acc: 0.9840\n","Epoch: 7, Valid Loss: 0.060, Valid Acc: 0.9846\n","Epoch: 8, Train Loss: 0.048, Train Acc: 0.9849\n","Epoch: 8, Valid Loss: 0.059, Valid Acc: 0.9871\n","Epoch: 9, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 9, Valid Loss: 0.050, Valid Acc: 0.9860\n","Epoch: 10, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 10, Valid Loss: 0.054, Valid Acc: 0.9866\n","Epoch: 11, Train Loss: 0.041, Train Acc: 0.9873\n","Epoch: 11, Valid Loss: 0.046, Valid Acc: 0.9881\n","Epoch: 12, Train Loss: 0.038, Train Acc: 0.9877\n","Epoch: 12, Valid Loss: 0.048, Valid Acc: 0.9875\n","Epoch: 13, Train Loss: 0.036, Train Acc: 0.9884\n","Epoch: 13, Valid Loss: 0.048, Valid Acc: 0.9881\n","Epoch: 14, Train Loss: 0.034, Train Acc: 0.9892\n","Epoch: 14, Valid Loss: 0.051, Valid Acc: 0.9862\n","Epoch: 15, Train Loss: 0.030, Train Acc: 0.9900\n","Epoch: 15, Valid Loss: 0.046, Valid Acc: 0.9876\n","Epoch: 16, Train Loss: 0.029, Train Acc: 0.9902\n","Epoch: 16, Valid Loss: 0.048, Valid Acc: 0.9873\n","Epoch: 17, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 17, Valid Loss: 0.042, Valid Acc: 0.9897\n","Epoch: 18, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 18, Valid Loss: 0.044, Valid Acc: 0.9890\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 19, Valid Loss: 0.042, Valid Acc: 0.9889\n","Epoch: 20, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 20, Valid Loss: 0.042, Valid Acc: 0.9880\n","Epoch: 21, Train Loss: 0.026, Train Acc: 0.9921\n","Epoch: 21, Valid Loss: 0.043, Valid Acc: 0.9880\n","Epoch: 22, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 22, Valid Loss: 0.044, Valid Acc: 0.9879\n","Epoch: 23, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 23, Valid Loss: 0.047, Valid Acc: 0.9887\n","Epoch: 24, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 24, Valid Loss: 0.039, Valid Acc: 0.9893\n","Epoch: 25, Train Loss: 0.027, Train Acc: 0.9918\n","Epoch: 25, Valid Loss: 0.043, Valid Acc: 0.9882\n","Epoch: 26, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 26, Valid Loss: 0.045, Valid Acc: 0.9873\n","Epoch: 27, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 27, Valid Loss: 0.045, Valid Acc: 0.9889\n","Epoch: 28, Train Loss: 0.025, Train Acc: 0.9923\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9875\n","Epoch: 29, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9905\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9918\n","Epoch: 30, Valid Loss: 0.042, Valid Acc: 0.9886\n","| \u001b[95m 90      \u001b[0m | \u001b[95m 0.9905  \u001b[0m | \u001b[95m 1.381e+0\u001b[0m | \u001b[95m 2.236   \u001b[0m |\n","Epoch: 1, Train Loss: 0.703, Train Acc: 0.7945\n","Epoch: 1, Valid Loss: 0.258, Valid Acc: 0.9353\n","Epoch: 2, Train Loss: 0.179, Train Acc: 0.9471\n","Epoch: 2, Valid Loss: 0.142, Valid Acc: 0.9642\n","Epoch: 3, Train Loss: 0.122, Train Acc: 0.9635\n","Epoch: 3, Valid Loss: 0.109, Valid Acc: 0.9711\n","Epoch: 4, Train Loss: 0.098, Train Acc: 0.9703\n","Epoch: 4, Valid Loss: 0.097, Valid Acc: 0.9734\n","Epoch: 5, Train Loss: 0.086, Train Acc: 0.9744\n","Epoch: 5, Valid Loss: 0.079, Valid Acc: 0.9782\n","Epoch: 6, Train Loss: 0.076, Train Acc: 0.9762\n","Epoch: 6, Valid Loss: 0.070, Valid Acc: 0.9801\n","Epoch: 7, Train Loss: 0.069, Train Acc: 0.9791\n","Epoch: 7, Valid Loss: 0.071, Valid Acc: 0.9813\n","Epoch: 8, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 8, Valid Loss: 0.064, Valid Acc: 0.9816\n","Epoch: 9, Train Loss: 0.061, Train Acc: 0.9813\n","Epoch: 9, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 10, Train Loss: 0.056, Train Acc: 0.9831\n","Epoch: 10, Valid Loss: 0.058, Valid Acc: 0.9827\n","Epoch: 11, Train Loss: 0.055, Train Acc: 0.9830\n","Epoch: 11, Valid Loss: 0.057, Valid Acc: 0.9836\n","Epoch: 12, Train Loss: 0.051, Train Acc: 0.9844\n","Epoch: 12, Valid Loss: 0.050, Valid Acc: 0.9843\n","Epoch: 13, Train Loss: 0.049, Train Acc: 0.9849\n","Epoch: 13, Valid Loss: 0.050, Valid Acc: 0.9859\n","Epoch: 14, Train Loss: 0.047, Train Acc: 0.9852\n","Epoch: 14, Valid Loss: 0.055, Valid Acc: 0.9858\n","Epoch: 15, Train Loss: 0.046, Train Acc: 0.9853\n","Epoch: 15, Valid Loss: 0.048, Valid Acc: 0.9853\n","Epoch: 16, Train Loss: 0.041, Train Acc: 0.9867\n","Epoch: 16, Valid Loss: 0.052, Valid Acc: 0.9855\n","Epoch: 17, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 17, Valid Loss: 0.048, Valid Acc: 0.9871\n","Epoch: 18, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 18, Valid Loss: 0.047, Valid Acc: 0.9871\n","Epoch: 19, Train Loss: 0.040, Train Acc: 0.9874\n","Epoch: 19, Valid Loss: 0.049, Valid Acc: 0.9865\n","Epoch: 20, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9865\n","Epoch: 21, Train Loss: 0.040, Train Acc: 0.9876\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9868\n","Epoch: 22, Train Loss: 0.040, Train Acc: 0.9876\n","Epoch: 22, Valid Loss: 0.048, Valid Acc: 0.9857\n","Epoch: 23, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 23, Valid Loss: 0.048, Valid Acc: 0.9858\n","Epoch: 24, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 24, Valid Loss: 0.047, Valid Acc: 0.9869\n","Epoch: 25, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 25, Valid Loss: 0.049, Valid Acc: 0.9868\n","Epoch: 26, Train Loss: 0.039, Train Acc: 0.9878\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9866\n","Epoch: 27, Train Loss: 0.038, Train Acc: 0.9880\n","Epoch: 27, Valid Loss: 0.045, Valid Acc: 0.9867\n","Epoch: 28, Train Loss: 0.038, Train Acc: 0.9878\n","Epoch: 28, Valid Loss: 0.048, Valid Acc: 0.9872\n","Epoch: 29, Train Loss: 0.038, Train Acc: 0.9880\n","Epoch: 29, Valid Loss: 0.047, Valid Acc: 0.9861\n","Epoch: 30, Train Loss: 0.038, Train Acc: 0.9877\n","Epoch: 30, Valid Loss: 0.046, Valid Acc: 0.9857\n","| \u001b[0m 91      \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 1.227e+0\u001b[0m | \u001b[0m 3.968   \u001b[0m |\n","Epoch: 1, Train Loss: 0.979, Train Acc: 0.7244\n","Epoch: 1, Valid Loss: 0.443, Valid Acc: 0.8951\n","Epoch: 2, Train Loss: 0.273, Train Acc: 0.9190\n","Epoch: 2, Valid Loss: 0.236, Valid Acc: 0.9486\n","Epoch: 3, Train Loss: 0.169, Train Acc: 0.9512\n","Epoch: 3, Valid Loss: 0.169, Valid Acc: 0.9601\n","Epoch: 4, Train Loss: 0.131, Train Acc: 0.9618\n","Epoch: 4, Valid Loss: 0.136, Valid Acc: 0.9674\n","Epoch: 5, Train Loss: 0.111, Train Acc: 0.9676\n","Epoch: 5, Valid Loss: 0.114, Valid Acc: 0.9708\n","Epoch: 6, Train Loss: 0.099, Train Acc: 0.9703\n","Epoch: 6, Valid Loss: 0.105, Valid Acc: 0.9733\n","Epoch: 7, Train Loss: 0.089, Train Acc: 0.9733\n","Epoch: 7, Valid Loss: 0.090, Valid Acc: 0.9770\n","Epoch: 8, Train Loss: 0.080, Train Acc: 0.9762\n","Epoch: 8, Valid Loss: 0.088, Valid Acc: 0.9772\n","Epoch: 9, Train Loss: 0.073, Train Acc: 0.9789\n","Epoch: 9, Valid Loss: 0.075, Valid Acc: 0.9795\n","Epoch: 10, Train Loss: 0.070, Train Acc: 0.9787\n","Epoch: 10, Valid Loss: 0.076, Valid Acc: 0.9819\n","Epoch: 11, Train Loss: 0.065, Train Acc: 0.9801\n","Epoch: 11, Valid Loss: 0.074, Valid Acc: 0.9803\n","Epoch: 12, Train Loss: 0.061, Train Acc: 0.9814\n","Epoch: 12, Valid Loss: 0.067, Valid Acc: 0.9828\n","Epoch: 13, Train Loss: 0.058, Train Acc: 0.9821\n","Epoch: 13, Valid Loss: 0.068, Valid Acc: 0.9819\n","Epoch: 14, Train Loss: 0.056, Train Acc: 0.9830\n","Epoch: 14, Valid Loss: 0.062, Valid Acc: 0.9834\n","Epoch: 15, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9854\n","Epoch: 16, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 16, Valid Loss: 0.062, Valid Acc: 0.9839\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9854\n","Epoch: 17, Valid Loss: 0.054, Valid Acc: 0.9847\n","Epoch: 18, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 18, Valid Loss: 0.054, Valid Acc: 0.9860\n","Epoch: 19, Train Loss: 0.047, Train Acc: 0.9857\n","Epoch: 19, Valid Loss: 0.051, Valid Acc: 0.9866\n","Epoch: 20, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 20, Valid Loss: 0.054, Valid Acc: 0.9834\n","Epoch: 21, Train Loss: 0.048, Train Acc: 0.9856\n","Epoch: 21, Valid Loss: 0.056, Valid Acc: 0.9853\n","Epoch: 22, Train Loss: 0.048, Train Acc: 0.9852\n","Epoch: 22, Valid Loss: 0.051, Valid Acc: 0.9861\n","Epoch: 23, Train Loss: 0.048, Train Acc: 0.9857\n","Epoch: 23, Valid Loss: 0.054, Valid Acc: 0.9843\n","Epoch: 24, Train Loss: 0.047, Train Acc: 0.9861\n","Epoch: 24, Valid Loss: 0.059, Valid Acc: 0.9851\n","Epoch: 25, Train Loss: 0.047, Train Acc: 0.9861\n","Epoch: 25, Valid Loss: 0.056, Valid Acc: 0.9841\n","Epoch: 26, Train Loss: 0.048, Train Acc: 0.9861\n","Epoch: 26, Valid Loss: 0.059, Valid Acc: 0.9841\n","Epoch: 27, Train Loss: 0.048, Train Acc: 0.9855\n","Epoch: 27, Valid Loss: 0.052, Valid Acc: 0.9836\n","Epoch: 28, Train Loss: 0.046, Train Acc: 0.9862\n","Epoch: 28, Valid Loss: 0.057, Valid Acc: 0.9835\n","Epoch: 29, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 29, Valid Loss: 0.049, Valid Acc: 0.9867\n","Epoch: 30, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 30, Valid Loss: 0.055, Valid Acc: 0.9854\n","| \u001b[0m 92      \u001b[0m | \u001b[0m 0.9867  \u001b[0m | \u001b[0m 1.971e+0\u001b[0m | \u001b[0m 3.901   \u001b[0m |\n","Epoch: 1, Train Loss: 0.476, Train Acc: 0.8527\n","Epoch: 1, Valid Loss: 0.150, Valid Acc: 0.9614\n","Epoch: 2, Train Loss: 0.112, Train Acc: 0.9660\n","Epoch: 2, Valid Loss: 0.092, Valid Acc: 0.9742\n","Epoch: 3, Train Loss: 0.082, Train Acc: 0.9749\n","Epoch: 3, Valid Loss: 0.080, Valid Acc: 0.9775\n","Epoch: 4, Train Loss: 0.068, Train Acc: 0.9789\n","Epoch: 4, Valid Loss: 0.074, Valid Acc: 0.9791\n","Epoch: 5, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 5, Valid Loss: 0.059, Valid Acc: 0.9832\n","Epoch: 6, Train Loss: 0.053, Train Acc: 0.9835\n","Epoch: 6, Valid Loss: 0.052, Valid Acc: 0.9847\n","Epoch: 7, Train Loss: 0.049, Train Acc: 0.9849\n","Epoch: 7, Valid Loss: 0.051, Valid Acc: 0.9843\n","Epoch: 8, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 8, Valid Loss: 0.044, Valid Acc: 0.9872\n","Epoch: 9, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 9, Valid Loss: 0.047, Valid Acc: 0.9865\n","Epoch: 10, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 10, Valid Loss: 0.045, Valid Acc: 0.9857\n","Epoch: 11, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 11, Valid Loss: 0.047, Valid Acc: 0.9871\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9883\n","Epoch: 12, Valid Loss: 0.044, Valid Acc: 0.9867\n","Epoch: 13, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 13, Valid Loss: 0.038, Valid Acc: 0.9887\n","Epoch: 14, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 14, Valid Loss: 0.042, Valid Acc: 0.9878\n","Epoch: 15, Train Loss: 0.029, Train Acc: 0.9908\n","Epoch: 15, Valid Loss: 0.044, Valid Acc: 0.9885\n","Epoch: 16, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 16, Valid Loss: 0.043, Valid Acc: 0.9874\n","Epoch: 17, Train Loss: 0.027, Train Acc: 0.9912\n","Epoch: 17, Valid Loss: 0.040, Valid Acc: 0.9872\n","Epoch: 18, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 18, Valid Loss: 0.042, Valid Acc: 0.9867\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 19, Valid Loss: 0.037, Valid Acc: 0.9888\n","Epoch: 20, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 20, Valid Loss: 0.042, Valid Acc: 0.9886\n","Epoch: 21, Train Loss: 0.025, Train Acc: 0.9917\n","Epoch: 21, Valid Loss: 0.038, Valid Acc: 0.9892\n","Epoch: 22, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 22, Valid Loss: 0.041, Valid Acc: 0.9885\n","Epoch: 23, Train Loss: 0.027, Train Acc: 0.9919\n","Epoch: 23, Valid Loss: 0.037, Valid Acc: 0.9889\n","Epoch: 24, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 24, Valid Loss: 0.040, Valid Acc: 0.9877\n","Epoch: 25, Train Loss: 0.025, Train Acc: 0.9922\n","Epoch: 25, Valid Loss: 0.039, Valid Acc: 0.9883\n","Epoch: 26, Train Loss: 0.025, Train Acc: 0.9923\n","Epoch: 26, Valid Loss: 0.039, Valid Acc: 0.9881\n","Epoch: 27, Train Loss: 0.024, Train Acc: 0.9923\n","Epoch: 27, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 28, Train Loss: 0.023, Train Acc: 0.9927\n","Epoch: 28, Valid Loss: 0.040, Valid Acc: 0.9883\n","Epoch: 29, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 29, Valid Loss: 0.035, Valid Acc: 0.9900\n","Epoch: 30, Train Loss: 0.023, Train Acc: 0.9927\n","Epoch: 30, Valid Loss: 0.037, Valid Acc: 0.9895\n","| \u001b[0m 93      \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 1.228e+0\u001b[0m | \u001b[0m 1.03    \u001b[0m |\n","Epoch: 1, Train Loss: 272.022, Train Acc: 0.1078\n","Epoch: 1, Valid Loss: 2.376, Valid Acc: 0.1010\n","Epoch: 2, Train Loss: 2.309, Train Acc: 0.1061\n","Epoch: 2, Valid Loss: 2.362, Valid Acc: 0.1010\n","Epoch: 3, Train Loss: 2.306, Train Acc: 0.1100\n","Epoch: 3, Valid Loss: 2.361, Valid Acc: 0.1135\n","| \u001b[0m 94      \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.465e+0\u001b[0m | \u001b[0m 0.3251  \u001b[0m |\n","Epoch: 1, Train Loss: 0.748, Train Acc: 0.7726\n","Epoch: 1, Valid Loss: 0.264, Valid Acc: 0.9363\n","Epoch: 2, Train Loss: 0.186, Train Acc: 0.9456\n","Epoch: 2, Valid Loss: 0.157, Valid Acc: 0.9601\n","Epoch: 3, Train Loss: 0.129, Train Acc: 0.9623\n","Epoch: 3, Valid Loss: 0.118, Valid Acc: 0.9702\n","Epoch: 4, Train Loss: 0.103, Train Acc: 0.9694\n","Epoch: 4, Valid Loss: 0.099, Valid Acc: 0.9740\n","Epoch: 5, Train Loss: 0.088, Train Acc: 0.9729\n","Epoch: 5, Valid Loss: 0.084, Valid Acc: 0.9757\n","Epoch: 6, Train Loss: 0.079, Train Acc: 0.9760\n","Epoch: 6, Valid Loss: 0.083, Valid Acc: 0.9772\n","Epoch: 7, Train Loss: 0.074, Train Acc: 0.9783\n","Epoch: 7, Valid Loss: 0.069, Valid Acc: 0.9799\n","Epoch: 8, Train Loss: 0.069, Train Acc: 0.9789\n","Epoch: 8, Valid Loss: 0.066, Valid Acc: 0.9810\n","Epoch: 9, Train Loss: 0.063, Train Acc: 0.9811\n","Epoch: 9, Valid Loss: 0.069, Valid Acc: 0.9816\n","Epoch: 10, Train Loss: 0.058, Train Acc: 0.9825\n","Epoch: 10, Valid Loss: 0.058, Valid Acc: 0.9835\n","Epoch: 11, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 11, Valid Loss: 0.061, Valid Acc: 0.9821\n","Epoch: 12, Train Loss: 0.052, Train Acc: 0.9847\n","Epoch: 12, Valid Loss: 0.055, Valid Acc: 0.9838\n","Epoch: 13, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 13, Valid Loss: 0.056, Valid Acc: 0.9828\n","Epoch: 14, Train Loss: 0.048, Train Acc: 0.9858\n","Epoch: 14, Valid Loss: 0.052, Valid Acc: 0.9847\n","Epoch: 15, Train Loss: 0.045, Train Acc: 0.9866\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9852\n","Epoch: 16, Train Loss: 0.043, Train Acc: 0.9866\n","Epoch: 16, Valid Loss: 0.051, Valid Acc: 0.9856\n","Epoch: 17, Train Loss: 0.042, Train Acc: 0.9867\n","Epoch: 17, Valid Loss: 0.050, Valid Acc: 0.9855\n","Epoch: 18, Train Loss: 0.039, Train Acc: 0.9883\n","Epoch: 18, Valid Loss: 0.051, Valid Acc: 0.9854\n","Epoch: 19, Train Loss: 0.038, Train Acc: 0.9882\n","Epoch: 19, Valid Loss: 0.049, Valid Acc: 0.9854\n","Epoch: 20, Train Loss: 0.038, Train Acc: 0.9885\n","Epoch: 20, Valid Loss: 0.045, Valid Acc: 0.9863\n","Epoch: 21, Train Loss: 0.037, Train Acc: 0.9890\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9857\n","Epoch: 22, Train Loss: 0.037, Train Acc: 0.9883\n","Epoch: 22, Valid Loss: 0.046, Valid Acc: 0.9870\n","Epoch: 23, Train Loss: 0.038, Train Acc: 0.9884\n","Epoch: 23, Valid Loss: 0.049, Valid Acc: 0.9863\n","Epoch: 24, Train Loss: 0.037, Train Acc: 0.9890\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9866\n","Epoch: 25, Train Loss: 0.037, Train Acc: 0.9887\n","Epoch: 25, Valid Loss: 0.046, Valid Acc: 0.9865\n","Epoch: 26, Train Loss: 0.035, Train Acc: 0.9890\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9855\n","Epoch: 27, Train Loss: 0.036, Train Acc: 0.9888\n","Epoch: 27, Valid Loss: 0.046, Valid Acc: 0.9869\n","Epoch: 28, Train Loss: 0.035, Train Acc: 0.9891\n","Epoch: 28, Valid Loss: 0.045, Valid Acc: 0.9872\n","Epoch: 29, Train Loss: 0.035, Train Acc: 0.9896\n","Epoch: 29, Valid Loss: 0.046, Valid Acc: 0.9866\n","Epoch: 30, Train Loss: 0.036, Train Acc: 0.9889\n","Epoch: 30, Valid Loss: 0.046, Valid Acc: 0.9856\n","| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9872  \u001b[0m | \u001b[0m 1.219e+0\u001b[0m | \u001b[0m 3.946   \u001b[0m |\n","Epoch: 1, Train Loss: 1.043, Train Acc: 0.6934\n","Epoch: 1, Valid Loss: 0.372, Valid Acc: 0.8870\n","Epoch: 2, Train Loss: 0.291, Train Acc: 0.9130\n","Epoch: 2, Valid Loss: 0.199, Valid Acc: 0.9419\n","Epoch: 3, Train Loss: 0.190, Train Acc: 0.9448\n","Epoch: 3, Valid Loss: 0.159, Valid Acc: 0.9553\n","Epoch: 4, Train Loss: 0.147, Train Acc: 0.9565\n","Epoch: 4, Valid Loss: 0.125, Valid Acc: 0.9653\n","Epoch: 5, Train Loss: 0.126, Train Acc: 0.9624\n","Epoch: 5, Valid Loss: 0.106, Valid Acc: 0.9712\n","Epoch: 6, Train Loss: 0.111, Train Acc: 0.9670\n","Epoch: 6, Valid Loss: 0.094, Valid Acc: 0.9727\n","Epoch: 7, Train Loss: 0.100, Train Acc: 0.9704\n","Epoch: 7, Valid Loss: 0.086, Valid Acc: 0.9753\n","Epoch: 8, Train Loss: 0.091, Train Acc: 0.9731\n","Epoch: 8, Valid Loss: 0.084, Valid Acc: 0.9753\n","Epoch: 9, Train Loss: 0.084, Train Acc: 0.9750\n","Epoch: 9, Valid Loss: 0.076, Valid Acc: 0.9754\n","Epoch: 10, Train Loss: 0.080, Train Acc: 0.9754\n","Epoch: 10, Valid Loss: 0.072, Valid Acc: 0.9775\n","Epoch: 11, Train Loss: 0.073, Train Acc: 0.9775\n","Epoch: 11, Valid Loss: 0.068, Valid Acc: 0.9783\n","Epoch: 12, Train Loss: 0.071, Train Acc: 0.9781\n","Epoch: 12, Valid Loss: 0.064, Valid Acc: 0.9789\n","Epoch: 13, Train Loss: 0.068, Train Acc: 0.9798\n","Epoch: 13, Valid Loss: 0.058, Valid Acc: 0.9824\n","Epoch: 14, Train Loss: 0.064, Train Acc: 0.9804\n","Epoch: 14, Valid Loss: 0.063, Valid Acc: 0.9808\n","Epoch: 15, Train Loss: 0.064, Train Acc: 0.9806\n","Epoch: 15, Valid Loss: 0.059, Valid Acc: 0.9822\n","Epoch: 16, Train Loss: 0.060, Train Acc: 0.9819\n","Epoch: 16, Valid Loss: 0.055, Valid Acc: 0.9830\n","Epoch: 17, Train Loss: 0.058, Train Acc: 0.9829\n","Epoch: 17, Valid Loss: 0.053, Valid Acc: 0.9833\n","Epoch: 18, Train Loss: 0.057, Train Acc: 0.9831\n","Epoch: 18, Valid Loss: 0.058, Valid Acc: 0.9815\n","Epoch: 19, Train Loss: 0.055, Train Acc: 0.9834\n","Epoch: 19, Valid Loss: 0.055, Valid Acc: 0.9825\n","Epoch: 20, Train Loss: 0.053, Train Acc: 0.9841\n","Epoch: 20, Valid Loss: 0.052, Valid Acc: 0.9829\n","Epoch: 21, Train Loss: 0.052, Train Acc: 0.9838\n","Epoch: 21, Valid Loss: 0.054, Valid Acc: 0.9833\n","Epoch: 22, Train Loss: 0.054, Train Acc: 0.9846\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9820\n","Epoch: 23, Train Loss: 0.051, Train Acc: 0.9840\n","Epoch: 23, Valid Loss: 0.051, Valid Acc: 0.9841\n","Epoch: 24, Train Loss: 0.054, Train Acc: 0.9845\n","Epoch: 24, Valid Loss: 0.055, Valid Acc: 0.9822\n","Epoch: 25, Train Loss: 0.053, Train Acc: 0.9843\n","Epoch: 25, Valid Loss: 0.053, Valid Acc: 0.9829\n","Epoch: 26, Train Loss: 0.054, Train Acc: 0.9844\n","Epoch: 26, Valid Loss: 0.053, Valid Acc: 0.9840\n","Epoch: 27, Train Loss: 0.049, Train Acc: 0.9848\n","Epoch: 27, Valid Loss: 0.049, Valid Acc: 0.9838\n","Epoch: 28, Train Loss: 0.051, Train Acc: 0.9844\n","Epoch: 28, Valid Loss: 0.052, Valid Acc: 0.9835\n","Epoch: 29, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 29, Valid Loss: 0.052, Valid Acc: 0.9836\n","Epoch: 30, Train Loss: 0.050, Train Acc: 0.9849\n","Epoch: 30, Valid Loss: 0.051, Valid Acc: 0.9826\n","| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9841  \u001b[0m | \u001b[0m 1.462e+0\u001b[0m | \u001b[0m 3.624   \u001b[0m |\n","Epoch: 1, Train Loss: 0.835, Train Acc: 0.7509\n","Epoch: 1, Valid Loss: 0.274, Valid Acc: 0.9214\n","Epoch: 2, Train Loss: 0.206, Train Acc: 0.9391\n","Epoch: 2, Valid Loss: 0.146, Valid Acc: 0.9583\n","Epoch: 3, Train Loss: 0.136, Train Acc: 0.9597\n","Epoch: 3, Valid Loss: 0.107, Valid Acc: 0.9685\n","Epoch: 4, Train Loss: 0.107, Train Acc: 0.9684\n","Epoch: 4, Valid Loss: 0.090, Valid Acc: 0.9739\n","Epoch: 5, Train Loss: 0.092, Train Acc: 0.9722\n","Epoch: 5, Valid Loss: 0.078, Valid Acc: 0.9772\n","Epoch: 6, Train Loss: 0.081, Train Acc: 0.9755\n","Epoch: 6, Valid Loss: 0.070, Valid Acc: 0.9804\n","Epoch: 7, Train Loss: 0.072, Train Acc: 0.9779\n","Epoch: 7, Valid Loss: 0.064, Valid Acc: 0.9796\n","Epoch: 8, Train Loss: 0.068, Train Acc: 0.9793\n","Epoch: 8, Valid Loss: 0.063, Valid Acc: 0.9802\n","Epoch: 9, Train Loss: 0.063, Train Acc: 0.9800\n","Epoch: 9, Valid Loss: 0.060, Valid Acc: 0.9813\n","Epoch: 10, Train Loss: 0.059, Train Acc: 0.9818\n","Epoch: 10, Valid Loss: 0.055, Valid Acc: 0.9839\n","Epoch: 11, Train Loss: 0.055, Train Acc: 0.9829\n","Epoch: 11, Valid Loss: 0.055, Valid Acc: 0.9830\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9838\n","Epoch: 12, Valid Loss: 0.052, Valid Acc: 0.9840\n","Epoch: 13, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 13, Valid Loss: 0.053, Valid Acc: 0.9836\n","Epoch: 14, Train Loss: 0.048, Train Acc: 0.9848\n","Epoch: 14, Valid Loss: 0.048, Valid Acc: 0.9847\n","Epoch: 15, Train Loss: 0.047, Train Acc: 0.9854\n","Epoch: 15, Valid Loss: 0.043, Valid Acc: 0.9858\n","Epoch: 16, Train Loss: 0.046, Train Acc: 0.9859\n","Epoch: 16, Valid Loss: 0.048, Valid Acc: 0.9846\n","Epoch: 17, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 17, Valid Loss: 0.043, Valid Acc: 0.9857\n","Epoch: 18, Train Loss: 0.041, Train Acc: 0.9871\n","Epoch: 18, Valid Loss: 0.046, Valid Acc: 0.9857\n","Epoch: 19, Train Loss: 0.041, Train Acc: 0.9869\n","Epoch: 19, Valid Loss: 0.045, Valid Acc: 0.9854\n","Epoch: 20, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 20, Valid Loss: 0.046, Valid Acc: 0.9852\n","Epoch: 21, Train Loss: 0.040, Train Acc: 0.9874\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9852\n","Epoch: 22, Train Loss: 0.040, Train Acc: 0.9874\n","Epoch: 22, Valid Loss: 0.044, Valid Acc: 0.9861\n","Epoch: 23, Train Loss: 0.039, Train Acc: 0.9874\n","Epoch: 23, Valid Loss: 0.041, Valid Acc: 0.9871\n","Epoch: 24, Train Loss: 0.039, Train Acc: 0.9877\n","Epoch: 24, Valid Loss: 0.044, Valid Acc: 0.9860\n","Epoch: 25, Train Loss: 0.039, Train Acc: 0.9884\n","Epoch: 25, Valid Loss: 0.041, Valid Acc: 0.9876\n","Epoch: 26, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 26, Valid Loss: 0.045, Valid Acc: 0.9849\n","Epoch: 27, Train Loss: 0.040, Train Acc: 0.9883\n","Epoch: 27, Valid Loss: 0.044, Valid Acc: 0.9859\n","Epoch: 28, Train Loss: 0.039, Train Acc: 0.9881\n","Epoch: 28, Valid Loss: 0.041, Valid Acc: 0.9867\n","Epoch: 29, Train Loss: 0.039, Train Acc: 0.9884\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9863\n","Epoch: 30, Train Loss: 0.039, Train Acc: 0.9878\n","Epoch: 30, Valid Loss: 0.044, Valid Acc: 0.9854\n","| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9876  \u001b[0m | \u001b[0m 1.467e+0\u001b[0m | \u001b[0m 3.952   \u001b[0m |\n","Epoch: 1, Train Loss: 0.936, Train Acc: 0.7418\n","Epoch: 1, Valid Loss: 0.361, Valid Acc: 0.9058\n","Epoch: 2, Train Loss: 0.261, Train Acc: 0.9213\n","Epoch: 2, Valid Loss: 0.246, Valid Acc: 0.9370\n","Epoch: 3, Train Loss: 0.187, Train Acc: 0.9426\n","Epoch: 3, Valid Loss: 0.189, Valid Acc: 0.9494\n","Epoch: 4, Train Loss: 0.161, Train Acc: 0.9512\n","Epoch: 4, Valid Loss: 0.163, Valid Acc: 0.9567\n","Epoch: 5, Train Loss: 0.150, Train Acc: 0.9549\n","Epoch: 5, Valid Loss: 0.173, Valid Acc: 0.9596\n","Epoch: 6, Train Loss: 0.135, Train Acc: 0.9595\n","Epoch: 6, Valid Loss: 0.149, Valid Acc: 0.9637\n","Epoch: 7, Train Loss: 0.134, Train Acc: 0.9591\n","Epoch: 7, Valid Loss: 0.136, Valid Acc: 0.9644\n","Epoch: 8, Train Loss: 0.128, Train Acc: 0.9616\n","Epoch: 8, Valid Loss: 0.135, Valid Acc: 0.9643\n","Epoch: 9, Train Loss: 0.122, Train Acc: 0.9616\n","Epoch: 9, Valid Loss: 0.135, Valid Acc: 0.9639\n","Epoch: 10, Train Loss: 0.118, Train Acc: 0.9646\n","Epoch: 10, Valid Loss: 0.128, Valid Acc: 0.9676\n","Epoch: 11, Train Loss: 0.118, Train Acc: 0.9642\n","Epoch: 11, Valid Loss: 0.136, Valid Acc: 0.9639\n","Epoch: 12, Train Loss: 0.106, Train Acc: 0.9680\n","Epoch: 12, Valid Loss: 0.116, Valid Acc: 0.9727\n","Epoch: 13, Train Loss: 0.103, Train Acc: 0.9686\n","Epoch: 13, Valid Loss: 0.119, Valid Acc: 0.9706\n","Epoch: 14, Train Loss: 0.100, Train Acc: 0.9698\n","Epoch: 14, Valid Loss: 0.115, Valid Acc: 0.9701\n","Epoch: 15, Train Loss: 0.095, Train Acc: 0.9702\n","Epoch: 15, Valid Loss: 0.106, Valid Acc: 0.9739\n","Epoch: 16, Train Loss: 0.096, Train Acc: 0.9704\n","Epoch: 16, Valid Loss: 0.107, Valid Acc: 0.9716\n","Epoch: 17, Train Loss: 0.095, Train Acc: 0.9720\n","Epoch: 17, Valid Loss: 0.103, Valid Acc: 0.9712\n","Epoch: 18, Train Loss: 0.093, Train Acc: 0.9713\n","Epoch: 18, Valid Loss: 0.121, Valid Acc: 0.9715\n","Epoch: 19, Train Loss: 0.095, Train Acc: 0.9705\n","Epoch: 19, Valid Loss: 0.102, Valid Acc: 0.9705\n","Epoch: 20, Train Loss: 0.096, Train Acc: 0.9705\n","Epoch: 20, Valid Loss: 0.104, Valid Acc: 0.9740\n","| \u001b[0m 98      \u001b[0m | \u001b[0m 0.974   \u001b[0m | \u001b[0m 1.968e+0\u001b[0m | \u001b[0m 0.01755 \u001b[0m |\n","Epoch: 1, Train Loss: 0.790, Train Acc: 0.7682\n","Epoch: 1, Valid Loss: 0.285, Valid Acc: 0.9271\n","Epoch: 2, Train Loss: 0.205, Train Acc: 0.9386\n","Epoch: 2, Valid Loss: 0.169, Valid Acc: 0.9603\n","Epoch: 3, Train Loss: 0.138, Train Acc: 0.9591\n","Epoch: 3, Valid Loss: 0.123, Valid Acc: 0.9666\n","Epoch: 4, Train Loss: 0.110, Train Acc: 0.9679\n","Epoch: 4, Valid Loss: 0.104, Valid Acc: 0.9727\n","Epoch: 5, Train Loss: 0.094, Train Acc: 0.9713\n","Epoch: 5, Valid Loss: 0.093, Valid Acc: 0.9749\n","Epoch: 6, Train Loss: 0.084, Train Acc: 0.9746\n","Epoch: 6, Valid Loss: 0.085, Valid Acc: 0.9777\n","Epoch: 7, Train Loss: 0.075, Train Acc: 0.9774\n","Epoch: 7, Valid Loss: 0.075, Valid Acc: 0.9802\n","Epoch: 8, Train Loss: 0.068, Train Acc: 0.9794\n","Epoch: 8, Valid Loss: 0.067, Valid Acc: 0.9816\n","Epoch: 9, Train Loss: 0.065, Train Acc: 0.9804\n","Epoch: 9, Valid Loss: 0.065, Valid Acc: 0.9818\n","Epoch: 10, Train Loss: 0.060, Train Acc: 0.9819\n","Epoch: 10, Valid Loss: 0.061, Valid Acc: 0.9825\n","Epoch: 11, Train Loss: 0.057, Train Acc: 0.9826\n","Epoch: 11, Valid Loss: 0.060, Valid Acc: 0.9840\n","Epoch: 12, Train Loss: 0.054, Train Acc: 0.9837\n","Epoch: 12, Valid Loss: 0.059, Valid Acc: 0.9849\n","Epoch: 13, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 13, Valid Loss: 0.062, Valid Acc: 0.9839\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 14, Valid Loss: 0.055, Valid Acc: 0.9840\n","Epoch: 15, Train Loss: 0.049, Train Acc: 0.9850\n","Epoch: 15, Valid Loss: 0.054, Valid Acc: 0.9851\n","Epoch: 16, Train Loss: 0.047, Train Acc: 0.9850\n","Epoch: 16, Valid Loss: 0.058, Valid Acc: 0.9834\n","Epoch: 17, Train Loss: 0.044, Train Acc: 0.9863\n","Epoch: 17, Valid Loss: 0.049, Valid Acc: 0.9863\n","Epoch: 18, Train Loss: 0.041, Train Acc: 0.9871\n","Epoch: 18, Valid Loss: 0.054, Valid Acc: 0.9859\n","Epoch: 19, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 19, Valid Loss: 0.054, Valid Acc: 0.9845\n","Epoch: 20, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 20, Valid Loss: 0.053, Valid Acc: 0.9858\n","Epoch: 21, Train Loss: 0.041, Train Acc: 0.9880\n","Epoch: 21, Valid Loss: 0.051, Valid Acc: 0.9854\n","Epoch: 22, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 22, Valid Loss: 0.049, Valid Acc: 0.9850\n","Epoch: 23, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 23, Valid Loss: 0.051, Valid Acc: 0.9868\n","Epoch: 24, Train Loss: 0.040, Train Acc: 0.9880\n","Epoch: 24, Valid Loss: 0.049, Valid Acc: 0.9864\n","Epoch: 25, Train Loss: 0.040, Train Acc: 0.9879\n","Epoch: 25, Valid Loss: 0.054, Valid Acc: 0.9850\n","Epoch: 26, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 26, Valid Loss: 0.050, Valid Acc: 0.9859\n","Epoch: 27, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 27, Valid Loss: 0.051, Valid Acc: 0.9854\n","Epoch: 28, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 28, Valid Loss: 0.052, Valid Acc: 0.9880\n","Epoch: 29, Train Loss: 0.038, Train Acc: 0.9879\n","Epoch: 29, Valid Loss: 0.052, Valid Acc: 0.9856\n","Epoch: 30, Train Loss: 0.039, Train Acc: 0.9878\n","Epoch: 30, Valid Loss: 0.051, Valid Acc: 0.9863\n","| \u001b[0m 99      \u001b[0m | \u001b[0m 0.988   \u001b[0m | \u001b[0m 1.368e+0\u001b[0m | \u001b[0m 3.963   \u001b[0m |\n","Epoch: 1, Train Loss: 159.939, Train Acc: 0.1029\n","Epoch: 1, Valid Loss: 2.368, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.326, Train Acc: 0.1022\n","Epoch: 2, Valid Loss: 2.370, Valid Acc: 0.1028\n","Epoch: 3, Train Loss: 2.328, Train Acc: 0.1037\n","Epoch: 3, Valid Loss: 2.357, Valid Acc: 0.1135\n","| \u001b[0m 100     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 0.6387  \u001b[0m |\n","Epoch: 1, Train Loss: 1.014, Train Acc: 0.7064\n","Epoch: 1, Valid Loss: 0.425, Valid Acc: 0.8956\n","Epoch: 2, Train Loss: 0.268, Train Acc: 0.9213\n","Epoch: 2, Valid Loss: 0.235, Valid Acc: 0.9462\n","Epoch: 3, Train Loss: 0.167, Train Acc: 0.9516\n","Epoch: 3, Valid Loss: 0.159, Valid Acc: 0.9634\n","Epoch: 4, Train Loss: 0.129, Train Acc: 0.9620\n","Epoch: 4, Valid Loss: 0.124, Valid Acc: 0.9686\n","Epoch: 5, Train Loss: 0.107, Train Acc: 0.9680\n","Epoch: 5, Valid Loss: 0.105, Valid Acc: 0.9723\n","Epoch: 6, Train Loss: 0.094, Train Acc: 0.9723\n","Epoch: 6, Valid Loss: 0.089, Valid Acc: 0.9762\n","Epoch: 7, Train Loss: 0.084, Train Acc: 0.9752\n","Epoch: 7, Valid Loss: 0.078, Valid Acc: 0.9786\n","Epoch: 8, Train Loss: 0.078, Train Acc: 0.9766\n","Epoch: 8, Valid Loss: 0.082, Valid Acc: 0.9797\n","Epoch: 9, Train Loss: 0.071, Train Acc: 0.9787\n","Epoch: 9, Valid Loss: 0.084, Valid Acc: 0.9805\n","Epoch: 10, Train Loss: 0.068, Train Acc: 0.9798\n","Epoch: 10, Valid Loss: 0.068, Valid Acc: 0.9817\n","Epoch: 11, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 11, Valid Loss: 0.057, Valid Acc: 0.9837\n","Epoch: 12, Train Loss: 0.060, Train Acc: 0.9820\n","Epoch: 12, Valid Loss: 0.062, Valid Acc: 0.9822\n","Epoch: 13, Train Loss: 0.060, Train Acc: 0.9825\n","Epoch: 13, Valid Loss: 0.058, Valid Acc: 0.9832\n","Epoch: 14, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 14, Valid Loss: 0.056, Valid Acc: 0.9843\n","Epoch: 15, Train Loss: 0.053, Train Acc: 0.9842\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9864\n","Epoch: 16, Train Loss: 0.050, Train Acc: 0.9844\n","Epoch: 16, Valid Loss: 0.053, Valid Acc: 0.9832\n","Epoch: 17, Train Loss: 0.048, Train Acc: 0.9855\n","Epoch: 17, Valid Loss: 0.056, Valid Acc: 0.9850\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9851\n","Epoch: 18, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 19, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 19, Valid Loss: 0.062, Valid Acc: 0.9832\n","Epoch: 20, Train Loss: 0.047, Train Acc: 0.9856\n","Epoch: 20, Valid Loss: 0.053, Valid Acc: 0.9848\n","Epoch: 21, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 21, Valid Loss: 0.058, Valid Acc: 0.9848\n","Epoch: 22, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 22, Valid Loss: 0.050, Valid Acc: 0.9847\n","Epoch: 23, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 23, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 24, Train Loss: 0.046, Train Acc: 0.9859\n","Epoch: 24, Valid Loss: 0.048, Valid Acc: 0.9843\n","Epoch: 25, Train Loss: 0.046, Train Acc: 0.9860\n","Epoch: 25, Valid Loss: 0.051, Valid Acc: 0.9842\n","Epoch: 26, Train Loss: 0.046, Train Acc: 0.9858\n","Epoch: 26, Valid Loss: 0.051, Valid Acc: 0.9837\n","Epoch: 27, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 27, Valid Loss: 0.050, Valid Acc: 0.9861\n","Epoch: 28, Train Loss: 0.044, Train Acc: 0.9868\n","Epoch: 28, Valid Loss: 0.053, Valid Acc: 0.9850\n","Epoch: 29, Train Loss: 0.045, Train Acc: 0.9871\n","Epoch: 29, Valid Loss: 0.050, Valid Acc: 0.9843\n","Epoch: 30, Train Loss: 0.046, Train Acc: 0.9865\n","Epoch: 30, Valid Loss: 0.049, Valid Acc: 0.9860\n","| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 1.98e+03\u001b[0m | \u001b[0m 3.96    \u001b[0m |\n","Epoch: 1, Train Loss: 0.353, Train Acc: 0.8933\n","Epoch: 1, Valid Loss: 0.116, Valid Acc: 0.9662\n","Epoch: 2, Train Loss: 0.100, Train Acc: 0.9690\n","Epoch: 2, Valid Loss: 0.074, Valid Acc: 0.9782\n","Epoch: 3, Train Loss: 0.077, Train Acc: 0.9769\n","Epoch: 3, Valid Loss: 0.064, Valid Acc: 0.9795\n","Epoch: 4, Train Loss: 0.063, Train Acc: 0.9807\n","Epoch: 4, Valid Loss: 0.053, Valid Acc: 0.9822\n","Epoch: 5, Train Loss: 0.057, Train Acc: 0.9827\n","Epoch: 5, Valid Loss: 0.050, Valid Acc: 0.9840\n","Epoch: 6, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 6, Valid Loss: 0.045, Valid Acc: 0.9867\n","Epoch: 7, Train Loss: 0.047, Train Acc: 0.9857\n","Epoch: 7, Valid Loss: 0.049, Valid Acc: 0.9856\n","Epoch: 8, Train Loss: 0.044, Train Acc: 0.9864\n","Epoch: 8, Valid Loss: 0.044, Valid Acc: 0.9865\n","Epoch: 9, Train Loss: 0.040, Train Acc: 0.9874\n","Epoch: 9, Valid Loss: 0.042, Valid Acc: 0.9858\n","Epoch: 10, Train Loss: 0.038, Train Acc: 0.9880\n","Epoch: 10, Valid Loss: 0.043, Valid Acc: 0.9868\n","Epoch: 11, Train Loss: 0.036, Train Acc: 0.9886\n","Epoch: 11, Valid Loss: 0.041, Valid Acc: 0.9881\n","Epoch: 12, Train Loss: 0.035, Train Acc: 0.9881\n","Epoch: 12, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 13, Train Loss: 0.034, Train Acc: 0.9890\n","Epoch: 13, Valid Loss: 0.044, Valid Acc: 0.9867\n","Epoch: 14, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 14, Valid Loss: 0.033, Valid Acc: 0.9901\n","Epoch: 15, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 15, Valid Loss: 0.037, Valid Acc: 0.9881\n","Epoch: 16, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 16, Valid Loss: 0.039, Valid Acc: 0.9888\n","Epoch: 17, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 17, Valid Loss: 0.036, Valid Acc: 0.9887\n","Epoch: 18, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 18, Valid Loss: 0.037, Valid Acc: 0.9888\n","Epoch: 19, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 19, Valid Loss: 0.039, Valid Acc: 0.9876\n","Epoch: 20, Train Loss: 0.024, Train Acc: 0.9925\n","Epoch: 20, Valid Loss: 0.036, Valid Acc: 0.9882\n","Epoch: 21, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 21, Valid Loss: 0.031, Valid Acc: 0.9896\n","Epoch: 22, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 22, Valid Loss: 0.033, Valid Acc: 0.9900\n","Epoch: 23, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 23, Valid Loss: 0.036, Valid Acc: 0.9896\n","Epoch: 24, Train Loss: 0.025, Train Acc: 0.9922\n","Epoch: 24, Valid Loss: 0.033, Valid Acc: 0.9904\n","Epoch: 25, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9895\n","Epoch: 26, Train Loss: 0.023, Train Acc: 0.9923\n","Epoch: 26, Valid Loss: 0.035, Valid Acc: 0.9884\n","Epoch: 27, Train Loss: 0.023, Train Acc: 0.9927\n","Epoch: 27, Valid Loss: 0.035, Valid Acc: 0.9884\n","Epoch: 28, Train Loss: 0.023, Train Acc: 0.9924\n","Epoch: 28, Valid Loss: 0.037, Valid Acc: 0.9876\n","Epoch: 29, Train Loss: 0.023, Train Acc: 0.9927\n","Epoch: 29, Valid Loss: 0.035, Valid Acc: 0.9886\n","Epoch: 30, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 30, Valid Loss: 0.036, Valid Acc: 0.9890\n","| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9904  \u001b[0m | \u001b[0m 313.4   \u001b[0m | \u001b[0m 3.904   \u001b[0m |\n","Epoch: 1, Train Loss: 2662.305, Train Acc: 0.1003\n","Epoch: 1, Valid Loss: 2.405, Valid Acc: 0.1032\n","Epoch: 2, Train Loss: 2.334, Train Acc: 0.1038\n","Epoch: 2, Valid Loss: 2.385, Valid Acc: 0.1028\n","Epoch: 3, Train Loss: 2.328, Train Acc: 0.1081\n","Epoch: 3, Valid Loss: 2.385, Valid Acc: 0.0892\n","| \u001b[0m 103     \u001b[0m | \u001b[0m 0.1032  \u001b[0m | \u001b[0m 1.479e+0\u001b[0m | \u001b[0m 0.9196  \u001b[0m |\n","Epoch: 1, Train Loss: 5.024, Train Acc: 0.1187\n","Epoch: 1, Valid Loss: 2.736, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.356, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.735, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.356, Train Acc: 0.1124\n","Epoch: 3, Valid Loss: 2.734, Valid Acc: 0.1135\n","| \u001b[0m 104     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.981e+0\u001b[0m | \u001b[0m 1.545   \u001b[0m |\n","Epoch: 1, Train Loss: 58.418, Train Acc: 0.1155\n","Epoch: 1, Valid Loss: 2.539, Valid Acc: 0.1010\n","Epoch: 2, Train Loss: 2.304, Train Acc: 0.1116\n","Epoch: 2, Valid Loss: 2.537, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.303, Train Acc: 0.1103\n","Epoch: 3, Valid Loss: 2.538, Valid Acc: 0.1010\n","| \u001b[0m 105     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.225e+0\u001b[0m | \u001b[0m 0.2664  \u001b[0m |\n","Epoch: 1, Train Loss: 0.977, Train Acc: 0.7153\n","Epoch: 1, Valid Loss: 0.383, Valid Acc: 0.9032\n","Epoch: 2, Train Loss: 0.270, Train Acc: 0.9216\n","Epoch: 2, Valid Loss: 0.224, Valid Acc: 0.9456\n","Epoch: 3, Train Loss: 0.179, Train Acc: 0.9477\n","Epoch: 3, Valid Loss: 0.162, Valid Acc: 0.9595\n","Epoch: 4, Train Loss: 0.147, Train Acc: 0.9581\n","Epoch: 4, Valid Loss: 0.140, Valid Acc: 0.9640\n","Epoch: 5, Train Loss: 0.123, Train Acc: 0.9630\n","Epoch: 5, Valid Loss: 0.116, Valid Acc: 0.9710\n","Epoch: 6, Train Loss: 0.109, Train Acc: 0.9687\n","Epoch: 6, Valid Loss: 0.103, Valid Acc: 0.9747\n","Epoch: 7, Train Loss: 0.099, Train Acc: 0.9707\n","Epoch: 7, Valid Loss: 0.091, Valid Acc: 0.9764\n","Epoch: 8, Train Loss: 0.089, Train Acc: 0.9732\n","Epoch: 8, Valid Loss: 0.085, Valid Acc: 0.9775\n","Epoch: 9, Train Loss: 0.081, Train Acc: 0.9761\n","Epoch: 9, Valid Loss: 0.082, Valid Acc: 0.9772\n","Epoch: 10, Train Loss: 0.075, Train Acc: 0.9778\n","Epoch: 10, Valid Loss: 0.074, Valid Acc: 0.9793\n","Epoch: 11, Train Loss: 0.069, Train Acc: 0.9790\n","Epoch: 11, Valid Loss: 0.073, Valid Acc: 0.9791\n","Epoch: 12, Train Loss: 0.073, Train Acc: 0.9790\n","Epoch: 12, Valid Loss: 0.068, Valid Acc: 0.9801\n","Epoch: 13, Train Loss: 0.068, Train Acc: 0.9795\n","Epoch: 13, Valid Loss: 0.065, Valid Acc: 0.9823\n","Epoch: 14, Train Loss: 0.062, Train Acc: 0.9817\n","Epoch: 14, Valid Loss: 0.068, Valid Acc: 0.9796\n","Epoch: 15, Train Loss: 0.058, Train Acc: 0.9824\n","Epoch: 15, Valid Loss: 0.065, Valid Acc: 0.9816\n","Epoch: 16, Train Loss: 0.058, Train Acc: 0.9825\n","Epoch: 16, Valid Loss: 0.063, Valid Acc: 0.9816\n","Epoch: 17, Train Loss: 0.058, Train Acc: 0.9828\n","Epoch: 17, Valid Loss: 0.059, Valid Acc: 0.9815\n","Epoch: 18, Train Loss: 0.057, Train Acc: 0.9829\n","Epoch: 18, Valid Loss: 0.064, Valid Acc: 0.9807\n","Epoch: 19, Train Loss: 0.055, Train Acc: 0.9833\n","Epoch: 19, Valid Loss: 0.063, Valid Acc: 0.9815\n","Epoch: 20, Train Loss: 0.058, Train Acc: 0.9830\n","Epoch: 20, Valid Loss: 0.063, Valid Acc: 0.9819\n","Epoch: 21, Train Loss: 0.057, Train Acc: 0.9829\n","Epoch: 21, Valid Loss: 0.059, Valid Acc: 0.9828\n","Epoch: 22, Train Loss: 0.056, Train Acc: 0.9831\n","Epoch: 22, Valid Loss: 0.059, Valid Acc: 0.9836\n","Epoch: 23, Train Loss: 0.058, Train Acc: 0.9828\n","Epoch: 23, Valid Loss: 0.056, Valid Acc: 0.9837\n","Epoch: 24, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 24, Valid Loss: 0.061, Valid Acc: 0.9835\n","Epoch: 25, Train Loss: 0.055, Train Acc: 0.9839\n","Epoch: 25, Valid Loss: 0.060, Valid Acc: 0.9816\n","Epoch: 26, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 26, Valid Loss: 0.059, Valid Acc: 0.9836\n","Epoch: 27, Train Loss: 0.053, Train Acc: 0.9838\n","Epoch: 27, Valid Loss: 0.057, Valid Acc: 0.9836\n","Epoch: 28, Train Loss: 0.055, Train Acc: 0.9831\n","Epoch: 28, Valid Loss: 0.060, Valid Acc: 0.9828\n","Epoch: 29, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 29, Valid Loss: 0.057, Valid Acc: 0.9839\n","Epoch: 30, Train Loss: 0.054, Train Acc: 0.9840\n","Epoch: 30, Valid Loss: 0.055, Valid Acc: 0.9831\n","| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9839  \u001b[0m | \u001b[0m 1.225e+0\u001b[0m | \u001b[0m 3.631   \u001b[0m |\n","Epoch: 1, Train Loss: 0.868, Train Acc: 0.7568\n","Epoch: 1, Valid Loss: 0.317, Valid Acc: 0.9201\n","Epoch: 2, Train Loss: 0.225, Train Acc: 0.9334\n","Epoch: 2, Valid Loss: 0.182, Valid Acc: 0.9544\n","Epoch: 3, Train Loss: 0.149, Train Acc: 0.9570\n","Epoch: 3, Valid Loss: 0.132, Valid Acc: 0.9640\n","Epoch: 4, Train Loss: 0.117, Train Acc: 0.9654\n","Epoch: 4, Valid Loss: 0.112, Valid Acc: 0.9702\n","Epoch: 5, Train Loss: 0.097, Train Acc: 0.9712\n","Epoch: 5, Valid Loss: 0.095, Valid Acc: 0.9756\n","Epoch: 6, Train Loss: 0.085, Train Acc: 0.9745\n","Epoch: 6, Valid Loss: 0.090, Valid Acc: 0.9758\n","Epoch: 7, Train Loss: 0.077, Train Acc: 0.9770\n","Epoch: 7, Valid Loss: 0.077, Valid Acc: 0.9793\n","Epoch: 8, Train Loss: 0.070, Train Acc: 0.9789\n","Epoch: 8, Valid Loss: 0.078, Valid Acc: 0.9803\n","Epoch: 9, Train Loss: 0.066, Train Acc: 0.9807\n","Epoch: 9, Valid Loss: 0.068, Valid Acc: 0.9810\n","Epoch: 10, Train Loss: 0.062, Train Acc: 0.9812\n","Epoch: 10, Valid Loss: 0.059, Valid Acc: 0.9823\n","Epoch: 11, Train Loss: 0.060, Train Acc: 0.9820\n","Epoch: 11, Valid Loss: 0.063, Valid Acc: 0.9831\n","Epoch: 12, Train Loss: 0.055, Train Acc: 0.9840\n","Epoch: 12, Valid Loss: 0.059, Valid Acc: 0.9839\n","Epoch: 13, Train Loss: 0.052, Train Acc: 0.9839\n","Epoch: 13, Valid Loss: 0.053, Valid Acc: 0.9846\n","Epoch: 14, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 14, Valid Loss: 0.056, Valid Acc: 0.9844\n","Epoch: 15, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 15, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 16, Train Loss: 0.045, Train Acc: 0.9865\n","Epoch: 16, Valid Loss: 0.052, Valid Acc: 0.9852\n","Epoch: 17, Train Loss: 0.046, Train Acc: 0.9863\n","Epoch: 17, Valid Loss: 0.055, Valid Acc: 0.9843\n","Epoch: 18, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 18, Valid Loss: 0.055, Valid Acc: 0.9859\n","Epoch: 19, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 19, Valid Loss: 0.048, Valid Acc: 0.9862\n","Epoch: 20, Train Loss: 0.043, Train Acc: 0.9874\n","Epoch: 20, Valid Loss: 0.055, Valid Acc: 0.9844\n","Epoch: 21, Train Loss: 0.043, Train Acc: 0.9876\n","Epoch: 21, Valid Loss: 0.048, Valid Acc: 0.9856\n","Epoch: 22, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 22, Valid Loss: 0.054, Valid Acc: 0.9836\n","Epoch: 23, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 23, Valid Loss: 0.053, Valid Acc: 0.9851\n","Epoch: 24, Train Loss: 0.044, Train Acc: 0.9861\n","Epoch: 24, Valid Loss: 0.050, Valid Acc: 0.9854\n","Epoch: 25, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 25, Valid Loss: 0.047, Valid Acc: 0.9864\n","Epoch: 26, Train Loss: 0.042, Train Acc: 0.9868\n","Epoch: 26, Valid Loss: 0.052, Valid Acc: 0.9846\n","Epoch: 27, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 27, Valid Loss: 0.050, Valid Acc: 0.9855\n","Epoch: 28, Train Loss: 0.042, Train Acc: 0.9875\n","Epoch: 28, Valid Loss: 0.048, Valid Acc: 0.9858\n","Epoch: 29, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 29, Valid Loss: 0.053, Valid Acc: 0.9856\n","Epoch: 30, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 30, Valid Loss: 0.050, Valid Acc: 0.9858\n","| \u001b[0m 107     \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 1.214e+0\u001b[0m | \u001b[0m 3.796   \u001b[0m |\n","Epoch: 1, Train Loss: 4.784, Train Acc: 0.1126\n","Epoch: 1, Valid Loss: 2.545, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.333, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.544, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.333, Train Acc: 0.1105\n","Epoch: 3, Valid Loss: 2.545, Valid Acc: 0.1135\n","| \u001b[0m 108     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.382e+0\u001b[0m | \u001b[0m 0.06694 \u001b[0m |\n","Epoch: 1, Train Loss: 5.197, Train Acc: 0.1176\n","Epoch: 1, Valid Loss: 2.553, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.341, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.553, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.341, Train Acc: 0.1114\n","Epoch: 3, Valid Loss: 2.554, Valid Acc: 0.1032\n","| \u001b[0m 109     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.387e+0\u001b[0m | \u001b[0m 0.08223 \u001b[0m |\n","Epoch: 1, Train Loss: 1.006, Train Acc: 0.7157\n","Epoch: 1, Valid Loss: 0.435, Valid Acc: 0.8980\n","Epoch: 2, Train Loss: 0.268, Train Acc: 0.9193\n","Epoch: 2, Valid Loss: 0.235, Valid Acc: 0.9488\n","Epoch: 3, Train Loss: 0.172, Train Acc: 0.9501\n","Epoch: 3, Valid Loss: 0.166, Valid Acc: 0.9625\n","Epoch: 4, Train Loss: 0.133, Train Acc: 0.9611\n","Epoch: 4, Valid Loss: 0.127, Valid Acc: 0.9669\n","Epoch: 5, Train Loss: 0.110, Train Acc: 0.9667\n","Epoch: 5, Valid Loss: 0.102, Valid Acc: 0.9733\n","Epoch: 6, Train Loss: 0.096, Train Acc: 0.9712\n","Epoch: 6, Valid Loss: 0.100, Valid Acc: 0.9759\n","Epoch: 7, Train Loss: 0.087, Train Acc: 0.9743\n","Epoch: 7, Valid Loss: 0.101, Valid Acc: 0.9767\n","Epoch: 8, Train Loss: 0.081, Train Acc: 0.9758\n","Epoch: 8, Valid Loss: 0.086, Valid Acc: 0.9774\n","Epoch: 9, Train Loss: 0.073, Train Acc: 0.9782\n","Epoch: 9, Valid Loss: 0.076, Valid Acc: 0.9800\n","Epoch: 10, Train Loss: 0.070, Train Acc: 0.9790\n","Epoch: 10, Valid Loss: 0.069, Valid Acc: 0.9818\n","Epoch: 11, Train Loss: 0.065, Train Acc: 0.9807\n","Epoch: 11, Valid Loss: 0.071, Valid Acc: 0.9808\n","Epoch: 12, Train Loss: 0.060, Train Acc: 0.9817\n","Epoch: 12, Valid Loss: 0.066, Valid Acc: 0.9825\n","Epoch: 13, Train Loss: 0.059, Train Acc: 0.9828\n","Epoch: 13, Valid Loss: 0.070, Valid Acc: 0.9813\n","Epoch: 14, Train Loss: 0.054, Train Acc: 0.9840\n","Epoch: 14, Valid Loss: 0.064, Valid Acc: 0.9833\n","Epoch: 15, Train Loss: 0.055, Train Acc: 0.9836\n","Epoch: 15, Valid Loss: 0.066, Valid Acc: 0.9854\n","Epoch: 16, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 16, Valid Loss: 0.056, Valid Acc: 0.9838\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9857\n","Epoch: 17, Valid Loss: 0.055, Valid Acc: 0.9866\n","Epoch: 18, Train Loss: 0.050, Train Acc: 0.9850\n","Epoch: 18, Valid Loss: 0.059, Valid Acc: 0.9853\n","Epoch: 19, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 19, Valid Loss: 0.058, Valid Acc: 0.9853\n","Epoch: 20, Train Loss: 0.048, Train Acc: 0.9859\n","Epoch: 20, Valid Loss: 0.059, Valid Acc: 0.9844\n","Epoch: 21, Train Loss: 0.048, Train Acc: 0.9859\n","Epoch: 21, Valid Loss: 0.056, Valid Acc: 0.9838\n","Epoch: 22, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9859\n","Epoch: 23, Train Loss: 0.047, Train Acc: 0.9861\n","Epoch: 23, Valid Loss: 0.059, Valid Acc: 0.9837\n","Epoch: 24, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 24, Valid Loss: 0.055, Valid Acc: 0.9842\n","Epoch: 25, Train Loss: 0.047, Train Acc: 0.9861\n","Epoch: 25, Valid Loss: 0.053, Valid Acc: 0.9845\n","Epoch: 26, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 26, Valid Loss: 0.057, Valid Acc: 0.9851\n","Epoch: 27, Train Loss: 0.047, Train Acc: 0.9856\n","Epoch: 27, Valid Loss: 0.062, Valid Acc: 0.9837\n","Epoch: 28, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 28, Valid Loss: 0.054, Valid Acc: 0.9851\n","Epoch: 29, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 29, Valid Loss: 0.055, Valid Acc: 0.9849\n","Epoch: 30, Train Loss: 0.045, Train Acc: 0.9867\n","Epoch: 30, Valid Loss: 0.053, Valid Acc: 0.9864\n","| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9866  \u001b[0m | \u001b[0m 1.977e+0\u001b[0m | \u001b[0m 3.893   \u001b[0m |\n","Epoch: 1, Train Loss: 0.822, Train Acc: 0.7564\n","Epoch: 1, Valid Loss: 0.309, Valid Acc: 0.9233\n","Epoch: 2, Train Loss: 0.210, Train Acc: 0.9392\n","Epoch: 2, Valid Loss: 0.170, Valid Acc: 0.9572\n","Epoch: 3, Train Loss: 0.140, Train Acc: 0.9586\n","Epoch: 3, Valid Loss: 0.128, Valid Acc: 0.9686\n","Epoch: 4, Train Loss: 0.113, Train Acc: 0.9663\n","Epoch: 4, Valid Loss: 0.108, Valid Acc: 0.9733\n","Epoch: 5, Train Loss: 0.095, Train Acc: 0.9714\n","Epoch: 5, Valid Loss: 0.095, Valid Acc: 0.9736\n","Epoch: 6, Train Loss: 0.088, Train Acc: 0.9735\n","Epoch: 6, Valid Loss: 0.091, Valid Acc: 0.9758\n","Epoch: 7, Train Loss: 0.075, Train Acc: 0.9774\n","Epoch: 7, Valid Loss: 0.081, Valid Acc: 0.9774\n","Epoch: 8, Train Loss: 0.073, Train Acc: 0.9786\n","Epoch: 8, Valid Loss: 0.075, Valid Acc: 0.9805\n","Epoch: 9, Train Loss: 0.068, Train Acc: 0.9799\n","Epoch: 9, Valid Loss: 0.073, Valid Acc: 0.9803\n","Epoch: 10, Train Loss: 0.065, Train Acc: 0.9805\n","Epoch: 10, Valid Loss: 0.065, Valid Acc: 0.9833\n","Epoch: 11, Train Loss: 0.060, Train Acc: 0.9820\n","Epoch: 11, Valid Loss: 0.061, Valid Acc: 0.9835\n","Epoch: 12, Train Loss: 0.057, Train Acc: 0.9826\n","Epoch: 12, Valid Loss: 0.070, Valid Acc: 0.9824\n","Epoch: 13, Train Loss: 0.055, Train Acc: 0.9835\n","Epoch: 13, Valid Loss: 0.062, Valid Acc: 0.9832\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9841\n","Epoch: 14, Valid Loss: 0.059, Valid Acc: 0.9830\n","Epoch: 15, Train Loss: 0.048, Train Acc: 0.9852\n","Epoch: 15, Valid Loss: 0.057, Valid Acc: 0.9838\n","Epoch: 16, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 16, Valid Loss: 0.058, Valid Acc: 0.9848\n","Epoch: 17, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 17, Valid Loss: 0.056, Valid Acc: 0.9853\n","Epoch: 18, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 18, Valid Loss: 0.057, Valid Acc: 0.9854\n","Epoch: 19, Train Loss: 0.044, Train Acc: 0.9868\n","Epoch: 19, Valid Loss: 0.056, Valid Acc: 0.9852\n","Epoch: 20, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 20, Valid Loss: 0.060, Valid Acc: 0.9838\n","Epoch: 21, Train Loss: 0.046, Train Acc: 0.9852\n","Epoch: 21, Valid Loss: 0.054, Valid Acc: 0.9851\n","Epoch: 22, Train Loss: 0.046, Train Acc: 0.9860\n","Epoch: 22, Valid Loss: 0.055, Valid Acc: 0.9854\n","Epoch: 23, Train Loss: 0.046, Train Acc: 0.9862\n","Epoch: 23, Valid Loss: 0.055, Valid Acc: 0.9856\n","Epoch: 24, Train Loss: 0.045, Train Acc: 0.9860\n","Epoch: 24, Valid Loss: 0.055, Valid Acc: 0.9847\n","Epoch: 25, Train Loss: 0.046, Train Acc: 0.9859\n","Epoch: 25, Valid Loss: 0.059, Valid Acc: 0.9852\n","Epoch: 26, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 26, Valid Loss: 0.055, Valid Acc: 0.9843\n","Epoch: 27, Train Loss: 0.044, Train Acc: 0.9868\n","Epoch: 27, Valid Loss: 0.051, Valid Acc: 0.9861\n","Epoch: 28, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9846\n","Epoch: 29, Train Loss: 0.044, Train Acc: 0.9863\n","Epoch: 29, Valid Loss: 0.053, Valid Acc: 0.9857\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 30, Valid Loss: 0.053, Valid Acc: 0.9851\n","| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9861  \u001b[0m | \u001b[0m 1.381e+0\u001b[0m | \u001b[0m 3.949   \u001b[0m |\n","Epoch: 1, Train Loss: 0.888, Train Acc: 0.7483\n","Epoch: 1, Valid Loss: 0.363, Valid Acc: 0.9127\n","Epoch: 2, Train Loss: 0.240, Train Acc: 0.9298\n","Epoch: 2, Valid Loss: 0.203, Valid Acc: 0.9513\n","Epoch: 3, Train Loss: 0.155, Train Acc: 0.9546\n","Epoch: 3, Valid Loss: 0.149, Valid Acc: 0.9635\n","Epoch: 4, Train Loss: 0.121, Train Acc: 0.9649\n","Epoch: 4, Valid Loss: 0.121, Valid Acc: 0.9679\n","Epoch: 5, Train Loss: 0.104, Train Acc: 0.9692\n","Epoch: 5, Valid Loss: 0.100, Valid Acc: 0.9740\n","Epoch: 6, Train Loss: 0.089, Train Acc: 0.9736\n","Epoch: 6, Valid Loss: 0.090, Valid Acc: 0.9780\n","Epoch: 7, Train Loss: 0.081, Train Acc: 0.9757\n","Epoch: 7, Valid Loss: 0.083, Valid Acc: 0.9782\n","Epoch: 8, Train Loss: 0.075, Train Acc: 0.9776\n","Epoch: 8, Valid Loss: 0.076, Valid Acc: 0.9797\n","Epoch: 9, Train Loss: 0.069, Train Acc: 0.9796\n","Epoch: 9, Valid Loss: 0.073, Valid Acc: 0.9810\n","Epoch: 10, Train Loss: 0.066, Train Acc: 0.9805\n","Epoch: 10, Valid Loss: 0.069, Valid Acc: 0.9825\n","Epoch: 11, Train Loss: 0.062, Train Acc: 0.9811\n","Epoch: 11, Valid Loss: 0.065, Valid Acc: 0.9826\n","Epoch: 12, Train Loss: 0.059, Train Acc: 0.9823\n","Epoch: 12, Valid Loss: 0.070, Valid Acc: 0.9835\n","Epoch: 13, Train Loss: 0.057, Train Acc: 0.9832\n","Epoch: 13, Valid Loss: 0.063, Valid Acc: 0.9830\n","Epoch: 14, Train Loss: 0.053, Train Acc: 0.9837\n","Epoch: 14, Valid Loss: 0.058, Valid Acc: 0.9843\n","Epoch: 15, Train Loss: 0.052, Train Acc: 0.9837\n","Epoch: 15, Valid Loss: 0.056, Valid Acc: 0.9864\n","Epoch: 16, Train Loss: 0.051, Train Acc: 0.9848\n","Epoch: 16, Valid Loss: 0.054, Valid Acc: 0.9841\n","Epoch: 17, Train Loss: 0.050, Train Acc: 0.9850\n","Epoch: 17, Valid Loss: 0.061, Valid Acc: 0.9839\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 18, Valid Loss: 0.053, Valid Acc: 0.9861\n","Epoch: 19, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 19, Valid Loss: 0.055, Valid Acc: 0.9850\n","Epoch: 20, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 20, Valid Loss: 0.054, Valid Acc: 0.9841\n","Epoch: 21, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 21, Valid Loss: 0.050, Valid Acc: 0.9866\n","Epoch: 22, Train Loss: 0.043, Train Acc: 0.9870\n","Epoch: 22, Valid Loss: 0.055, Valid Acc: 0.9845\n","Epoch: 23, Train Loss: 0.043, Train Acc: 0.9864\n","Epoch: 23, Valid Loss: 0.053, Valid Acc: 0.9848\n","Epoch: 24, Train Loss: 0.044, Train Acc: 0.9869\n","Epoch: 24, Valid Loss: 0.054, Valid Acc: 0.9852\n","Epoch: 25, Train Loss: 0.043, Train Acc: 0.9873\n","Epoch: 25, Valid Loss: 0.053, Valid Acc: 0.9854\n","Epoch: 26, Train Loss: 0.043, Train Acc: 0.9867\n","Epoch: 26, Valid Loss: 0.055, Valid Acc: 0.9842\n","Epoch: 27, Train Loss: 0.042, Train Acc: 0.9872\n","Epoch: 27, Valid Loss: 0.056, Valid Acc: 0.9849\n","Epoch: 28, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 28, Valid Loss: 0.050, Valid Acc: 0.9854\n","Epoch: 29, Train Loss: 0.043, Train Acc: 0.9871\n","Epoch: 29, Valid Loss: 0.054, Valid Acc: 0.9863\n","Epoch: 30, Train Loss: 0.042, Train Acc: 0.9877\n","Epoch: 30, Valid Loss: 0.055, Valid Acc: 0.9847\n","| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9866  \u001b[0m | \u001b[0m 1.388e+0\u001b[0m | \u001b[0m 3.86    \u001b[0m |\n","Epoch: 1, Train Loss: 0.779, Train Acc: 0.7704\n","Epoch: 1, Valid Loss: 0.299, Valid Acc: 0.9216\n","Epoch: 2, Train Loss: 0.202, Train Acc: 0.9391\n","Epoch: 2, Valid Loss: 0.164, Valid Acc: 0.9581\n","Epoch: 3, Train Loss: 0.138, Train Acc: 0.9598\n","Epoch: 3, Valid Loss: 0.125, Valid Acc: 0.9662\n","Epoch: 4, Train Loss: 0.109, Train Acc: 0.9674\n","Epoch: 4, Valid Loss: 0.103, Valid Acc: 0.9719\n","Epoch: 5, Train Loss: 0.094, Train Acc: 0.9718\n","Epoch: 5, Valid Loss: 0.091, Valid Acc: 0.9751\n","Epoch: 6, Train Loss: 0.082, Train Acc: 0.9748\n","Epoch: 6, Valid Loss: 0.079, Valid Acc: 0.9788\n","Epoch: 7, Train Loss: 0.075, Train Acc: 0.9777\n","Epoch: 7, Valid Loss: 0.080, Valid Acc: 0.9787\n","Epoch: 8, Train Loss: 0.069, Train Acc: 0.9793\n","Epoch: 8, Valid Loss: 0.069, Valid Acc: 0.9827\n","Epoch: 9, Train Loss: 0.065, Train Acc: 0.9804\n","Epoch: 9, Valid Loss: 0.068, Valid Acc: 0.9825\n","Epoch: 10, Train Loss: 0.061, Train Acc: 0.9813\n","Epoch: 10, Valid Loss: 0.065, Valid Acc: 0.9821\n","Epoch: 11, Train Loss: 0.056, Train Acc: 0.9836\n","Epoch: 11, Valid Loss: 0.061, Valid Acc: 0.9844\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9835\n","Epoch: 12, Valid Loss: 0.060, Valid Acc: 0.9823\n","Epoch: 13, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 13, Valid Loss: 0.061, Valid Acc: 0.9841\n","Epoch: 14, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 14, Valid Loss: 0.054, Valid Acc: 0.9848\n","Epoch: 15, Train Loss: 0.048, Train Acc: 0.9850\n","Epoch: 15, Valid Loss: 0.057, Valid Acc: 0.9842\n","Epoch: 16, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 16, Valid Loss: 0.057, Valid Acc: 0.9854\n","Epoch: 17, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 17, Valid Loss: 0.056, Valid Acc: 0.9847\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9855\n","Epoch: 18, Valid Loss: 0.055, Valid Acc: 0.9846\n","Epoch: 19, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 19, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 20, Train Loss: 0.046, Train Acc: 0.9857\n","Epoch: 20, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 21, Train Loss: 0.047, Train Acc: 0.9862\n","Epoch: 21, Valid Loss: 0.057, Valid Acc: 0.9837\n","Epoch: 22, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 22, Valid Loss: 0.056, Valid Acc: 0.9850\n","Epoch: 23, Train Loss: 0.046, Train Acc: 0.9862\n","Epoch: 23, Valid Loss: 0.055, Valid Acc: 0.9841\n","Epoch: 24, Train Loss: 0.045, Train Acc: 0.9861\n","Epoch: 24, Valid Loss: 0.053, Valid Acc: 0.9839\n","Epoch: 25, Train Loss: 0.045, Train Acc: 0.9860\n","Epoch: 25, Valid Loss: 0.052, Valid Acc: 0.9855\n","Epoch: 26, Train Loss: 0.044, Train Acc: 0.9867\n","Epoch: 26, Valid Loss: 0.053, Valid Acc: 0.9859\n","Epoch: 27, Train Loss: 0.046, Train Acc: 0.9858\n","Epoch: 27, Valid Loss: 0.052, Valid Acc: 0.9851\n","Epoch: 28, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 28, Valid Loss: 0.052, Valid Acc: 0.9850\n","Epoch: 29, Train Loss: 0.045, Train Acc: 0.9862\n","Epoch: 29, Valid Loss: 0.055, Valid Acc: 0.9852\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9862\n","Epoch: 30, Valid Loss: 0.054, Valid Acc: 0.9865\n","| \u001b[0m 113     \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 1.37e+03\u001b[0m | \u001b[0m 3.98    \u001b[0m |\n","Epoch: 1, Train Loss: 1212.450, Train Acc: 0.1049\n","Epoch: 1, Valid Loss: 2.869, Valid Acc: 0.1008\n","Epoch: 2, Train Loss: 2.353, Train Acc: 0.1039\n","Epoch: 2, Valid Loss: 2.484, Valid Acc: 0.0981\n","Epoch: 3, Train Loss: 2.385, Train Acc: 0.1072\n","Epoch: 3, Valid Loss: 2.349, Valid Acc: 0.0974\n","| \u001b[0m 114     \u001b[0m | \u001b[0m 0.1008  \u001b[0m | \u001b[0m 1.275e+0\u001b[0m | \u001b[0m 0.7429  \u001b[0m |\n","Epoch: 1, Train Loss: 0.986, Train Acc: 0.7221\n","Epoch: 1, Valid Loss: 0.406, Valid Acc: 0.9016\n","Epoch: 2, Train Loss: 0.253, Train Acc: 0.9258\n","Epoch: 2, Valid Loss: 0.223, Valid Acc: 0.9513\n","Epoch: 3, Train Loss: 0.159, Train Acc: 0.9526\n","Epoch: 3, Valid Loss: 0.155, Valid Acc: 0.9637\n","Epoch: 4, Train Loss: 0.124, Train Acc: 0.9637\n","Epoch: 4, Valid Loss: 0.118, Valid Acc: 0.9700\n","Epoch: 5, Train Loss: 0.105, Train Acc: 0.9687\n","Epoch: 5, Valid Loss: 0.112, Valid Acc: 0.9739\n","Epoch: 6, Train Loss: 0.092, Train Acc: 0.9726\n","Epoch: 6, Valid Loss: 0.094, Valid Acc: 0.9775\n","Epoch: 7, Train Loss: 0.082, Train Acc: 0.9757\n","Epoch: 7, Valid Loss: 0.088, Valid Acc: 0.9776\n","Epoch: 8, Train Loss: 0.075, Train Acc: 0.9771\n","Epoch: 8, Valid Loss: 0.080, Valid Acc: 0.9783\n","Epoch: 9, Train Loss: 0.071, Train Acc: 0.9783\n","Epoch: 9, Valid Loss: 0.074, Valid Acc: 0.9806\n","Epoch: 10, Train Loss: 0.067, Train Acc: 0.9795\n","Epoch: 10, Valid Loss: 0.072, Valid Acc: 0.9828\n","Epoch: 11, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 11, Valid Loss: 0.065, Valid Acc: 0.9821\n","Epoch: 12, Train Loss: 0.060, Train Acc: 0.9811\n","Epoch: 12, Valid Loss: 0.064, Valid Acc: 0.9824\n","Epoch: 13, Train Loss: 0.056, Train Acc: 0.9831\n","Epoch: 13, Valid Loss: 0.066, Valid Acc: 0.9824\n","Epoch: 14, Train Loss: 0.053, Train Acc: 0.9835\n","Epoch: 14, Valid Loss: 0.058, Valid Acc: 0.9829\n","Epoch: 15, Train Loss: 0.052, Train Acc: 0.9845\n","Epoch: 15, Valid Loss: 0.058, Valid Acc: 0.9845\n","Epoch: 16, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 16, Valid Loss: 0.058, Valid Acc: 0.9834\n","Epoch: 17, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 17, Valid Loss: 0.058, Valid Acc: 0.9845\n","Epoch: 18, Train Loss: 0.046, Train Acc: 0.9863\n","Epoch: 18, Valid Loss: 0.050, Valid Acc: 0.9860\n","Epoch: 19, Train Loss: 0.047, Train Acc: 0.9866\n","Epoch: 19, Valid Loss: 0.053, Valid Acc: 0.9857\n","Epoch: 20, Train Loss: 0.046, Train Acc: 0.9867\n","Epoch: 20, Valid Loss: 0.054, Valid Acc: 0.9840\n","Epoch: 21, Train Loss: 0.045, Train Acc: 0.9866\n","Epoch: 21, Valid Loss: 0.052, Valid Acc: 0.9849\n","Epoch: 22, Train Loss: 0.045, Train Acc: 0.9863\n","Epoch: 22, Valid Loss: 0.049, Valid Acc: 0.9855\n","Epoch: 23, Train Loss: 0.045, Train Acc: 0.9866\n","Epoch: 23, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 24, Train Loss: 0.046, Train Acc: 0.9855\n","Epoch: 24, Valid Loss: 0.055, Valid Acc: 0.9842\n","Epoch: 25, Train Loss: 0.043, Train Acc: 0.9868\n","Epoch: 25, Valid Loss: 0.051, Valid Acc: 0.9851\n","Epoch: 26, Train Loss: 0.044, Train Acc: 0.9863\n","Epoch: 26, Valid Loss: 0.052, Valid Acc: 0.9860\n","Epoch: 27, Train Loss: 0.043, Train Acc: 0.9876\n","Epoch: 27, Valid Loss: 0.050, Valid Acc: 0.9864\n","Epoch: 28, Train Loss: 0.044, Train Acc: 0.9870\n","Epoch: 28, Valid Loss: 0.055, Valid Acc: 0.9841\n","Epoch: 29, Train Loss: 0.043, Train Acc: 0.9868\n","Epoch: 29, Valid Loss: 0.056, Valid Acc: 0.9841\n","Epoch: 30, Train Loss: 0.043, Train Acc: 0.9873\n","Epoch: 30, Valid Loss: 0.055, Valid Acc: 0.9853\n","| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 1.964e+0\u001b[0m | \u001b[0m 3.994   \u001b[0m |\n","Epoch: 1, Train Loss: 1.491, Train Acc: 0.5404\n","Epoch: 1, Valid Loss: 0.679, Valid Acc: 0.7823\n","Epoch: 2, Train Loss: 0.592, Train Acc: 0.8105\n","Epoch: 2, Valid Loss: 0.443, Valid Acc: 0.8625\n","Epoch: 3, Train Loss: 0.452, Train Acc: 0.8602\n","Epoch: 3, Valid Loss: 0.411, Valid Acc: 0.8744\n","Epoch: 4, Train Loss: 0.399, Train Acc: 0.8766\n","Epoch: 4, Valid Loss: 0.361, Valid Acc: 0.8910\n","Epoch: 5, Train Loss: 0.391, Train Acc: 0.8808\n","Epoch: 5, Valid Loss: 0.402, Valid Acc: 0.8772\n","Epoch: 6, Train Loss: 0.377, Train Acc: 0.8850\n","Epoch: 6, Valid Loss: 0.457, Valid Acc: 0.8579\n","Epoch: 7, Train Loss: 0.367, Train Acc: 0.8851\n","Epoch: 7, Valid Loss: 0.340, Valid Acc: 0.8946\n","Epoch: 8, Train Loss: 0.345, Train Acc: 0.8945\n","Epoch: 8, Valid Loss: 0.341, Valid Acc: 0.8913\n","Epoch: 9, Train Loss: 0.345, Train Acc: 0.8920\n","Epoch: 9, Valid Loss: 0.307, Valid Acc: 0.9025\n","Epoch: 10, Train Loss: 0.339, Train Acc: 0.8970\n","Epoch: 10, Valid Loss: 0.336, Valid Acc: 0.8960\n","Epoch: 11, Train Loss: 0.341, Train Acc: 0.8949\n","Epoch: 11, Valid Loss: 0.333, Valid Acc: 0.8949\n","Epoch: 12, Train Loss: 0.332, Train Acc: 0.8985\n","Epoch: 12, Valid Loss: 0.309, Valid Acc: 0.9047\n","Epoch: 13, Train Loss: 0.331, Train Acc: 0.8968\n","Epoch: 13, Valid Loss: 0.316, Valid Acc: 0.9010\n","Epoch: 14, Train Loss: 0.303, Train Acc: 0.9062\n","Epoch: 14, Valid Loss: 0.271, Valid Acc: 0.9120\n","Epoch: 15, Train Loss: 0.296, Train Acc: 0.9076\n","Epoch: 15, Valid Loss: 0.278, Valid Acc: 0.9147\n","Epoch: 16, Train Loss: 0.296, Train Acc: 0.9089\n","Epoch: 16, Valid Loss: 0.282, Valid Acc: 0.9146\n","| \u001b[0m 116     \u001b[0m | \u001b[0m 0.9147  \u001b[0m | \u001b[0m 1.461e+0\u001b[0m | \u001b[0m 1.199   \u001b[0m |\n","Epoch: 1, Train Loss: 0.384, Train Acc: 0.8835\n","Epoch: 1, Valid Loss: 0.133, Valid Acc: 0.9606\n","Epoch: 2, Train Loss: 0.112, Train Acc: 0.9658\n","Epoch: 2, Valid Loss: 0.077, Valid Acc: 0.9767\n","Epoch: 3, Train Loss: 0.083, Train Acc: 0.9745\n","Epoch: 3, Valid Loss: 0.069, Valid Acc: 0.9775\n","Epoch: 4, Train Loss: 0.070, Train Acc: 0.9787\n","Epoch: 4, Valid Loss: 0.056, Valid Acc: 0.9834\n","Epoch: 5, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 5, Valid Loss: 0.055, Valid Acc: 0.9829\n","Epoch: 6, Train Loss: 0.056, Train Acc: 0.9827\n","Epoch: 6, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 7, Train Loss: 0.051, Train Acc: 0.9839\n","Epoch: 7, Valid Loss: 0.049, Valid Acc: 0.9835\n","Epoch: 8, Train Loss: 0.047, Train Acc: 0.9856\n","Epoch: 8, Valid Loss: 0.046, Valid Acc: 0.9854\n","Epoch: 9, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 9, Valid Loss: 0.047, Valid Acc: 0.9850\n","Epoch: 10, Train Loss: 0.041, Train Acc: 0.9869\n","Epoch: 10, Valid Loss: 0.046, Valid Acc: 0.9857\n","Epoch: 11, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 11, Valid Loss: 0.045, Valid Acc: 0.9855\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9881\n","Epoch: 12, Valid Loss: 0.044, Valid Acc: 0.9861\n","Epoch: 13, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 13, Valid Loss: 0.039, Valid Acc: 0.9881\n","Epoch: 14, Train Loss: 0.034, Train Acc: 0.9893\n","Epoch: 14, Valid Loss: 0.041, Valid Acc: 0.9869\n","Epoch: 15, Train Loss: 0.033, Train Acc: 0.9894\n","Epoch: 15, Valid Loss: 0.039, Valid Acc: 0.9864\n","Epoch: 16, Train Loss: 0.028, Train Acc: 0.9911\n","Epoch: 16, Valid Loss: 0.035, Valid Acc: 0.9884\n","Epoch: 17, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 17, Valid Loss: 0.037, Valid Acc: 0.9879\n","Epoch: 18, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 18, Valid Loss: 0.036, Valid Acc: 0.9889\n","Epoch: 19, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 19, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 20, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 20, Valid Loss: 0.033, Valid Acc: 0.9892\n","Epoch: 21, Train Loss: 0.025, Train Acc: 0.9917\n","Epoch: 21, Valid Loss: 0.036, Valid Acc: 0.9889\n","Epoch: 22, Train Loss: 0.024, Train Acc: 0.9922\n","Epoch: 22, Valid Loss: 0.034, Valid Acc: 0.9895\n","Epoch: 23, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 23, Valid Loss: 0.037, Valid Acc: 0.9888\n","Epoch: 24, Train Loss: 0.024, Train Acc: 0.9925\n","Epoch: 24, Valid Loss: 0.035, Valid Acc: 0.9890\n","Epoch: 25, Train Loss: 0.024, Train Acc: 0.9923\n","Epoch: 25, Valid Loss: 0.032, Valid Acc: 0.9906\n","Epoch: 26, Train Loss: 0.025, Train Acc: 0.9922\n","Epoch: 26, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 27, Train Loss: 0.023, Train Acc: 0.9925\n","Epoch: 27, Valid Loss: 0.034, Valid Acc: 0.9893\n","Epoch: 28, Train Loss: 0.024, Train Acc: 0.9920\n","Epoch: 28, Valid Loss: 0.033, Valid Acc: 0.9888\n","Epoch: 29, Train Loss: 0.023, Train Acc: 0.9924\n","Epoch: 29, Valid Loss: 0.034, Valid Acc: 0.9896\n","Epoch: 30, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 30, Valid Loss: 0.034, Valid Acc: 0.9897\n","| \u001b[95m 117     \u001b[0m | \u001b[95m 0.9906  \u001b[0m | \u001b[95m 351.3   \u001b[0m | \u001b[95m 3.874   \u001b[0m |\n","Epoch: 1, Train Loss: 1206.558, Train Acc: 0.1033\n","Epoch: 1, Valid Loss: 2.426, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.325, Train Acc: 0.1043\n","Epoch: 2, Valid Loss: 2.436, Valid Acc: 0.1028\n","Epoch: 3, Train Loss: 2.327, Train Acc: 0.1027\n","Epoch: 3, Valid Loss: 2.441, Valid Acc: 0.0974\n","| \u001b[0m 118     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 554.9   \u001b[0m | \u001b[0m 0.9606  \u001b[0m |\n","Epoch: 1, Train Loss: 0.915, Train Acc: 0.7461\n","Epoch: 1, Valid Loss: 0.327, Valid Acc: 0.9111\n","Epoch: 2, Train Loss: 0.247, Train Acc: 0.9289\n","Epoch: 2, Valid Loss: 0.186, Valid Acc: 0.9499\n","Epoch: 3, Train Loss: 0.165, Train Acc: 0.9521\n","Epoch: 3, Valid Loss: 0.134, Valid Acc: 0.9627\n","Epoch: 4, Train Loss: 0.131, Train Acc: 0.9603\n","Epoch: 4, Valid Loss: 0.108, Valid Acc: 0.9693\n","Epoch: 5, Train Loss: 0.111, Train Acc: 0.9669\n","Epoch: 5, Valid Loss: 0.090, Valid Acc: 0.9726\n","Epoch: 6, Train Loss: 0.099, Train Acc: 0.9701\n","Epoch: 6, Valid Loss: 0.080, Valid Acc: 0.9770\n","Epoch: 7, Train Loss: 0.088, Train Acc: 0.9739\n","Epoch: 7, Valid Loss: 0.074, Valid Acc: 0.9774\n","Epoch: 8, Train Loss: 0.082, Train Acc: 0.9753\n","Epoch: 8, Valid Loss: 0.071, Valid Acc: 0.9794\n","Epoch: 9, Train Loss: 0.075, Train Acc: 0.9771\n","Epoch: 9, Valid Loss: 0.067, Valid Acc: 0.9800\n","Epoch: 10, Train Loss: 0.069, Train Acc: 0.9788\n","Epoch: 10, Valid Loss: 0.064, Valid Acc: 0.9796\n","Epoch: 11, Train Loss: 0.067, Train Acc: 0.9800\n","Epoch: 11, Valid Loss: 0.059, Valid Acc: 0.9817\n","Epoch: 12, Train Loss: 0.063, Train Acc: 0.9810\n","Epoch: 12, Valid Loss: 0.055, Valid Acc: 0.9817\n","Epoch: 13, Train Loss: 0.059, Train Acc: 0.9819\n","Epoch: 13, Valid Loss: 0.057, Valid Acc: 0.9827\n","Epoch: 14, Train Loss: 0.057, Train Acc: 0.9828\n","Epoch: 14, Valid Loss: 0.051, Valid Acc: 0.9849\n","Epoch: 15, Train Loss: 0.055, Train Acc: 0.9828\n","Epoch: 15, Valid Loss: 0.051, Valid Acc: 0.9846\n","Epoch: 16, Train Loss: 0.052, Train Acc: 0.9836\n","Epoch: 16, Valid Loss: 0.052, Valid Acc: 0.9818\n","Epoch: 17, Train Loss: 0.051, Train Acc: 0.9842\n","Epoch: 17, Valid Loss: 0.048, Valid Acc: 0.9848\n","Epoch: 18, Train Loss: 0.048, Train Acc: 0.9855\n","Epoch: 18, Valid Loss: 0.049, Valid Acc: 0.9849\n","Epoch: 19, Train Loss: 0.049, Train Acc: 0.9847\n","Epoch: 19, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 20, Train Loss: 0.049, Train Acc: 0.9854\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9860\n","Epoch: 21, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 21, Valid Loss: 0.049, Valid Acc: 0.9843\n","Epoch: 22, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 22, Valid Loss: 0.048, Valid Acc: 0.9839\n","Epoch: 23, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 23, Valid Loss: 0.047, Valid Acc: 0.9854\n","Epoch: 24, Train Loss: 0.046, Train Acc: 0.9864\n","Epoch: 24, Valid Loss: 0.048, Valid Acc: 0.9846\n","Epoch: 25, Train Loss: 0.047, Train Acc: 0.9860\n","Epoch: 25, Valid Loss: 0.050, Valid Acc: 0.9830\n","Epoch: 26, Train Loss: 0.046, Train Acc: 0.9861\n","Epoch: 26, Valid Loss: 0.049, Valid Acc: 0.9845\n","Epoch: 27, Train Loss: 0.048, Train Acc: 0.9854\n","Epoch: 27, Valid Loss: 0.046, Valid Acc: 0.9854\n","Epoch: 28, Train Loss: 0.047, Train Acc: 0.9863\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9849\n","Epoch: 29, Train Loss: 0.047, Train Acc: 0.9859\n","Epoch: 29, Valid Loss: 0.048, Valid Acc: 0.9846\n","Epoch: 30, Train Loss: 0.047, Train Acc: 0.9851\n","Epoch: 30, Valid Loss: 0.048, Valid Acc: 0.9857\n","| \u001b[0m 119     \u001b[0m | \u001b[0m 0.986   \u001b[0m | \u001b[0m 551.3   \u001b[0m | \u001b[0m 3.29    \u001b[0m |\n","Epoch: 1, Train Loss: 3.414, Train Acc: 0.1075\n","Epoch: 1, Valid Loss: 2.309, Valid Acc: 0.0958\n","Epoch: 2, Train Loss: 2.308, Train Acc: 0.1076\n","Epoch: 2, Valid Loss: 2.306, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.308, Train Acc: 0.1052\n","Epoch: 3, Valid Loss: 2.307, Valid Acc: 0.1028\n","| \u001b[0m 120     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 313.6   \u001b[0m | \u001b[0m 1.915   \u001b[0m |\n","Epoch: 1, Train Loss: 0.502, Train Acc: 0.8486\n","Epoch: 1, Valid Loss: 0.162, Valid Acc: 0.9562\n","Epoch: 2, Train Loss: 0.118, Train Acc: 0.9645\n","Epoch: 2, Valid Loss: 0.103, Valid Acc: 0.9729\n","Epoch: 3, Train Loss: 0.089, Train Acc: 0.9735\n","Epoch: 3, Valid Loss: 0.087, Valid Acc: 0.9774\n","Epoch: 4, Train Loss: 0.074, Train Acc: 0.9773\n","Epoch: 4, Valid Loss: 0.073, Valid Acc: 0.9804\n","Epoch: 5, Train Loss: 0.063, Train Acc: 0.9809\n","Epoch: 5, Valid Loss: 0.064, Valid Acc: 0.9821\n","Epoch: 6, Train Loss: 0.059, Train Acc: 0.9822\n","Epoch: 6, Valid Loss: 0.060, Valid Acc: 0.9833\n","Epoch: 7, Train Loss: 0.052, Train Acc: 0.9839\n","Epoch: 7, Valid Loss: 0.062, Valid Acc: 0.9838\n","Epoch: 8, Train Loss: 0.050, Train Acc: 0.9845\n","Epoch: 8, Valid Loss: 0.058, Valid Acc: 0.9839\n","Epoch: 9, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 9, Valid Loss: 0.051, Valid Acc: 0.9860\n","Epoch: 10, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 10, Valid Loss: 0.053, Valid Acc: 0.9863\n","Epoch: 11, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 11, Valid Loss: 0.045, Valid Acc: 0.9868\n","Epoch: 12, Train Loss: 0.041, Train Acc: 0.9870\n","Epoch: 12, Valid Loss: 0.051, Valid Acc: 0.9856\n","Epoch: 13, Train Loss: 0.037, Train Acc: 0.9882\n","Epoch: 13, Valid Loss: 0.049, Valid Acc: 0.9863\n","Epoch: 14, Train Loss: 0.035, Train Acc: 0.9892\n","Epoch: 14, Valid Loss: 0.045, Valid Acc: 0.9886\n","Epoch: 15, Train Loss: 0.035, Train Acc: 0.9889\n","Epoch: 15, Valid Loss: 0.047, Valid Acc: 0.9868\n","Epoch: 16, Train Loss: 0.029, Train Acc: 0.9904\n","Epoch: 16, Valid Loss: 0.043, Valid Acc: 0.9880\n","Epoch: 17, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 17, Valid Loss: 0.041, Valid Acc: 0.9884\n","Epoch: 18, Train Loss: 0.027, Train Acc: 0.9911\n","Epoch: 18, Valid Loss: 0.045, Valid Acc: 0.9875\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 19, Valid Loss: 0.044, Valid Acc: 0.9884\n","Epoch: 20, Train Loss: 0.025, Train Acc: 0.9916\n","Epoch: 20, Valid Loss: 0.043, Valid Acc: 0.9878\n","Epoch: 21, Train Loss: 0.026, Train Acc: 0.9913\n","Epoch: 21, Valid Loss: 0.039, Valid Acc: 0.9886\n","Epoch: 22, Train Loss: 0.025, Train Acc: 0.9916\n","Epoch: 22, Valid Loss: 0.044, Valid Acc: 0.9879\n","Epoch: 23, Train Loss: 0.028, Train Acc: 0.9908\n","Epoch: 23, Valid Loss: 0.040, Valid Acc: 0.9885\n","Epoch: 24, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 24, Valid Loss: 0.042, Valid Acc: 0.9891\n","Epoch: 25, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 25, Valid Loss: 0.040, Valid Acc: 0.9889\n","Epoch: 26, Train Loss: 0.024, Train Acc: 0.9922\n","Epoch: 26, Valid Loss: 0.042, Valid Acc: 0.9898\n","Epoch: 27, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 27, Valid Loss: 0.037, Valid Acc: 0.9901\n","Epoch: 28, Train Loss: 0.024, Train Acc: 0.9924\n","Epoch: 28, Valid Loss: 0.040, Valid Acc: 0.9896\n","Epoch: 29, Train Loss: 0.024, Train Acc: 0.9923\n","Epoch: 29, Valid Loss: 0.045, Valid Acc: 0.9873\n","Epoch: 30, Train Loss: 0.024, Train Acc: 0.9922\n","Epoch: 30, Valid Loss: 0.036, Valid Acc: 0.9898\n","| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9901  \u001b[0m | \u001b[0m 1.204e+0\u001b[0m | \u001b[0m 2.269   \u001b[0m |\n","Epoch: 1, Train Loss: 0.809, Train Acc: 0.7705\n","Epoch: 1, Valid Loss: 0.242, Valid Acc: 0.9297\n","Epoch: 2, Train Loss: 0.197, Train Acc: 0.9415\n","Epoch: 2, Valid Loss: 0.137, Valid Acc: 0.9592\n","Epoch: 3, Train Loss: 0.133, Train Acc: 0.9616\n","Epoch: 3, Valid Loss: 0.110, Valid Acc: 0.9676\n","Epoch: 4, Train Loss: 0.108, Train Acc: 0.9677\n","Epoch: 4, Valid Loss: 0.089, Valid Acc: 0.9722\n","Epoch: 5, Train Loss: 0.094, Train Acc: 0.9719\n","Epoch: 5, Valid Loss: 0.080, Valid Acc: 0.9749\n","Epoch: 6, Train Loss: 0.083, Train Acc: 0.9757\n","Epoch: 6, Valid Loss: 0.072, Valid Acc: 0.9771\n","Epoch: 7, Train Loss: 0.074, Train Acc: 0.9778\n","Epoch: 7, Valid Loss: 0.068, Valid Acc: 0.9794\n","Epoch: 8, Train Loss: 0.065, Train Acc: 0.9799\n","Epoch: 8, Valid Loss: 0.064, Valid Acc: 0.9802\n","Epoch: 9, Train Loss: 0.062, Train Acc: 0.9815\n","Epoch: 9, Valid Loss: 0.060, Valid Acc: 0.9820\n","Epoch: 10, Train Loss: 0.059, Train Acc: 0.9821\n","Epoch: 10, Valid Loss: 0.056, Valid Acc: 0.9817\n","Epoch: 11, Train Loss: 0.057, Train Acc: 0.9826\n","Epoch: 11, Valid Loss: 0.055, Valid Acc: 0.9822\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9842\n","Epoch: 12, Valid Loss: 0.049, Valid Acc: 0.9854\n","Epoch: 13, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 13, Valid Loss: 0.049, Valid Acc: 0.9852\n","Epoch: 14, Train Loss: 0.049, Train Acc: 0.9854\n","Epoch: 14, Valid Loss: 0.049, Valid Acc: 0.9846\n","Epoch: 15, Train Loss: 0.045, Train Acc: 0.9859\n","Epoch: 15, Valid Loss: 0.048, Valid Acc: 0.9858\n","Epoch: 16, Train Loss: 0.045, Train Acc: 0.9867\n","Epoch: 16, Valid Loss: 0.045, Valid Acc: 0.9863\n","Epoch: 17, Train Loss: 0.044, Train Acc: 0.9869\n","Epoch: 17, Valid Loss: 0.048, Valid Acc: 0.9847\n","Epoch: 18, Train Loss: 0.042, Train Acc: 0.9871\n","Epoch: 18, Valid Loss: 0.047, Valid Acc: 0.9856\n","Epoch: 19, Train Loss: 0.044, Train Acc: 0.9870\n","Epoch: 19, Valid Loss: 0.046, Valid Acc: 0.9851\n","Epoch: 20, Train Loss: 0.044, Train Acc: 0.9869\n","Epoch: 20, Valid Loss: 0.047, Valid Acc: 0.9846\n","Epoch: 21, Train Loss: 0.042, Train Acc: 0.9874\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9850\n","Epoch: 22, Train Loss: 0.043, Train Acc: 0.9871\n","Epoch: 22, Valid Loss: 0.049, Valid Acc: 0.9835\n","Epoch: 23, Train Loss: 0.043, Train Acc: 0.9871\n","Epoch: 23, Valid Loss: 0.044, Valid Acc: 0.9859\n","Epoch: 24, Train Loss: 0.042, Train Acc: 0.9871\n","Epoch: 24, Valid Loss: 0.046, Valid Acc: 0.9854\n","Epoch: 25, Train Loss: 0.043, Train Acc: 0.9876\n","Epoch: 25, Valid Loss: 0.049, Valid Acc: 0.9841\n","Epoch: 26, Train Loss: 0.043, Train Acc: 0.9873\n","Epoch: 26, Valid Loss: 0.045, Valid Acc: 0.9859\n","Epoch: 27, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 27, Valid Loss: 0.049, Valid Acc: 0.9851\n","Epoch: 28, Train Loss: 0.041, Train Acc: 0.9870\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9852\n","Epoch: 29, Train Loss: 0.041, Train Acc: 0.9878\n","Epoch: 29, Valid Loss: 0.046, Valid Acc: 0.9852\n","Epoch: 30, Train Loss: 0.041, Train Acc: 0.9876\n","Epoch: 30, Valid Loss: 0.045, Valid Acc: 0.9848\n","| \u001b[0m 122     \u001b[0m | \u001b[0m 0.9863  \u001b[0m | \u001b[0m 1.273e+0\u001b[0m | \u001b[0m 3.902   \u001b[0m |\n","Epoch: 1, Train Loss: 2.326, Train Acc: 0.1286\n","Epoch: 1, Valid Loss: 2.254, Valid Acc: 0.1759\n","Epoch: 2, Train Loss: 2.193, Train Acc: 0.2295\n","Epoch: 2, Valid Loss: 2.121, Valid Acc: 0.2990\n","Epoch: 3, Train Loss: 2.051, Train Acc: 0.3562\n","Epoch: 3, Valid Loss: 1.965, Valid Acc: 0.4172\n","| \u001b[0m 123     \u001b[0m | \u001b[0m 0.4172  \u001b[0m | \u001b[0m 1.676e+0\u001b[0m | \u001b[0m 3.023   \u001b[0m |\n","Epoch: 1, Train Loss: 0.339, Train Acc: 0.8970\n","Epoch: 1, Valid Loss: 0.123, Valid Acc: 0.9640\n","Epoch: 2, Train Loss: 0.105, Train Acc: 0.9683\n","Epoch: 2, Valid Loss: 0.076, Valid Acc: 0.9758\n","Epoch: 3, Train Loss: 0.080, Train Acc: 0.9756\n","Epoch: 3, Valid Loss: 0.064, Valid Acc: 0.9800\n","Epoch: 4, Train Loss: 0.066, Train Acc: 0.9795\n","Epoch: 4, Valid Loss: 0.059, Valid Acc: 0.9822\n","Epoch: 5, Train Loss: 0.059, Train Acc: 0.9816\n","Epoch: 5, Valid Loss: 0.053, Valid Acc: 0.9820\n","Epoch: 6, Train Loss: 0.055, Train Acc: 0.9832\n","Epoch: 6, Valid Loss: 0.052, Valid Acc: 0.9843\n","Epoch: 7, Train Loss: 0.051, Train Acc: 0.9839\n","Epoch: 7, Valid Loss: 0.047, Valid Acc: 0.9856\n","Epoch: 8, Train Loss: 0.047, Train Acc: 0.9853\n","Epoch: 8, Valid Loss: 0.049, Valid Acc: 0.9849\n","Epoch: 9, Train Loss: 0.044, Train Acc: 0.9859\n","Epoch: 9, Valid Loss: 0.053, Valid Acc: 0.9834\n","Epoch: 10, Train Loss: 0.040, Train Acc: 0.9876\n","Epoch: 10, Valid Loss: 0.044, Valid Acc: 0.9866\n","Epoch: 11, Train Loss: 0.040, Train Acc: 0.9870\n","Epoch: 11, Valid Loss: 0.043, Valid Acc: 0.9840\n","Epoch: 12, Train Loss: 0.034, Train Acc: 0.9895\n","Epoch: 12, Valid Loss: 0.039, Valid Acc: 0.9878\n","Epoch: 13, Train Loss: 0.032, Train Acc: 0.9901\n","Epoch: 13, Valid Loss: 0.035, Valid Acc: 0.9886\n","Epoch: 14, Train Loss: 0.031, Train Acc: 0.9907\n","Epoch: 14, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 15, Train Loss: 0.031, Train Acc: 0.9899\n","Epoch: 15, Valid Loss: 0.038, Valid Acc: 0.9872\n","Epoch: 16, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 16, Valid Loss: 0.038, Valid Acc: 0.9889\n","Epoch: 17, Train Loss: 0.031, Train Acc: 0.9906\n","Epoch: 17, Valid Loss: 0.038, Valid Acc: 0.9874\n","Epoch: 18, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 18, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 19, Train Loss: 0.028, Train Acc: 0.9914\n","Epoch: 19, Valid Loss: 0.035, Valid Acc: 0.9873\n","Epoch: 20, Train Loss: 0.029, Train Acc: 0.9910\n","Epoch: 20, Valid Loss: 0.039, Valid Acc: 0.9878\n","Epoch: 21, Train Loss: 0.029, Train Acc: 0.9912\n","Epoch: 21, Valid Loss: 0.037, Valid Acc: 0.9884\n","Epoch: 22, Train Loss: 0.028, Train Acc: 0.9911\n","Epoch: 22, Valid Loss: 0.039, Valid Acc: 0.9877\n","Epoch: 23, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 24, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 24, Valid Loss: 0.037, Valid Acc: 0.9892\n","Epoch: 25, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9882\n","Epoch: 26, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 26, Valid Loss: 0.034, Valid Acc: 0.9898\n","Epoch: 27, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 27, Valid Loss: 0.036, Valid Acc: 0.9881\n","Epoch: 28, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 28, Valid Loss: 0.034, Valid Acc: 0.9884\n","Epoch: 29, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 29, Valid Loss: 0.039, Valid Acc: 0.9871\n","Epoch: 30, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 30, Valid Loss: 0.036, Valid Acc: 0.9887\n","| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9898  \u001b[0m | \u001b[0m 310.7   \u001b[0m | \u001b[0m 3.927   \u001b[0m |\n","Epoch: 1, Train Loss: 0.839, Train Acc: 0.7482\n","Epoch: 1, Valid Loss: 0.278, Valid Acc: 0.9203\n","Epoch: 2, Train Loss: 0.211, Train Acc: 0.9380\n","Epoch: 2, Valid Loss: 0.153, Valid Acc: 0.9562\n","Epoch: 3, Train Loss: 0.144, Train Acc: 0.9579\n","Epoch: 3, Valid Loss: 0.119, Valid Acc: 0.9656\n","Epoch: 4, Train Loss: 0.113, Train Acc: 0.9662\n","Epoch: 4, Valid Loss: 0.094, Valid Acc: 0.9710\n","Epoch: 5, Train Loss: 0.096, Train Acc: 0.9712\n","Epoch: 5, Valid Loss: 0.082, Valid Acc: 0.9762\n","Epoch: 6, Train Loss: 0.084, Train Acc: 0.9749\n","Epoch: 6, Valid Loss: 0.075, Valid Acc: 0.9766\n","Epoch: 7, Train Loss: 0.076, Train Acc: 0.9772\n","Epoch: 7, Valid Loss: 0.069, Valid Acc: 0.9793\n","Epoch: 8, Train Loss: 0.071, Train Acc: 0.9778\n","Epoch: 8, Valid Loss: 0.062, Valid Acc: 0.9810\n","Epoch: 9, Train Loss: 0.066, Train Acc: 0.9802\n","Epoch: 9, Valid Loss: 0.055, Valid Acc: 0.9829\n","Epoch: 10, Train Loss: 0.060, Train Acc: 0.9816\n","Epoch: 10, Valid Loss: 0.055, Valid Acc: 0.9837\n","Epoch: 11, Train Loss: 0.058, Train Acc: 0.9822\n","Epoch: 11, Valid Loss: 0.053, Valid Acc: 0.9846\n","Epoch: 12, Train Loss: 0.055, Train Acc: 0.9830\n","Epoch: 12, Valid Loss: 0.054, Valid Acc: 0.9817\n","Epoch: 13, Train Loss: 0.053, Train Acc: 0.9828\n","Epoch: 13, Valid Loss: 0.049, Valid Acc: 0.9832\n","Epoch: 14, Train Loss: 0.051, Train Acc: 0.9846\n","Epoch: 14, Valid Loss: 0.048, Valid Acc: 0.9852\n","Epoch: 15, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 15, Valid Loss: 0.047, Valid Acc: 0.9852\n","Epoch: 16, Train Loss: 0.045, Train Acc: 0.9864\n","Epoch: 16, Valid Loss: 0.050, Valid Acc: 0.9842\n","Epoch: 17, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 17, Valid Loss: 0.046, Valid Acc: 0.9844\n","Epoch: 18, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 18, Valid Loss: 0.043, Valid Acc: 0.9864\n","Epoch: 19, Train Loss: 0.042, Train Acc: 0.9874\n","Epoch: 19, Valid Loss: 0.047, Valid Acc: 0.9849\n","Epoch: 20, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 20, Valid Loss: 0.043, Valid Acc: 0.9851\n","Epoch: 21, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 21, Valid Loss: 0.044, Valid Acc: 0.9860\n","Epoch: 22, Train Loss: 0.042, Train Acc: 0.9871\n","Epoch: 22, Valid Loss: 0.045, Valid Acc: 0.9854\n","Epoch: 23, Train Loss: 0.043, Train Acc: 0.9869\n","Epoch: 23, Valid Loss: 0.046, Valid Acc: 0.9851\n","Epoch: 24, Train Loss: 0.041, Train Acc: 0.9876\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9847\n","Epoch: 25, Train Loss: 0.043, Train Acc: 0.9866\n","Epoch: 25, Valid Loss: 0.047, Valid Acc: 0.9839\n","Epoch: 26, Train Loss: 0.040, Train Acc: 0.9875\n","Epoch: 26, Valid Loss: 0.043, Valid Acc: 0.9867\n","Epoch: 27, Train Loss: 0.041, Train Acc: 0.9876\n","Epoch: 27, Valid Loss: 0.046, Valid Acc: 0.9838\n","Epoch: 28, Train Loss: 0.042, Train Acc: 0.9877\n","Epoch: 28, Valid Loss: 0.042, Valid Acc: 0.9863\n","Epoch: 29, Train Loss: 0.041, Train Acc: 0.9875\n","Epoch: 29, Valid Loss: 0.042, Valid Acc: 0.9850\n","Epoch: 30, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 30, Valid Loss: 0.043, Valid Acc: 0.9868\n","| \u001b[0m 125     \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 1.469e+0\u001b[0m | \u001b[0m 3.992   \u001b[0m |\n","Epoch: 1, Train Loss: 0.368, Train Acc: 0.8881\n","Epoch: 1, Valid Loss: 0.118, Valid Acc: 0.9640\n","Epoch: 2, Train Loss: 0.105, Train Acc: 0.9680\n","Epoch: 2, Valid Loss: 0.077, Valid Acc: 0.9774\n","Epoch: 3, Train Loss: 0.079, Train Acc: 0.9759\n","Epoch: 3, Valid Loss: 0.068, Valid Acc: 0.9801\n","Epoch: 4, Train Loss: 0.067, Train Acc: 0.9791\n","Epoch: 4, Valid Loss: 0.059, Valid Acc: 0.9817\n","Epoch: 5, Train Loss: 0.059, Train Acc: 0.9820\n","Epoch: 5, Valid Loss: 0.053, Valid Acc: 0.9825\n","Epoch: 6, Train Loss: 0.052, Train Acc: 0.9833\n","Epoch: 6, Valid Loss: 0.055, Valid Acc: 0.9832\n","Epoch: 7, Train Loss: 0.048, Train Acc: 0.9852\n","Epoch: 7, Valid Loss: 0.047, Valid Acc: 0.9845\n","Epoch: 8, Train Loss: 0.045, Train Acc: 0.9856\n","Epoch: 8, Valid Loss: 0.048, Valid Acc: 0.9849\n","Epoch: 9, Train Loss: 0.043, Train Acc: 0.9866\n","Epoch: 9, Valid Loss: 0.049, Valid Acc: 0.9834\n","Epoch: 10, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 10, Valid Loss: 0.043, Valid Acc: 0.9867\n","Epoch: 11, Train Loss: 0.036, Train Acc: 0.9889\n","Epoch: 11, Valid Loss: 0.040, Valid Acc: 0.9869\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9885\n","Epoch: 12, Valid Loss: 0.039, Valid Acc: 0.9871\n","Epoch: 13, Train Loss: 0.034, Train Acc: 0.9893\n","Epoch: 13, Valid Loss: 0.041, Valid Acc: 0.9866\n","Epoch: 14, Train Loss: 0.029, Train Acc: 0.9905\n","Epoch: 14, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 15, Train Loss: 0.027, Train Acc: 0.9917\n","Epoch: 15, Valid Loss: 0.033, Valid Acc: 0.9894\n","Epoch: 16, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 16, Valid Loss: 0.040, Valid Acc: 0.9885\n","Epoch: 17, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 17, Valid Loss: 0.040, Valid Acc: 0.9876\n","Epoch: 18, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 18, Valid Loss: 0.037, Valid Acc: 0.9887\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 19, Valid Loss: 0.036, Valid Acc: 0.9881\n","Epoch: 20, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 20, Valid Loss: 0.038, Valid Acc: 0.9881\n","Epoch: 21, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 21, Valid Loss: 0.034, Valid Acc: 0.9897\n","Epoch: 22, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 22, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 23, Train Loss: 0.025, Train Acc: 0.9924\n","Epoch: 23, Valid Loss: 0.035, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.023, Train Acc: 0.9926\n","Epoch: 24, Valid Loss: 0.038, Valid Acc: 0.9893\n","Epoch: 25, Train Loss: 0.025, Train Acc: 0.9915\n","Epoch: 25, Valid Loss: 0.034, Valid Acc: 0.9891\n","Epoch: 26, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 26, Valid Loss: 0.036, Valid Acc: 0.9895\n","Epoch: 27, Train Loss: 0.024, Train Acc: 0.9921\n","Epoch: 27, Valid Loss: 0.031, Valid Acc: 0.9901\n","Epoch: 28, Train Loss: 0.023, Train Acc: 0.9924\n","Epoch: 28, Valid Loss: 0.035, Valid Acc: 0.9895\n","Epoch: 29, Train Loss: 0.024, Train Acc: 0.9923\n","Epoch: 29, Valid Loss: 0.032, Valid Acc: 0.9903\n","Epoch: 30, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 30, Valid Loss: 0.036, Valid Acc: 0.9884\n","| \u001b[0m 126     \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 360.8   \u001b[0m | \u001b[0m 3.986   \u001b[0m |\n","Epoch: 1, Train Loss: 3.045, Train Acc: 0.1090\n","Epoch: 1, Valid Loss: 2.328, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.314, Train Acc: 0.1073\n","Epoch: 2, Valid Loss: 2.327, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.314, Train Acc: 0.1090\n","Epoch: 3, Valid Loss: 2.330, Valid Acc: 0.1135\n","| \u001b[0m 127     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 361.5   \u001b[0m | \u001b[0m 1.684   \u001b[0m |\n","Epoch: 1, Train Loss: 0.893, Train Acc: 0.7396\n","Epoch: 1, Valid Loss: 0.401, Valid Acc: 0.8860\n","Epoch: 2, Train Loss: 0.322, Train Acc: 0.9010\n","Epoch: 2, Valid Loss: 0.286, Valid Acc: 0.9234\n","Epoch: 3, Train Loss: 0.238, Train Acc: 0.9260\n","Epoch: 3, Valid Loss: 0.222, Valid Acc: 0.9349\n","Epoch: 4, Train Loss: 0.205, Train Acc: 0.9360\n","Epoch: 4, Valid Loss: 0.201, Valid Acc: 0.9435\n","Epoch: 5, Train Loss: 0.190, Train Acc: 0.9415\n","Epoch: 5, Valid Loss: 0.211, Valid Acc: 0.9416\n","Epoch: 6, Train Loss: 0.181, Train Acc: 0.9442\n","Epoch: 6, Valid Loss: 0.159, Valid Acc: 0.9558\n","Epoch: 7, Train Loss: 0.174, Train Acc: 0.9465\n","Epoch: 7, Valid Loss: 0.182, Valid Acc: 0.9508\n","Epoch: 8, Train Loss: 0.162, Train Acc: 0.9504\n","Epoch: 8, Valid Loss: 0.174, Valid Acc: 0.9503\n","Epoch: 9, Train Loss: 0.166, Train Acc: 0.9501\n","Epoch: 9, Valid Loss: 0.175, Valid Acc: 0.9521\n","Epoch: 10, Train Loss: 0.149, Train Acc: 0.9529\n","Epoch: 10, Valid Loss: 0.155, Valid Acc: 0.9581\n","Epoch: 11, Train Loss: 0.145, Train Acc: 0.9556\n","Epoch: 11, Valid Loss: 0.146, Valid Acc: 0.9590\n","Epoch: 12, Train Loss: 0.137, Train Acc: 0.9577\n","Epoch: 12, Valid Loss: 0.152, Valid Acc: 0.9589\n","Epoch: 13, Train Loss: 0.127, Train Acc: 0.9613\n","Epoch: 13, Valid Loss: 0.126, Valid Acc: 0.9643\n","Epoch: 14, Train Loss: 0.127, Train Acc: 0.9598\n","Epoch: 14, Valid Loss: 0.141, Valid Acc: 0.9621\n","Epoch: 15, Train Loss: 0.132, Train Acc: 0.9596\n","Epoch: 15, Valid Loss: 0.135, Valid Acc: 0.9612\n","Epoch: 16, Train Loss: 0.112, Train Acc: 0.9653\n","Epoch: 16, Valid Loss: 0.119, Valid Acc: 0.9673\n","| \u001b[0m 128     \u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 1.23e+03\u001b[0m | \u001b[0m 1.193   \u001b[0m |\n","Epoch: 1, Train Loss: 0.293, Train Acc: 0.9089\n","Epoch: 1, Valid Loss: 0.093, Valid Acc: 0.9722\n","Epoch: 2, Train Loss: 0.088, Train Acc: 0.9726\n","Epoch: 2, Valid Loss: 0.065, Valid Acc: 0.9803\n","Epoch: 3, Train Loss: 0.068, Train Acc: 0.9793\n","Epoch: 3, Valid Loss: 0.057, Valid Acc: 0.9818\n","Epoch: 4, Train Loss: 0.058, Train Acc: 0.9823\n","Epoch: 4, Valid Loss: 0.050, Valid Acc: 0.9840\n","Epoch: 5, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 5, Valid Loss: 0.049, Valid Acc: 0.9844\n","Epoch: 6, Train Loss: 0.046, Train Acc: 0.9856\n","Epoch: 6, Valid Loss: 0.047, Valid Acc: 0.9857\n","Epoch: 7, Train Loss: 0.042, Train Acc: 0.9873\n","Epoch: 7, Valid Loss: 0.043, Valid Acc: 0.9864\n","Epoch: 8, Train Loss: 0.040, Train Acc: 0.9873\n","Epoch: 8, Valid Loss: 0.043, Valid Acc: 0.9863\n","Epoch: 9, Train Loss: 0.036, Train Acc: 0.9887\n","Epoch: 9, Valid Loss: 0.047, Valid Acc: 0.9858\n","Epoch: 10, Train Loss: 0.037, Train Acc: 0.9881\n","Epoch: 10, Valid Loss: 0.039, Valid Acc: 0.9871\n","Epoch: 11, Train Loss: 0.035, Train Acc: 0.9887\n","Epoch: 11, Valid Loss: 0.041, Valid Acc: 0.9864\n","Epoch: 12, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 12, Valid Loss: 0.037, Valid Acc: 0.9873\n","Epoch: 13, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 13, Valid Loss: 0.037, Valid Acc: 0.9889\n","Epoch: 14, Train Loss: 0.025, Train Acc: 0.9918\n","Epoch: 14, Valid Loss: 0.037, Valid Acc: 0.9881\n","Epoch: 15, Train Loss: 0.025, Train Acc: 0.9922\n","Epoch: 15, Valid Loss: 0.032, Valid Acc: 0.9884\n","Epoch: 16, Train Loss: 0.024, Train Acc: 0.9919\n","Epoch: 16, Valid Loss: 0.036, Valid Acc: 0.9884\n","Epoch: 17, Train Loss: 0.023, Train Acc: 0.9927\n","Epoch: 17, Valid Loss: 0.037, Valid Acc: 0.9892\n","Epoch: 18, Train Loss: 0.023, Train Acc: 0.9925\n","Epoch: 18, Valid Loss: 0.035, Valid Acc: 0.9890\n","Epoch: 19, Train Loss: 0.023, Train Acc: 0.9923\n","Epoch: 19, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 20, Train Loss: 0.023, Train Acc: 0.9926\n","Epoch: 20, Valid Loss: 0.037, Valid Acc: 0.9879\n","Epoch: 21, Train Loss: 0.024, Train Acc: 0.9923\n","Epoch: 21, Valid Loss: 0.035, Valid Acc: 0.9892\n","Epoch: 22, Train Loss: 0.021, Train Acc: 0.9932\n","Epoch: 22, Valid Loss: 0.037, Valid Acc: 0.9885\n","Epoch: 23, Train Loss: 0.020, Train Acc: 0.9937\n","Epoch: 23, Valid Loss: 0.033, Valid Acc: 0.9892\n","Epoch: 24, Train Loss: 0.023, Train Acc: 0.9925\n","Epoch: 24, Valid Loss: 0.033, Valid Acc: 0.9888\n","Epoch: 25, Train Loss: 0.021, Train Acc: 0.9932\n","Epoch: 25, Valid Loss: 0.031, Valid Acc: 0.9900\n","Epoch: 26, Train Loss: 0.021, Train Acc: 0.9938\n","Epoch: 26, Valid Loss: 0.036, Valid Acc: 0.9875\n","Epoch: 27, Train Loss: 0.021, Train Acc: 0.9931\n","Epoch: 27, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 28, Train Loss: 0.020, Train Acc: 0.9934\n","Epoch: 28, Valid Loss: 0.033, Valid Acc: 0.9898\n","Epoch: 29, Train Loss: 0.020, Train Acc: 0.9935\n","Epoch: 29, Valid Loss: 0.036, Valid Acc: 0.9893\n","Epoch: 30, Train Loss: 0.020, Train Acc: 0.9938\n","Epoch: 30, Valid Loss: 0.033, Valid Acc: 0.9902\n","| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 378.3   \u001b[0m | \u001b[0m 2.166   \u001b[0m |\n","Epoch: 1, Train Loss: 0.712, Train Acc: 0.7816\n","Epoch: 1, Valid Loss: 0.486, Valid Acc: 0.8475\n","Epoch: 2, Train Loss: 0.452, Train Acc: 0.8567\n","Epoch: 2, Valid Loss: 0.422, Valid Acc: 0.8670\n","Epoch: 3, Train Loss: 0.415, Train Acc: 0.8685\n","Epoch: 3, Valid Loss: 0.373, Valid Acc: 0.8811\n","Epoch: 4, Train Loss: 0.369, Train Acc: 0.8858\n","Epoch: 4, Valid Loss: 0.315, Valid Acc: 0.9037\n","Epoch: 5, Train Loss: 0.321, Train Acc: 0.8992\n","Epoch: 5, Valid Loss: 0.288, Valid Acc: 0.9052\n","Epoch: 6, Train Loss: 0.306, Train Acc: 0.9043\n","Epoch: 6, Valid Loss: 0.294, Valid Acc: 0.9103\n","Epoch: 7, Train Loss: 0.298, Train Acc: 0.9094\n","Epoch: 7, Valid Loss: 0.246, Valid Acc: 0.9259\n","Epoch: 8, Train Loss: 0.279, Train Acc: 0.9149\n","Epoch: 8, Valid Loss: 0.271, Valid Acc: 0.9195\n","Epoch: 9, Train Loss: 0.274, Train Acc: 0.9157\n","Epoch: 9, Valid Loss: 0.257, Valid Acc: 0.9243\n","Epoch: 10, Train Loss: 0.268, Train Acc: 0.9191\n","Epoch: 10, Valid Loss: 0.255, Valid Acc: 0.9268\n","Epoch: 11, Train Loss: 0.278, Train Acc: 0.9147\n","Epoch: 11, Valid Loss: 0.248, Valid Acc: 0.9278\n","Epoch: 12, Train Loss: 0.256, Train Acc: 0.9220\n","Epoch: 12, Valid Loss: 0.233, Valid Acc: 0.9344\n","Epoch: 13, Train Loss: 0.243, Train Acc: 0.9257\n","Epoch: 13, Valid Loss: 0.252, Valid Acc: 0.9290\n","Epoch: 14, Train Loss: 0.240, Train Acc: 0.9274\n","Epoch: 14, Valid Loss: 0.232, Valid Acc: 0.9296\n","Epoch: 15, Train Loss: 0.224, Train Acc: 0.9332\n","Epoch: 15, Valid Loss: 0.221, Valid Acc: 0.9370\n","Epoch: 16, Train Loss: 0.221, Train Acc: 0.9341\n","Epoch: 16, Valid Loss: 0.195, Valid Acc: 0.9422\n","| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9422  \u001b[0m | \u001b[0m 376.3   \u001b[0m | \u001b[0m 1.23    \u001b[0m |\n","Epoch: 1, Train Loss: 0.362, Train Acc: 0.8913\n","Epoch: 1, Valid Loss: 0.120, Valid Acc: 0.9646\n","Epoch: 2, Train Loss: 0.106, Train Acc: 0.9687\n","Epoch: 2, Valid Loss: 0.082, Valid Acc: 0.9744\n","Epoch: 3, Train Loss: 0.082, Train Acc: 0.9746\n","Epoch: 3, Valid Loss: 0.063, Valid Acc: 0.9811\n","Epoch: 4, Train Loss: 0.068, Train Acc: 0.9792\n","Epoch: 4, Valid Loss: 0.067, Valid Acc: 0.9786\n","Epoch: 5, Train Loss: 0.061, Train Acc: 0.9820\n","Epoch: 5, Valid Loss: 0.054, Valid Acc: 0.9823\n","Epoch: 6, Train Loss: 0.056, Train Acc: 0.9829\n","Epoch: 6, Valid Loss: 0.050, Valid Acc: 0.9851\n","Epoch: 7, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 7, Valid Loss: 0.050, Valid Acc: 0.9834\n","Epoch: 8, Train Loss: 0.046, Train Acc: 0.9859\n","Epoch: 8, Valid Loss: 0.043, Valid Acc: 0.9858\n","Epoch: 9, Train Loss: 0.044, Train Acc: 0.9858\n","Epoch: 9, Valid Loss: 0.045, Valid Acc: 0.9845\n","Epoch: 10, Train Loss: 0.042, Train Acc: 0.9863\n","Epoch: 10, Valid Loss: 0.043, Valid Acc: 0.9868\n","Epoch: 11, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 11, Valid Loss: 0.046, Valid Acc: 0.9856\n","Epoch: 12, Train Loss: 0.034, Train Acc: 0.9895\n","Epoch: 12, Valid Loss: 0.040, Valid Acc: 0.9880\n","Epoch: 13, Train Loss: 0.032, Train Acc: 0.9899\n","Epoch: 13, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 14, Train Loss: 0.031, Train Acc: 0.9902\n","Epoch: 14, Valid Loss: 0.041, Valid Acc: 0.9870\n","Epoch: 15, Train Loss: 0.031, Train Acc: 0.9904\n","Epoch: 15, Valid Loss: 0.038, Valid Acc: 0.9870\n","Epoch: 16, Train Loss: 0.030, Train Acc: 0.9903\n","Epoch: 16, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 17, Train Loss: 0.030, Train Acc: 0.9902\n","Epoch: 17, Valid Loss: 0.037, Valid Acc: 0.9882\n","Epoch: 18, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 18, Valid Loss: 0.035, Valid Acc: 0.9884\n","Epoch: 19, Train Loss: 0.030, Train Acc: 0.9910\n","Epoch: 19, Valid Loss: 0.039, Valid Acc: 0.9881\n","Epoch: 20, Train Loss: 0.029, Train Acc: 0.9908\n","Epoch: 20, Valid Loss: 0.040, Valid Acc: 0.9883\n","Epoch: 21, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 21, Valid Loss: 0.036, Valid Acc: 0.9881\n","Epoch: 22, Train Loss: 0.028, Train Acc: 0.9915\n","Epoch: 22, Valid Loss: 0.038, Valid Acc: 0.9888\n","Epoch: 23, Train Loss: 0.029, Train Acc: 0.9909\n","Epoch: 23, Valid Loss: 0.039, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 24, Valid Loss: 0.040, Valid Acc: 0.9868\n","Epoch: 25, Train Loss: 0.028, Train Acc: 0.9914\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9880\n","Epoch: 26, Train Loss: 0.028, Train Acc: 0.9914\n","Epoch: 26, Valid Loss: 0.035, Valid Acc: 0.9886\n","Epoch: 27, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 27, Valid Loss: 0.032, Valid Acc: 0.9899\n","Epoch: 28, Train Loss: 0.028, Train Acc: 0.9911\n","Epoch: 28, Valid Loss: 0.035, Valid Acc: 0.9879\n","Epoch: 29, Train Loss: 0.027, Train Acc: 0.9916\n","Epoch: 29, Valid Loss: 0.037, Valid Acc: 0.9873\n","Epoch: 30, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 30, Valid Loss: 0.035, Valid Acc: 0.9884\n","| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9899  \u001b[0m | \u001b[0m 305.9   \u001b[0m | \u001b[0m 3.862   \u001b[0m |\n","Epoch: 1, Train Loss: 1.025, Train Acc: 0.7126\n","Epoch: 1, Valid Loss: 0.333, Valid Acc: 0.8997\n","Epoch: 2, Train Loss: 0.275, Train Acc: 0.9143\n","Epoch: 2, Valid Loss: 0.207, Valid Acc: 0.9349\n","Epoch: 3, Train Loss: 0.204, Train Acc: 0.9376\n","Epoch: 3, Valid Loss: 0.173, Valid Acc: 0.9465\n","Epoch: 4, Train Loss: 0.177, Train Acc: 0.9464\n","Epoch: 4, Valid Loss: 0.166, Valid Acc: 0.9480\n","Epoch: 5, Train Loss: 0.166, Train Acc: 0.9501\n","Epoch: 5, Valid Loss: 0.167, Valid Acc: 0.9496\n","Epoch: 6, Train Loss: 0.154, Train Acc: 0.9524\n","Epoch: 6, Valid Loss: 0.138, Valid Acc: 0.9555\n","Epoch: 7, Train Loss: 0.145, Train Acc: 0.9549\n","Epoch: 7, Valid Loss: 0.133, Valid Acc: 0.9588\n","Epoch: 8, Train Loss: 0.136, Train Acc: 0.9588\n","Epoch: 8, Valid Loss: 0.114, Valid Acc: 0.9631\n","Epoch: 9, Train Loss: 0.129, Train Acc: 0.9596\n","Epoch: 9, Valid Loss: 0.112, Valid Acc: 0.9668\n","Epoch: 10, Train Loss: 0.119, Train Acc: 0.9631\n","Epoch: 10, Valid Loss: 0.122, Valid Acc: 0.9621\n","Epoch: 11, Train Loss: 0.120, Train Acc: 0.9628\n","Epoch: 11, Valid Loss: 0.102, Valid Acc: 0.9693\n","Epoch: 12, Train Loss: 0.115, Train Acc: 0.9647\n","Epoch: 12, Valid Loss: 0.103, Valid Acc: 0.9696\n","Epoch: 13, Train Loss: 0.107, Train Acc: 0.9667\n","Epoch: 13, Valid Loss: 0.106, Valid Acc: 0.9676\n","Epoch: 14, Train Loss: 0.095, Train Acc: 0.9702\n","Epoch: 14, Valid Loss: 0.096, Valid Acc: 0.9700\n","Epoch: 15, Train Loss: 0.091, Train Acc: 0.9715\n","Epoch: 15, Valid Loss: 0.098, Valid Acc: 0.9701\n","Epoch: 16, Train Loss: 0.088, Train Acc: 0.9728\n","Epoch: 16, Valid Loss: 0.089, Valid Acc: 0.9731\n","Epoch: 17, Train Loss: 0.086, Train Acc: 0.9726\n","Epoch: 17, Valid Loss: 0.090, Valid Acc: 0.9721\n","Epoch: 18, Train Loss: 0.086, Train Acc: 0.9734\n","Epoch: 18, Valid Loss: 0.083, Valid Acc: 0.9736\n","Epoch: 19, Train Loss: 0.084, Train Acc: 0.9744\n","Epoch: 19, Valid Loss: 0.087, Valid Acc: 0.9729\n","Epoch: 20, Train Loss: 0.085, Train Acc: 0.9739\n","Epoch: 20, Valid Loss: 0.094, Valid Acc: 0.9713\n","| \u001b[0m 132     \u001b[0m | \u001b[0m 0.9736  \u001b[0m | \u001b[0m 1.693e+0\u001b[0m | \u001b[0m 1.195   \u001b[0m |\n","Epoch: 1, Train Loss: 7.221, Train Acc: 0.1219\n","Epoch: 1, Valid Loss: 2.335, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.334, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.334, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.334, Train Acc: 0.1114\n","Epoch: 3, Valid Loss: 2.333, Valid Acc: 0.1135\n","| \u001b[0m 133     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.691e+0\u001b[0m | \u001b[0m 1.783   \u001b[0m |\n","Epoch: 1, Train Loss: 0.536, Train Acc: 0.8340\n","Epoch: 1, Valid Loss: 0.141, Valid Acc: 0.9585\n","Epoch: 2, Train Loss: 0.122, Train Acc: 0.9629\n","Epoch: 2, Valid Loss: 0.092, Valid Acc: 0.9708\n","Epoch: 3, Train Loss: 0.087, Train Acc: 0.9733\n","Epoch: 3, Valid Loss: 0.071, Valid Acc: 0.9790\n","Epoch: 4, Train Loss: 0.071, Train Acc: 0.9779\n","Epoch: 4, Valid Loss: 0.069, Valid Acc: 0.9790\n","Epoch: 5, Train Loss: 0.066, Train Acc: 0.9791\n","Epoch: 5, Valid Loss: 0.058, Valid Acc: 0.9810\n","Epoch: 6, Train Loss: 0.060, Train Acc: 0.9816\n","Epoch: 6, Valid Loss: 0.051, Valid Acc: 0.9836\n","Epoch: 7, Train Loss: 0.052, Train Acc: 0.9842\n","Epoch: 7, Valid Loss: 0.048, Valid Acc: 0.9843\n","Epoch: 8, Train Loss: 0.048, Train Acc: 0.9853\n","Epoch: 8, Valid Loss: 0.049, Valid Acc: 0.9822\n","Epoch: 9, Train Loss: 0.045, Train Acc: 0.9852\n","Epoch: 9, Valid Loss: 0.049, Valid Acc: 0.9847\n","Epoch: 10, Train Loss: 0.043, Train Acc: 0.9866\n","Epoch: 10, Valid Loss: 0.051, Valid Acc: 0.9843\n","Epoch: 11, Train Loss: 0.041, Train Acc: 0.9874\n","Epoch: 11, Valid Loss: 0.042, Valid Acc: 0.9867\n","Epoch: 12, Train Loss: 0.038, Train Acc: 0.9874\n","Epoch: 12, Valid Loss: 0.044, Valid Acc: 0.9851\n","Epoch: 13, Train Loss: 0.036, Train Acc: 0.9889\n","Epoch: 13, Valid Loss: 0.041, Valid Acc: 0.9867\n","Epoch: 14, Train Loss: 0.037, Train Acc: 0.9887\n","Epoch: 14, Valid Loss: 0.043, Valid Acc: 0.9844\n","Epoch: 15, Train Loss: 0.032, Train Acc: 0.9898\n","Epoch: 15, Valid Loss: 0.040, Valid Acc: 0.9861\n","Epoch: 16, Train Loss: 0.030, Train Acc: 0.9906\n","Epoch: 16, Valid Loss: 0.040, Valid Acc: 0.9876\n","Epoch: 17, Train Loss: 0.028, Train Acc: 0.9913\n","Epoch: 17, Valid Loss: 0.038, Valid Acc: 0.9874\n","Epoch: 18, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 18, Valid Loss: 0.038, Valid Acc: 0.9878\n","Epoch: 19, Train Loss: 0.028, Train Acc: 0.9915\n","Epoch: 19, Valid Loss: 0.039, Valid Acc: 0.9883\n","Epoch: 20, Train Loss: 0.028, Train Acc: 0.9914\n","Epoch: 20, Valid Loss: 0.039, Valid Acc: 0.9879\n","Epoch: 21, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 21, Valid Loss: 0.036, Valid Acc: 0.9880\n","Epoch: 22, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 22, Valid Loss: 0.037, Valid Acc: 0.9889\n","Epoch: 23, Train Loss: 0.028, Train Acc: 0.9911\n","Epoch: 23, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 24, Train Loss: 0.026, Train Acc: 0.9914\n","Epoch: 24, Valid Loss: 0.037, Valid Acc: 0.9883\n","Epoch: 25, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9885\n","Epoch: 26, Train Loss: 0.027, Train Acc: 0.9912\n","Epoch: 26, Valid Loss: 0.037, Valid Acc: 0.9877\n","Epoch: 27, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 27, Valid Loss: 0.038, Valid Acc: 0.9875\n","Epoch: 28, Train Loss: 0.026, Train Acc: 0.9924\n","Epoch: 28, Valid Loss: 0.035, Valid Acc: 0.9880\n","Epoch: 29, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 29, Valid Loss: 0.038, Valid Acc: 0.9885\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 30, Valid Loss: 0.040, Valid Acc: 0.9869\n","| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9889  \u001b[0m | \u001b[0m 1.694e+0\u001b[0m | \u001b[0m 2.344   \u001b[0m |\n","Epoch: 1, Train Loss: 284.226, Train Acc: 0.1052\n","Epoch: 1, Valid Loss: 2.355, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.344, Train Acc: 0.1075\n","Epoch: 2, Valid Loss: 2.343, Valid Acc: 0.0974\n","Epoch: 3, Train Loss: 2.343, Train Acc: 0.1069\n","Epoch: 3, Valid Loss: 2.342, Valid Acc: 0.0958\n","| \u001b[0m 135     \u001b[0m | \u001b[0m 0.1028  \u001b[0m | \u001b[0m 1.696e+0\u001b[0m | \u001b[0m 0.4901  \u001b[0m |\n","Epoch: 1, Train Loss: 5.776, Train Acc: 0.1109\n","Epoch: 1, Valid Loss: 2.484, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.346, Train Acc: 0.1103\n","Epoch: 2, Valid Loss: 2.483, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.346, Train Acc: 0.1094\n","Epoch: 3, Valid Loss: 2.485, Valid Acc: 0.1135\n","| \u001b[0m 136     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.2e+03 \u001b[0m | \u001b[0m 1.959   \u001b[0m |\n","Epoch: 1, Train Loss: 0.515, Train Acc: 0.8469\n","Epoch: 1, Valid Loss: 0.152, Valid Acc: 0.9571\n","Epoch: 2, Train Loss: 0.126, Train Acc: 0.9614\n","Epoch: 2, Valid Loss: 0.115, Valid Acc: 0.9662\n","Epoch: 3, Train Loss: 0.095, Train Acc: 0.9704\n","Epoch: 3, Valid Loss: 0.091, Valid Acc: 0.9738\n","Epoch: 4, Train Loss: 0.080, Train Acc: 0.9748\n","Epoch: 4, Valid Loss: 0.087, Valid Acc: 0.9752\n","Epoch: 5, Train Loss: 0.075, Train Acc: 0.9765\n","Epoch: 5, Valid Loss: 0.081, Valid Acc: 0.9773\n","Epoch: 6, Train Loss: 0.069, Train Acc: 0.9791\n","Epoch: 6, Valid Loss: 0.070, Valid Acc: 0.9805\n","Epoch: 7, Train Loss: 0.061, Train Acc: 0.9813\n","Epoch: 7, Valid Loss: 0.057, Valid Acc: 0.9834\n","Epoch: 8, Train Loss: 0.058, Train Acc: 0.9824\n","Epoch: 8, Valid Loss: 0.067, Valid Acc: 0.9797\n","Epoch: 9, Train Loss: 0.054, Train Acc: 0.9828\n","Epoch: 9, Valid Loss: 0.061, Valid Acc: 0.9838\n","Epoch: 10, Train Loss: 0.053, Train Acc: 0.9832\n","Epoch: 10, Valid Loss: 0.062, Valid Acc: 0.9830\n","Epoch: 11, Train Loss: 0.050, Train Acc: 0.9841\n","Epoch: 11, Valid Loss: 0.064, Valid Acc: 0.9826\n","Epoch: 12, Train Loss: 0.043, Train Acc: 0.9870\n","Epoch: 12, Valid Loss: 0.056, Valid Acc: 0.9839\n","Epoch: 13, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 13, Valid Loss: 0.052, Valid Acc: 0.9849\n","Epoch: 14, Train Loss: 0.040, Train Acc: 0.9871\n","Epoch: 14, Valid Loss: 0.057, Valid Acc: 0.9845\n","Epoch: 15, Train Loss: 0.039, Train Acc: 0.9883\n","Epoch: 15, Valid Loss: 0.059, Valid Acc: 0.9845\n","Epoch: 16, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 16, Valid Loss: 0.053, Valid Acc: 0.9856\n","Epoch: 17, Train Loss: 0.039, Train Acc: 0.9879\n","Epoch: 17, Valid Loss: 0.053, Valid Acc: 0.9868\n","Epoch: 18, Train Loss: 0.038, Train Acc: 0.9881\n","Epoch: 18, Valid Loss: 0.050, Valid Acc: 0.9850\n","Epoch: 19, Train Loss: 0.037, Train Acc: 0.9880\n","Epoch: 19, Valid Loss: 0.056, Valid Acc: 0.9845\n","Epoch: 20, Train Loss: 0.037, Train Acc: 0.9881\n","Epoch: 20, Valid Loss: 0.050, Valid Acc: 0.9867\n","Epoch: 21, Train Loss: 0.036, Train Acc: 0.9886\n","Epoch: 21, Valid Loss: 0.055, Valid Acc: 0.9856\n","Epoch: 22, Train Loss: 0.037, Train Acc: 0.9884\n","Epoch: 22, Valid Loss: 0.049, Valid Acc: 0.9850\n","Epoch: 23, Train Loss: 0.037, Train Acc: 0.9880\n","Epoch: 23, Valid Loss: 0.048, Valid Acc: 0.9860\n","Epoch: 24, Train Loss: 0.036, Train Acc: 0.9882\n","Epoch: 24, Valid Loss: 0.044, Valid Acc: 0.9875\n","Epoch: 25, Train Loss: 0.036, Train Acc: 0.9885\n","Epoch: 25, Valid Loss: 0.056, Valid Acc: 0.9856\n","Epoch: 26, Train Loss: 0.036, Train Acc: 0.9884\n","Epoch: 26, Valid Loss: 0.049, Valid Acc: 0.9857\n","Epoch: 27, Train Loss: 0.035, Train Acc: 0.9887\n","Epoch: 27, Valid Loss: 0.055, Valid Acc: 0.9842\n","Epoch: 28, Train Loss: 0.035, Train Acc: 0.9887\n","Epoch: 28, Valid Loss: 0.056, Valid Acc: 0.9845\n","Epoch: 29, Train Loss: 0.036, Train Acc: 0.9888\n","Epoch: 29, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 30, Train Loss: 0.034, Train Acc: 0.9894\n","Epoch: 30, Valid Loss: 0.049, Valid Acc: 0.9861\n","| \u001b[0m 137     \u001b[0m | \u001b[0m 0.9875  \u001b[0m | \u001b[0m 1.207e+0\u001b[0m | \u001b[0m 2.637   \u001b[0m |\n","Epoch: 1, Train Loss: 0.222, Train Acc: 0.9313\n","Epoch: 1, Valid Loss: 0.089, Valid Acc: 0.9716\n","Epoch: 2, Train Loss: 0.078, Train Acc: 0.9757\n","Epoch: 2, Valid Loss: 0.057, Valid Acc: 0.9835\n","Epoch: 3, Train Loss: 0.063, Train Acc: 0.9804\n","Epoch: 3, Valid Loss: 0.054, Valid Acc: 0.9824\n","Epoch: 4, Train Loss: 0.055, Train Acc: 0.9830\n","Epoch: 4, Valid Loss: 0.051, Valid Acc: 0.9828\n","Epoch: 5, Train Loss: 0.048, Train Acc: 0.9847\n","Epoch: 5, Valid Loss: 0.048, Valid Acc: 0.9856\n","Epoch: 6, Train Loss: 0.042, Train Acc: 0.9864\n","Epoch: 6, Valid Loss: 0.045, Valid Acc: 0.9853\n","Epoch: 7, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 7, Valid Loss: 0.041, Valid Acc: 0.9874\n","Epoch: 8, Train Loss: 0.037, Train Acc: 0.9880\n","Epoch: 8, Valid Loss: 0.047, Valid Acc: 0.9868\n","Epoch: 9, Train Loss: 0.036, Train Acc: 0.9886\n","Epoch: 9, Valid Loss: 0.044, Valid Acc: 0.9876\n","Epoch: 10, Train Loss: 0.034, Train Acc: 0.9896\n","Epoch: 10, Valid Loss: 0.044, Valid Acc: 0.9873\n","Epoch: 11, Train Loss: 0.033, Train Acc: 0.9895\n","Epoch: 11, Valid Loss: 0.043, Valid Acc: 0.9861\n","Epoch: 12, Train Loss: 0.024, Train Acc: 0.9921\n","Epoch: 12, Valid Loss: 0.038, Valid Acc: 0.9883\n","Epoch: 13, Train Loss: 0.022, Train Acc: 0.9927\n","Epoch: 13, Valid Loss: 0.038, Valid Acc: 0.9887\n","Epoch: 14, Train Loss: 0.022, Train Acc: 0.9929\n","Epoch: 14, Valid Loss: 0.037, Valid Acc: 0.9884\n","Epoch: 15, Train Loss: 0.019, Train Acc: 0.9933\n","Epoch: 15, Valid Loss: 0.037, Valid Acc: 0.9899\n","Epoch: 16, Train Loss: 0.020, Train Acc: 0.9934\n","Epoch: 16, Valid Loss: 0.033, Valid Acc: 0.9892\n","Epoch: 17, Train Loss: 0.018, Train Acc: 0.9941\n","Epoch: 17, Valid Loss: 0.036, Valid Acc: 0.9900\n","Epoch: 18, Train Loss: 0.018, Train Acc: 0.9937\n","Epoch: 18, Valid Loss: 0.037, Valid Acc: 0.9898\n","Epoch: 19, Train Loss: 0.017, Train Acc: 0.9943\n","Epoch: 19, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 20, Train Loss: 0.016, Train Acc: 0.9948\n","Epoch: 20, Valid Loss: 0.037, Valid Acc: 0.9895\n","Epoch: 21, Train Loss: 0.018, Train Acc: 0.9939\n","Epoch: 21, Valid Loss: 0.035, Valid Acc: 0.9886\n","Epoch: 22, Train Loss: 0.017, Train Acc: 0.9944\n","Epoch: 22, Valid Loss: 0.034, Valid Acc: 0.9898\n","Epoch: 23, Train Loss: 0.017, Train Acc: 0.9945\n","Epoch: 23, Valid Loss: 0.032, Valid Acc: 0.9904\n","Epoch: 24, Train Loss: 0.017, Train Acc: 0.9944\n","Epoch: 24, Valid Loss: 0.032, Valid Acc: 0.9900\n","Epoch: 25, Train Loss: 0.016, Train Acc: 0.9944\n","Epoch: 25, Valid Loss: 0.035, Valid Acc: 0.9901\n","Epoch: 26, Train Loss: 0.016, Train Acc: 0.9949\n","Epoch: 26, Valid Loss: 0.034, Valid Acc: 0.9904\n","Epoch: 27, Train Loss: 0.015, Train Acc: 0.9950\n","Epoch: 27, Valid Loss: 0.030, Valid Acc: 0.9914\n","Epoch: 28, Train Loss: 0.015, Train Acc: 0.9950\n","Epoch: 28, Valid Loss: 0.036, Valid Acc: 0.9891\n","Epoch: 29, Train Loss: 0.015, Train Acc: 0.9951\n","Epoch: 29, Valid Loss: 0.034, Valid Acc: 0.9887\n","Epoch: 30, Train Loss: 0.015, Train Acc: 0.9948\n","Epoch: 30, Valid Loss: 0.032, Valid Acc: 0.9907\n","| \u001b[95m 138     \u001b[0m | \u001b[95m 0.9914  \u001b[0m | \u001b[95m 324.2   \u001b[0m | \u001b[95m 2.332   \u001b[0m |\n","Epoch: 1, Train Loss: 0.342, Train Acc: 0.8966\n","Epoch: 1, Valid Loss: 0.117, Valid Acc: 0.9668\n","Epoch: 2, Train Loss: 0.103, Train Acc: 0.9684\n","Epoch: 2, Valid Loss: 0.081, Valid Acc: 0.9768\n","Epoch: 3, Train Loss: 0.080, Train Acc: 0.9753\n","Epoch: 3, Valid Loss: 0.067, Valid Acc: 0.9806\n","Epoch: 4, Train Loss: 0.067, Train Acc: 0.9794\n","Epoch: 4, Valid Loss: 0.059, Valid Acc: 0.9838\n","Epoch: 5, Train Loss: 0.061, Train Acc: 0.9816\n","Epoch: 5, Valid Loss: 0.054, Valid Acc: 0.9829\n","Epoch: 6, Train Loss: 0.053, Train Acc: 0.9837\n","Epoch: 6, Valid Loss: 0.055, Valid Acc: 0.9819\n","Epoch: 7, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 7, Valid Loss: 0.049, Valid Acc: 0.9841\n","Epoch: 8, Train Loss: 0.048, Train Acc: 0.9851\n","Epoch: 8, Valid Loss: 0.045, Valid Acc: 0.9837\n","Epoch: 9, Train Loss: 0.043, Train Acc: 0.9864\n","Epoch: 9, Valid Loss: 0.045, Valid Acc: 0.9861\n","Epoch: 10, Train Loss: 0.042, Train Acc: 0.9869\n","Epoch: 10, Valid Loss: 0.045, Valid Acc: 0.9858\n","Epoch: 11, Train Loss: 0.038, Train Acc: 0.9878\n","Epoch: 11, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 12, Train Loss: 0.037, Train Acc: 0.9884\n","Epoch: 12, Valid Loss: 0.043, Valid Acc: 0.9856\n","Epoch: 13, Train Loss: 0.031, Train Acc: 0.9902\n","Epoch: 13, Valid Loss: 0.037, Valid Acc: 0.9879\n","Epoch: 14, Train Loss: 0.029, Train Acc: 0.9910\n","Epoch: 14, Valid Loss: 0.037, Valid Acc: 0.9886\n","Epoch: 15, Train Loss: 0.028, Train Acc: 0.9913\n","Epoch: 15, Valid Loss: 0.036, Valid Acc: 0.9873\n","Epoch: 16, Train Loss: 0.029, Train Acc: 0.9906\n","Epoch: 16, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 17, Train Loss: 0.027, Train Acc: 0.9914\n","Epoch: 17, Valid Loss: 0.037, Valid Acc: 0.9878\n","Epoch: 18, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 18, Valid Loss: 0.035, Valid Acc: 0.9889\n","Epoch: 19, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 19, Valid Loss: 0.035, Valid Acc: 0.9888\n","Epoch: 20, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 20, Valid Loss: 0.037, Valid Acc: 0.9878\n","Epoch: 21, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 21, Valid Loss: 0.035, Valid Acc: 0.9886\n","Epoch: 22, Train Loss: 0.026, Train Acc: 0.9918\n","Epoch: 22, Valid Loss: 0.038, Valid Acc: 0.9870\n","Epoch: 23, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 23, Valid Loss: 0.034, Valid Acc: 0.9891\n","Epoch: 24, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 24, Valid Loss: 0.035, Valid Acc: 0.9889\n","Epoch: 25, Train Loss: 0.025, Train Acc: 0.9924\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9892\n","Epoch: 26, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 26, Valid Loss: 0.036, Valid Acc: 0.9905\n","Epoch: 27, Train Loss: 0.025, Train Acc: 0.9921\n","Epoch: 27, Valid Loss: 0.035, Valid Acc: 0.9887\n","Epoch: 28, Train Loss: 0.025, Train Acc: 0.9919\n","Epoch: 28, Valid Loss: 0.035, Valid Acc: 0.9881\n","Epoch: 29, Train Loss: 0.024, Train Acc: 0.9925\n","Epoch: 29, Valid Loss: 0.036, Valid Acc: 0.9873\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9918\n","Epoch: 30, Valid Loss: 0.033, Valid Acc: 0.9890\n","| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9905  \u001b[0m | \u001b[0m 322.8   \u001b[0m | \u001b[0m 3.994   \u001b[0m |\n","Epoch: 1, Train Loss: 20.159, Train Acc: 0.1028\n","Epoch: 1, Valid Loss: 2.328, Valid Acc: 0.1028\n","Epoch: 2, Train Loss: 2.321, Train Acc: 0.1028\n","Epoch: 2, Valid Loss: 2.320, Valid Acc: 0.1009\n","Epoch: 3, Train Loss: 2.321, Train Acc: 0.1032\n","Epoch: 3, Valid Loss: 2.320, Valid Acc: 0.0974\n","| \u001b[0m 140     \u001b[0m | \u001b[0m 0.1028  \u001b[0m | \u001b[0m 324.7   \u001b[0m | \u001b[0m 0.3047  \u001b[0m |\n","Epoch: 1, Train Loss: 0.362, Train Acc: 0.8901\n","Epoch: 1, Valid Loss: 0.112, Valid Acc: 0.9669\n","Epoch: 2, Train Loss: 0.102, Train Acc: 0.9690\n","Epoch: 2, Valid Loss: 0.081, Valid Acc: 0.9749\n","Epoch: 3, Train Loss: 0.079, Train Acc: 0.9760\n","Epoch: 3, Valid Loss: 0.061, Valid Acc: 0.9806\n","Epoch: 4, Train Loss: 0.067, Train Acc: 0.9797\n","Epoch: 4, Valid Loss: 0.056, Valid Acc: 0.9816\n","Epoch: 5, Train Loss: 0.059, Train Acc: 0.9822\n","Epoch: 5, Valid Loss: 0.050, Valid Acc: 0.9847\n","Epoch: 6, Train Loss: 0.051, Train Acc: 0.9841\n","Epoch: 6, Valid Loss: 0.048, Valid Acc: 0.9840\n","Epoch: 7, Train Loss: 0.048, Train Acc: 0.9849\n","Epoch: 7, Valid Loss: 0.048, Valid Acc: 0.9846\n","Epoch: 8, Train Loss: 0.044, Train Acc: 0.9865\n","Epoch: 8, Valid Loss: 0.041, Valid Acc: 0.9859\n","Epoch: 9, Train Loss: 0.043, Train Acc: 0.9865\n","Epoch: 9, Valid Loss: 0.043, Valid Acc: 0.9861\n","Epoch: 10, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 10, Valid Loss: 0.044, Valid Acc: 0.9850\n","Epoch: 11, Train Loss: 0.038, Train Acc: 0.9875\n","Epoch: 11, Valid Loss: 0.047, Valid Acc: 0.9849\n","Epoch: 12, Train Loss: 0.033, Train Acc: 0.9895\n","Epoch: 12, Valid Loss: 0.038, Valid Acc: 0.9881\n","Epoch: 13, Train Loss: 0.031, Train Acc: 0.9904\n","Epoch: 13, Valid Loss: 0.038, Valid Acc: 0.9877\n","Epoch: 14, Train Loss: 0.029, Train Acc: 0.9908\n","Epoch: 14, Valid Loss: 0.036, Valid Acc: 0.9879\n","Epoch: 15, Train Loss: 0.030, Train Acc: 0.9905\n","Epoch: 15, Valid Loss: 0.037, Valid Acc: 0.9888\n","Epoch: 16, Train Loss: 0.028, Train Acc: 0.9908\n","Epoch: 16, Valid Loss: 0.038, Valid Acc: 0.9881\n","Epoch: 17, Train Loss: 0.029, Train Acc: 0.9910\n","Epoch: 17, Valid Loss: 0.039, Valid Acc: 0.9874\n","Epoch: 18, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 18, Valid Loss: 0.037, Valid Acc: 0.9880\n","Epoch: 19, Train Loss: 0.027, Train Acc: 0.9915\n","Epoch: 19, Valid Loss: 0.040, Valid Acc: 0.9871\n","Epoch: 20, Train Loss: 0.028, Train Acc: 0.9909\n","Epoch: 20, Valid Loss: 0.036, Valid Acc: 0.9879\n","Epoch: 21, Train Loss: 0.028, Train Acc: 0.9912\n","Epoch: 21, Valid Loss: 0.037, Valid Acc: 0.9873\n","Epoch: 22, Train Loss: 0.027, Train Acc: 0.9918\n","Epoch: 22, Valid Loss: 0.041, Valid Acc: 0.9863\n","Epoch: 23, Train Loss: 0.026, Train Acc: 0.9916\n","Epoch: 23, Valid Loss: 0.037, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 24, Valid Loss: 0.035, Valid Acc: 0.9880\n","Epoch: 25, Train Loss: 0.026, Train Acc: 0.9920\n","Epoch: 25, Valid Loss: 0.036, Valid Acc: 0.9888\n","Epoch: 26, Train Loss: 0.026, Train Acc: 0.9917\n","Epoch: 26, Valid Loss: 0.038, Valid Acc: 0.9884\n","Epoch: 27, Train Loss: 0.027, Train Acc: 0.9913\n","Epoch: 27, Valid Loss: 0.036, Valid Acc: 0.9880\n","Epoch: 28, Train Loss: 0.026, Train Acc: 0.9919\n","Epoch: 28, Valid Loss: 0.039, Valid Acc: 0.9877\n","Epoch: 29, Train Loss: 0.026, Train Acc: 0.9914\n","Epoch: 29, Valid Loss: 0.037, Valid Acc: 0.9881\n","Epoch: 30, Train Loss: 0.025, Train Acc: 0.9920\n","Epoch: 30, Valid Loss: 0.036, Valid Acc: 0.9891\n","| \u001b[0m 141     \u001b[0m | \u001b[0m 0.9891  \u001b[0m | \u001b[0m 325.5   \u001b[0m | \u001b[0m 3.908   \u001b[0m |\n","Epoch: 1, Train Loss: 5.137, Train Acc: 0.1203\n","Epoch: 1, Valid Loss: 2.723, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.344, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.722, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.344, Train Acc: 0.1113\n","Epoch: 3, Valid Loss: 2.721, Valid Acc: 0.1135\n","| \u001b[0m 142     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.972e+0\u001b[0m | \u001b[0m 1.618   \u001b[0m |\n","Epoch: 1, Train Loss: 0.654, Train Acc: 0.8064\n","Epoch: 1, Valid Loss: 0.240, Valid Acc: 0.9343\n","Epoch: 2, Train Loss: 0.195, Train Acc: 0.9410\n","Epoch: 2, Valid Loss: 0.149, Valid Acc: 0.9574\n","Epoch: 3, Train Loss: 0.140, Train Acc: 0.9579\n","Epoch: 3, Valid Loss: 0.114, Valid Acc: 0.9663\n","Epoch: 4, Train Loss: 0.114, Train Acc: 0.9652\n","Epoch: 4, Valid Loss: 0.095, Valid Acc: 0.9702\n","Epoch: 5, Train Loss: 0.099, Train Acc: 0.9698\n","Epoch: 5, Valid Loss: 0.082, Valid Acc: 0.9744\n","Epoch: 6, Train Loss: 0.087, Train Acc: 0.9738\n","Epoch: 6, Valid Loss: 0.078, Valid Acc: 0.9753\n","Epoch: 7, Train Loss: 0.081, Train Acc: 0.9748\n","Epoch: 7, Valid Loss: 0.070, Valid Acc: 0.9788\n","Epoch: 8, Train Loss: 0.075, Train Acc: 0.9771\n","Epoch: 8, Valid Loss: 0.070, Valid Acc: 0.9786\n","Epoch: 9, Train Loss: 0.070, Train Acc: 0.9791\n","Epoch: 9, Valid Loss: 0.060, Valid Acc: 0.9824\n","Epoch: 10, Train Loss: 0.064, Train Acc: 0.9807\n","Epoch: 10, Valid Loss: 0.059, Valid Acc: 0.9800\n","Epoch: 11, Train Loss: 0.060, Train Acc: 0.9818\n","Epoch: 11, Valid Loss: 0.058, Valid Acc: 0.9814\n","Epoch: 12, Train Loss: 0.058, Train Acc: 0.9824\n","Epoch: 12, Valid Loss: 0.056, Valid Acc: 0.9827\n","Epoch: 13, Train Loss: 0.057, Train Acc: 0.9825\n","Epoch: 13, Valid Loss: 0.055, Valid Acc: 0.9831\n","Epoch: 14, Train Loss: 0.052, Train Acc: 0.9840\n","Epoch: 14, Valid Loss: 0.051, Valid Acc: 0.9835\n","Epoch: 15, Train Loss: 0.052, Train Acc: 0.9838\n","Epoch: 15, Valid Loss: 0.050, Valid Acc: 0.9847\n","Epoch: 16, Train Loss: 0.050, Train Acc: 0.9846\n","Epoch: 16, Valid Loss: 0.046, Valid Acc: 0.9855\n","Epoch: 17, Train Loss: 0.049, Train Acc: 0.9850\n","Epoch: 17, Valid Loss: 0.044, Valid Acc: 0.9861\n","Epoch: 18, Train Loss: 0.047, Train Acc: 0.9851\n","Epoch: 18, Valid Loss: 0.049, Valid Acc: 0.9846\n","Epoch: 19, Train Loss: 0.042, Train Acc: 0.9870\n","Epoch: 19, Valid Loss: 0.046, Valid Acc: 0.9849\n","Epoch: 20, Train Loss: 0.042, Train Acc: 0.9870\n","Epoch: 20, Valid Loss: 0.044, Valid Acc: 0.9859\n","Epoch: 21, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 21, Valid Loss: 0.046, Valid Acc: 0.9843\n","Epoch: 22, Train Loss: 0.041, Train Acc: 0.9872\n","Epoch: 22, Valid Loss: 0.046, Valid Acc: 0.9859\n","Epoch: 23, Train Loss: 0.040, Train Acc: 0.9877\n","Epoch: 23, Valid Loss: 0.043, Valid Acc: 0.9864\n","Epoch: 24, Train Loss: 0.041, Train Acc: 0.9868\n","Epoch: 24, Valid Loss: 0.045, Valid Acc: 0.9856\n","Epoch: 25, Train Loss: 0.041, Train Acc: 0.9873\n","Epoch: 25, Valid Loss: 0.045, Valid Acc: 0.9846\n","Epoch: 26, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 26, Valid Loss: 0.043, Valid Acc: 0.9861\n","Epoch: 27, Train Loss: 0.041, Train Acc: 0.9878\n","Epoch: 27, Valid Loss: 0.045, Valid Acc: 0.9850\n","Epoch: 28, Train Loss: 0.040, Train Acc: 0.9872\n","Epoch: 28, Valid Loss: 0.046, Valid Acc: 0.9850\n","Epoch: 29, Train Loss: 0.041, Train Acc: 0.9878\n","Epoch: 29, Valid Loss: 0.044, Valid Acc: 0.9848\n","Epoch: 30, Train Loss: 0.040, Train Acc: 0.9878\n","Epoch: 30, Valid Loss: 0.045, Valid Acc: 0.9853\n","| \u001b[0m 143     \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 320.8   \u001b[0m | \u001b[0m 3.281   \u001b[0m |\n","Epoch: 1, Train Loss: 2.394, Train Acc: 0.0820\n","Epoch: 1, Valid Loss: 2.416, Valid Acc: 0.0820\n","Epoch: 2, Train Loss: 2.394, Train Acc: 0.0802\n","Epoch: 2, Valid Loss: 2.419, Valid Acc: 0.0788\n","Epoch: 3, Train Loss: 2.394, Train Acc: 0.0815\n","Epoch: 3, Valid Loss: 2.421, Valid Acc: 0.0801\n","| \u001b[0m 144     \u001b[0m | \u001b[0m 0.082   \u001b[0m | \u001b[0m 317.2   \u001b[0m | \u001b[0m 4.0     \u001b[0m |\n","Epoch: 1, Train Loss: 4.427, Train Acc: 0.1256\n","Epoch: 1, Valid Loss: 2.718, Valid Acc: 0.1135\n","Epoch: 2, Train Loss: 2.341, Train Acc: 0.1124\n","Epoch: 2, Valid Loss: 2.716, Valid Acc: 0.1135\n","Epoch: 3, Train Loss: 2.340, Train Acc: 0.1124\n","Epoch: 3, Valid Loss: 2.716, Valid Acc: 0.1135\n","| \u001b[0m 145     \u001b[0m | \u001b[0m 0.1135  \u001b[0m | \u001b[0m 1.968e+0\u001b[0m | \u001b[0m 1.54    \u001b[0m |\n","Epoch: 1, Train Loss: 1.508, Train Acc: 0.5634\n","Epoch: 1, Valid Loss: 0.804, Valid Acc: 0.8046\n","Epoch: 2, Train Loss: 0.481, Train Acc: 0.8536\n","Epoch: 2, Valid Loss: 0.410, Valid Acc: 0.8985\n","Epoch: 3, Train Loss: 0.298, Train Acc: 0.9126\n","Epoch: 3, Valid Loss: 0.301, Valid Acc: 0.9334\n","Epoch: 4, Train Loss: 0.226, Train Acc: 0.9342\n","Epoch: 4, Valid Loss: 0.235, Valid Acc: 0.9478\n","Epoch: 5, Train Loss: 0.184, Train Acc: 0.9457\n","Epoch: 5, Valid Loss: 0.189, Valid Acc: 0.9571\n","Epoch: 6, Train Loss: 0.158, Train Acc: 0.9539\n","Epoch: 6, Valid Loss: 0.161, Valid Acc: 0.9611\n","Epoch: 7, Train Loss: 0.138, Train Acc: 0.9603\n","Epoch: 7, Valid Loss: 0.157, Valid Acc: 0.9645\n","Epoch: 8, Train Loss: 0.125, Train Acc: 0.9635\n","Epoch: 8, Valid Loss: 0.135, Valid Acc: 0.9657\n","Epoch: 9, Train Loss: 0.117, Train Acc: 0.9653\n","Epoch: 9, Valid Loss: 0.123, Valid Acc: 0.9685\n","Epoch: 10, Train Loss: 0.107, Train Acc: 0.9685\n","Epoch: 10, Valid Loss: 0.114, Valid Acc: 0.9697\n","Epoch: 11, Train Loss: 0.102, Train Acc: 0.9702\n","Epoch: 11, Valid Loss: 0.106, Valid Acc: 0.9741\n","Epoch: 12, Train Loss: 0.094, Train Acc: 0.9723\n","Epoch: 12, Valid Loss: 0.107, Valid Acc: 0.9743\n","Epoch: 13, Train Loss: 0.089, Train Acc: 0.9732\n","Epoch: 13, Valid Loss: 0.093, Valid Acc: 0.9754\n","Epoch: 14, Train Loss: 0.086, Train Acc: 0.9747\n","Epoch: 14, Valid Loss: 0.092, Valid Acc: 0.9768\n","Epoch: 15, Train Loss: 0.082, Train Acc: 0.9759\n","Epoch: 15, Valid Loss: 0.090, Valid Acc: 0.9769\n","Epoch: 16, Train Loss: 0.078, Train Acc: 0.9764\n","Epoch: 16, Valid Loss: 0.079, Valid Acc: 0.9782\n","Epoch: 17, Train Loss: 0.076, Train Acc: 0.9779\n","Epoch: 17, Valid Loss: 0.088, Valid Acc: 0.9787\n","Epoch: 18, Train Loss: 0.074, Train Acc: 0.9778\n","Epoch: 18, Valid Loss: 0.077, Valid Acc: 0.9784\n","Epoch: 19, Train Loss: 0.072, Train Acc: 0.9784\n","Epoch: 19, Valid Loss: 0.084, Valid Acc: 0.9801\n","Epoch: 20, Train Loss: 0.067, Train Acc: 0.9800\n","Epoch: 20, Valid Loss: 0.074, Valid Acc: 0.9798\n","Epoch: 21, Train Loss: 0.068, Train Acc: 0.9798\n","Epoch: 21, Valid Loss: 0.071, Valid Acc: 0.9827\n","Epoch: 22, Train Loss: 0.064, Train Acc: 0.9809\n","Epoch: 22, Valid Loss: 0.065, Valid Acc: 0.9812\n","Epoch: 23, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 23, Valid Loss: 0.064, Valid Acc: 0.9835\n","Epoch: 24, Train Loss: 0.061, Train Acc: 0.9818\n","Epoch: 24, Valid Loss: 0.063, Valid Acc: 0.9828\n","Epoch: 25, Train Loss: 0.059, Train Acc: 0.9829\n","Epoch: 25, Valid Loss: 0.065, Valid Acc: 0.9816\n","Epoch: 26, Train Loss: 0.060, Train Acc: 0.9817\n","Epoch: 26, Valid Loss: 0.064, Valid Acc: 0.9829\n","Epoch: 27, Train Loss: 0.058, Train Acc: 0.9825\n","Epoch: 27, Valid Loss: 0.063, Valid Acc: 0.9832\n","Epoch: 28, Train Loss: 0.059, Train Acc: 0.9823\n","Epoch: 28, Valid Loss: 0.067, Valid Acc: 0.9821\n","Epoch: 29, Train Loss: 0.060, Train Acc: 0.9821\n","Epoch: 29, Valid Loss: 0.067, Valid Acc: 0.9819\n","Epoch: 30, Train Loss: 0.059, Train Acc: 0.9825\n","Epoch: 30, Valid Loss: 0.065, Valid Acc: 0.9823\n","| \u001b[0m 146     \u001b[0m | \u001b[0m 0.9835  \u001b[0m | \u001b[0m 1.97e+03\u001b[0m | \u001b[0m 3.433   \u001b[0m |\n","Epoch: 1, Train Loss: 0.637, Train Acc: 0.8016\n","Epoch: 1, Valid Loss: 0.218, Valid Acc: 0.9402\n","Epoch: 2, Train Loss: 0.169, Train Acc: 0.9489\n","Epoch: 2, Valid Loss: 0.158, Valid Acc: 0.9583\n","Epoch: 3, Train Loss: 0.131, Train Acc: 0.9606\n","Epoch: 3, Valid Loss: 0.122, Valid Acc: 0.9655\n","Epoch: 4, Train Loss: 0.116, Train Acc: 0.9651\n","Epoch: 4, Valid Loss: 0.120, Valid Acc: 0.9654\n","Epoch: 5, Train Loss: 0.100, Train Acc: 0.9684\n","Epoch: 5, Valid Loss: 0.103, Valid Acc: 0.9693\n","Epoch: 6, Train Loss: 0.095, Train Acc: 0.9706\n","Epoch: 6, Valid Loss: 0.102, Valid Acc: 0.9710\n","Epoch: 7, Train Loss: 0.089, Train Acc: 0.9723\n","Epoch: 7, Valid Loss: 0.100, Valid Acc: 0.9745\n","Epoch: 8, Train Loss: 0.083, Train Acc: 0.9742\n","Epoch: 8, Valid Loss: 0.090, Valid Acc: 0.9755\n","Epoch: 9, Train Loss: 0.078, Train Acc: 0.9761\n","Epoch: 9, Valid Loss: 0.077, Valid Acc: 0.9781\n","Epoch: 10, Train Loss: 0.078, Train Acc: 0.9764\n","Epoch: 10, Valid Loss: 0.084, Valid Acc: 0.9753\n","Epoch: 11, Train Loss: 0.077, Train Acc: 0.9760\n","Epoch: 11, Valid Loss: 0.087, Valid Acc: 0.9763\n","Epoch: 12, Train Loss: 0.074, Train Acc: 0.9775\n","Epoch: 12, Valid Loss: 0.080, Valid Acc: 0.9778\n","Epoch: 13, Train Loss: 0.071, Train Acc: 0.9780\n","Epoch: 13, Valid Loss: 0.076, Valid Acc: 0.9794\n","Epoch: 14, Train Loss: 0.069, Train Acc: 0.9781\n","Epoch: 14, Valid Loss: 0.080, Valid Acc: 0.9788\n","Epoch: 15, Train Loss: 0.071, Train Acc: 0.9782\n","Epoch: 15, Valid Loss: 0.078, Valid Acc: 0.9787\n","Epoch: 16, Train Loss: 0.061, Train Acc: 0.9805\n","Epoch: 16, Valid Loss: 0.071, Valid Acc: 0.9791\n","Epoch: 17, Train Loss: 0.060, Train Acc: 0.9810\n","Epoch: 17, Valid Loss: 0.065, Valid Acc: 0.9801\n","Epoch: 18, Train Loss: 0.058, Train Acc: 0.9822\n","Epoch: 18, Valid Loss: 0.070, Valid Acc: 0.9802\n","Epoch: 19, Train Loss: 0.055, Train Acc: 0.9829\n","Epoch: 19, Valid Loss: 0.069, Valid Acc: 0.9807\n","Epoch: 20, Train Loss: 0.056, Train Acc: 0.9827\n","Epoch: 20, Valid Loss: 0.062, Valid Acc: 0.9830\n","Epoch: 21, Train Loss: 0.057, Train Acc: 0.9818\n","Epoch: 21, Valid Loss: 0.062, Valid Acc: 0.9820\n","Epoch: 22, Train Loss: 0.055, Train Acc: 0.9833\n","Epoch: 22, Valid Loss: 0.065, Valid Acc: 0.9810\n","Epoch: 23, Train Loss: 0.053, Train Acc: 0.9836\n","Epoch: 23, Valid Loss: 0.068, Valid Acc: 0.9811\n","Epoch: 24, Train Loss: 0.053, Train Acc: 0.9839\n","Epoch: 24, Valid Loss: 0.058, Valid Acc: 0.9846\n","Epoch: 25, Train Loss: 0.054, Train Acc: 0.9835\n","Epoch: 25, Valid Loss: 0.065, Valid Acc: 0.9821\n","Epoch: 26, Train Loss: 0.054, Train Acc: 0.9834\n","Epoch: 26, Valid Loss: 0.064, Valid Acc: 0.9822\n","Epoch: 27, Train Loss: 0.053, Train Acc: 0.9828\n","Epoch: 27, Valid Loss: 0.058, Valid Acc: 0.9845\n","Epoch: 28, Train Loss: 0.054, Train Acc: 0.9833\n","Epoch: 28, Valid Loss: 0.060, Valid Acc: 0.9832\n","Epoch: 29, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 29, Valid Loss: 0.065, Valid Acc: 0.9815\n","Epoch: 30, Train Loss: 0.054, Train Acc: 0.9831\n","Epoch: 30, Valid Loss: 0.066, Valid Acc: 0.9818\n","| \u001b[0m 147     \u001b[0m | \u001b[0m 0.9846  \u001b[0m | \u001b[0m 1.22e+03\u001b[0m | \u001b[0m 2.611   \u001b[0m |\n","Epoch: 1, Train Loss: 0.243, Train Acc: 0.9245\n","Epoch: 1, Valid Loss: 0.091, Valid Acc: 0.9714\n","Epoch: 2, Train Loss: 0.086, Train Acc: 0.9725\n","Epoch: 2, Valid Loss: 0.070, Valid Acc: 0.9797\n","Epoch: 3, Train Loss: 0.072, Train Acc: 0.9772\n","Epoch: 3, Valid Loss: 0.061, Valid Acc: 0.9808\n","Epoch: 4, Train Loss: 0.063, Train Acc: 0.9808\n","Epoch: 4, Valid Loss: 0.064, Valid Acc: 0.9775\n","Epoch: 5, Train Loss: 0.056, Train Acc: 0.9822\n","Epoch: 5, Valid Loss: 0.057, Valid Acc: 0.9842\n","Epoch: 6, Train Loss: 0.052, Train Acc: 0.9829\n","Epoch: 6, Valid Loss: 0.062, Valid Acc: 0.9825\n","Epoch: 7, Train Loss: 0.049, Train Acc: 0.9847\n","Epoch: 7, Valid Loss: 0.050, Valid Acc: 0.9840\n","Epoch: 8, Train Loss: 0.045, Train Acc: 0.9853\n","Epoch: 8, Valid Loss: 0.048, Valid Acc: 0.9838\n","Epoch: 9, Train Loss: 0.045, Train Acc: 0.9850\n","Epoch: 9, Valid Loss: 0.049, Valid Acc: 0.9848\n","Epoch: 10, Train Loss: 0.044, Train Acc: 0.9866\n","Epoch: 10, Valid Loss: 0.051, Valid Acc: 0.9847\n","Epoch: 11, Train Loss: 0.041, Train Acc: 0.9877\n","Epoch: 11, Valid Loss: 0.047, Valid Acc: 0.9836\n","Epoch: 12, Train Loss: 0.031, Train Acc: 0.9899\n","Epoch: 12, Valid Loss: 0.043, Valid Acc: 0.9867\n","Epoch: 13, Train Loss: 0.028, Train Acc: 0.9910\n","Epoch: 13, Valid Loss: 0.041, Valid Acc: 0.9876\n","Epoch: 14, Train Loss: 0.026, Train Acc: 0.9915\n","Epoch: 14, Valid Loss: 0.040, Valid Acc: 0.9864\n","Epoch: 15, Train Loss: 0.027, Train Acc: 0.9909\n","Epoch: 15, Valid Loss: 0.036, Valid Acc: 0.9891\n","Epoch: 16, Train Loss: 0.025, Train Acc: 0.9923\n","Epoch: 16, Valid Loss: 0.036, Valid Acc: 0.9882\n","Epoch: 17, Train Loss: 0.024, Train Acc: 0.9922\n","Epoch: 17, Valid Loss: 0.040, Valid Acc: 0.9883\n","Epoch: 18, Train Loss: 0.022, Train Acc: 0.9928\n","Epoch: 18, Valid Loss: 0.040, Valid Acc: 0.9884\n","Epoch: 19, Train Loss: 0.023, Train Acc: 0.9928\n","Epoch: 19, Valid Loss: 0.038, Valid Acc: 0.9888\n","Epoch: 20, Train Loss: 0.022, Train Acc: 0.9931\n","Epoch: 20, Valid Loss: 0.039, Valid Acc: 0.9876\n","Epoch: 21, Train Loss: 0.022, Train Acc: 0.9929\n","Epoch: 21, Valid Loss: 0.039, Valid Acc: 0.9886\n","Epoch: 22, Train Loss: 0.021, Train Acc: 0.9929\n","Epoch: 22, Valid Loss: 0.039, Valid Acc: 0.9875\n","Epoch: 23, Train Loss: 0.022, Train Acc: 0.9927\n","Epoch: 23, Valid Loss: 0.039, Valid Acc: 0.9883\n","Epoch: 24, Train Loss: 0.019, Train Acc: 0.9939\n","Epoch: 24, Valid Loss: 0.039, Valid Acc: 0.9876\n","Epoch: 25, Train Loss: 0.020, Train Acc: 0.9937\n","Epoch: 25, Valid Loss: 0.037, Valid Acc: 0.9878\n","Epoch: 26, Train Loss: 0.021, Train Acc: 0.9931\n","Epoch: 26, Valid Loss: 0.044, Valid Acc: 0.9880\n","Epoch: 27, Train Loss: 0.020, Train Acc: 0.9933\n","Epoch: 27, Valid Loss: 0.040, Valid Acc: 0.9884\n","Epoch: 28, Train Loss: 0.019, Train Acc: 0.9937\n","Epoch: 28, Valid Loss: 0.040, Valid Acc: 0.9881\n","Epoch: 29, Train Loss: 0.019, Train Acc: 0.9933\n","Epoch: 29, Valid Loss: 0.036, Valid Acc: 0.9888\n","Epoch: 30, Train Loss: 0.018, Train Acc: 0.9938\n","Epoch: 30, Valid Loss: 0.035, Valid Acc: 0.9887\n","| \u001b[0m 148     \u001b[0m | \u001b[0m 0.9891  \u001b[0m | \u001b[0m 322.4   \u001b[0m | \u001b[0m 2.508   \u001b[0m |\n","Epoch: 1, Train Loss: 0.554, Train Acc: 0.8306\n","Epoch: 1, Valid Loss: 0.157, Valid Acc: 0.9590\n","Epoch: 2, Train Loss: 0.125, Train Acc: 0.9621\n","Epoch: 2, Valid Loss: 0.115, Valid Acc: 0.9701\n","Epoch: 3, Train Loss: 0.099, Train Acc: 0.9696\n","Epoch: 3, Valid Loss: 0.093, Valid Acc: 0.9749\n","Epoch: 4, Train Loss: 0.085, Train Acc: 0.9739\n","Epoch: 4, Valid Loss: 0.078, Valid Acc: 0.9774\n","Epoch: 5, Train Loss: 0.076, Train Acc: 0.9769\n","Epoch: 5, Valid Loss: 0.081, Valid Acc: 0.9780\n","Epoch: 6, Train Loss: 0.069, Train Acc: 0.9778\n","Epoch: 6, Valid Loss: 0.070, Valid Acc: 0.9787\n","Epoch: 7, Train Loss: 0.065, Train Acc: 0.9790\n","Epoch: 7, Valid Loss: 0.068, Valid Acc: 0.9812\n","Epoch: 8, Train Loss: 0.062, Train Acc: 0.9809\n","Epoch: 8, Valid Loss: 0.065, Valid Acc: 0.9818\n","Epoch: 9, Train Loss: 0.059, Train Acc: 0.9813\n","Epoch: 9, Valid Loss: 0.063, Valid Acc: 0.9825\n","Epoch: 10, Train Loss: 0.057, Train Acc: 0.9818\n","Epoch: 10, Valid Loss: 0.065, Valid Acc: 0.9816\n","Epoch: 11, Train Loss: 0.055, Train Acc: 0.9828\n","Epoch: 11, Valid Loss: 0.064, Valid Acc: 0.9826\n","Epoch: 12, Train Loss: 0.053, Train Acc: 0.9834\n","Epoch: 12, Valid Loss: 0.061, Valid Acc: 0.9821\n","Epoch: 13, Train Loss: 0.044, Train Acc: 0.9859\n","Epoch: 13, Valid Loss: 0.053, Valid Acc: 0.9836\n","Epoch: 14, Train Loss: 0.041, Train Acc: 0.9865\n","Epoch: 14, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 15, Train Loss: 0.043, Train Acc: 0.9864\n","Epoch: 15, Valid Loss: 0.052, Valid Acc: 0.9855\n","Epoch: 16, Train Loss: 0.040, Train Acc: 0.9871\n","Epoch: 16, Valid Loss: 0.049, Valid Acc: 0.9847\n","Epoch: 17, Train Loss: 0.040, Train Acc: 0.9871\n","Epoch: 17, Valid Loss: 0.053, Valid Acc: 0.9840\n","Epoch: 18, Train Loss: 0.040, Train Acc: 0.9871\n","Epoch: 18, Valid Loss: 0.050, Valid Acc: 0.9852\n","Epoch: 19, Train Loss: 0.038, Train Acc: 0.9879\n","Epoch: 19, Valid Loss: 0.051, Valid Acc: 0.9855\n","Epoch: 20, Train Loss: 0.038, Train Acc: 0.9881\n","Epoch: 20, Valid Loss: 0.053, Valid Acc: 0.9843\n","Epoch: 21, Train Loss: 0.037, Train Acc: 0.9881\n","Epoch: 21, Valid Loss: 0.056, Valid Acc: 0.9854\n","Epoch: 22, Train Loss: 0.036, Train Acc: 0.9887\n","Epoch: 22, Valid Loss: 0.048, Valid Acc: 0.9850\n","Epoch: 23, Train Loss: 0.038, Train Acc: 0.9878\n","Epoch: 23, Valid Loss: 0.053, Valid Acc: 0.9842\n","Epoch: 24, Train Loss: 0.036, Train Acc: 0.9884\n","Epoch: 24, Valid Loss: 0.051, Valid Acc: 0.9865\n","Epoch: 25, Train Loss: 0.037, Train Acc: 0.9880\n","Epoch: 25, Valid Loss: 0.050, Valid Acc: 0.9866\n","Epoch: 26, Train Loss: 0.035, Train Acc: 0.9889\n","Epoch: 26, Valid Loss: 0.047, Valid Acc: 0.9863\n","Epoch: 27, Train Loss: 0.035, Train Acc: 0.9882\n","Epoch: 27, Valid Loss: 0.048, Valid Acc: 0.9857\n","Epoch: 28, Train Loss: 0.034, Train Acc: 0.9888\n","Epoch: 28, Valid Loss: 0.047, Valid Acc: 0.9860\n","Epoch: 29, Train Loss: 0.036, Train Acc: 0.9883\n","Epoch: 29, Valid Loss: 0.054, Valid Acc: 0.9855\n","Epoch: 30, Train Loss: 0.036, Train Acc: 0.9883\n","Epoch: 30, Valid Loss: 0.049, Valid Acc: 0.9860\n","| \u001b[0m 149     \u001b[0m | \u001b[0m 0.9866  \u001b[0m | \u001b[0m 1.229e+0\u001b[0m | \u001b[0m 2.665   \u001b[0m |\n","Epoch: 1, Train Loss: 1.050, Train Acc: 0.7014\n","Epoch: 1, Valid Loss: 0.465, Valid Acc: 0.8909\n","Epoch: 2, Train Loss: 0.284, Train Acc: 0.9152\n","Epoch: 2, Valid Loss: 0.251, Valid Acc: 0.9423\n","Epoch: 3, Train Loss: 0.182, Train Acc: 0.9470\n","Epoch: 3, Valid Loss: 0.178, Valid Acc: 0.9588\n","Epoch: 4, Train Loss: 0.140, Train Acc: 0.9592\n","Epoch: 4, Valid Loss: 0.152, Valid Acc: 0.9651\n","Epoch: 5, Train Loss: 0.119, Train Acc: 0.9649\n","Epoch: 5, Valid Loss: 0.124, Valid Acc: 0.9712\n","Epoch: 6, Train Loss: 0.104, Train Acc: 0.9685\n","Epoch: 6, Valid Loss: 0.110, Valid Acc: 0.9752\n","Epoch: 7, Train Loss: 0.095, Train Acc: 0.9727\n","Epoch: 7, Valid Loss: 0.100, Valid Acc: 0.9776\n","Epoch: 8, Train Loss: 0.085, Train Acc: 0.9747\n","Epoch: 8, Valid Loss: 0.089, Valid Acc: 0.9774\n","Epoch: 9, Train Loss: 0.079, Train Acc: 0.9761\n","Epoch: 9, Valid Loss: 0.086, Valid Acc: 0.9785\n","Epoch: 10, Train Loss: 0.072, Train Acc: 0.9784\n","Epoch: 10, Valid Loss: 0.078, Valid Acc: 0.9795\n","Epoch: 11, Train Loss: 0.069, Train Acc: 0.9795\n","Epoch: 11, Valid Loss: 0.069, Valid Acc: 0.9815\n","Epoch: 12, Train Loss: 0.064, Train Acc: 0.9806\n","Epoch: 12, Valid Loss: 0.069, Valid Acc: 0.9815\n","Epoch: 13, Train Loss: 0.061, Train Acc: 0.9817\n","Epoch: 13, Valid Loss: 0.068, Valid Acc: 0.9819\n","Epoch: 14, Train Loss: 0.057, Train Acc: 0.9830\n","Epoch: 14, Valid Loss: 0.061, Valid Acc: 0.9838\n","Epoch: 15, Train Loss: 0.056, Train Acc: 0.9834\n","Epoch: 15, Valid Loss: 0.056, Valid Acc: 0.9835\n","Epoch: 16, Train Loss: 0.054, Train Acc: 0.9838\n","Epoch: 16, Valid Loss: 0.061, Valid Acc: 0.9830\n","Epoch: 17, Train Loss: 0.052, Train Acc: 0.9841\n","Epoch: 17, Valid Loss: 0.061, Valid Acc: 0.9842\n","Epoch: 18, Train Loss: 0.050, Train Acc: 0.9849\n","Epoch: 18, Valid Loss: 0.055, Valid Acc: 0.9846\n","Epoch: 19, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 19, Valid Loss: 0.061, Valid Acc: 0.9825\n","Epoch: 20, Train Loss: 0.051, Train Acc: 0.9849\n","Epoch: 20, Valid Loss: 0.055, Valid Acc: 0.9858\n","Epoch: 21, Train Loss: 0.049, Train Acc: 0.9849\n","Epoch: 21, Valid Loss: 0.059, Valid Acc: 0.9843\n","Epoch: 22, Train Loss: 0.049, Train Acc: 0.9855\n","Epoch: 22, Valid Loss: 0.052, Valid Acc: 0.9845\n","Epoch: 23, Train Loss: 0.050, Train Acc: 0.9851\n","Epoch: 23, Valid Loss: 0.057, Valid Acc: 0.9832\n","Epoch: 24, Train Loss: 0.049, Train Acc: 0.9855\n","Epoch: 24, Valid Loss: 0.057, Valid Acc: 0.9844\n","Epoch: 25, Train Loss: 0.049, Train Acc: 0.9852\n","Epoch: 25, Valid Loss: 0.056, Valid Acc: 0.9849\n","Epoch: 26, Train Loss: 0.051, Train Acc: 0.9845\n","Epoch: 26, Valid Loss: 0.057, Valid Acc: 0.9842\n","Epoch: 27, Train Loss: 0.049, Train Acc: 0.9853\n","Epoch: 27, Valid Loss: 0.058, Valid Acc: 0.9851\n","Epoch: 28, Train Loss: 0.049, Train Acc: 0.9853\n","Epoch: 28, Valid Loss: 0.054, Valid Acc: 0.9846\n","Epoch: 29, Train Loss: 0.049, Train Acc: 0.9854\n","Epoch: 29, Valid Loss: 0.056, Valid Acc: 0.9849\n","Epoch: 30, Train Loss: 0.047, Train Acc: 0.9858\n","Epoch: 30, Valid Loss: 0.052, Valid Acc: 0.9861\n","| \u001b[0m 150     \u001b[0m | \u001b[0m 0.9861  \u001b[0m | \u001b[0m 1.966e+0\u001b[0m | \u001b[0m 3.823   \u001b[0m |\n","=================================================\n","{'target': 0.9914, 'params': {'batch_size': 324.22303115042257, 'lr': 2.3315897981189844}}\n"]}]},{"cell_type":"code","metadata":{"id":"Xuh4Qx6-QDyc","executionInfo":{"status":"error","timestamp":1639959394497,"user_tz":0,"elapsed":3744,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}},"colab":{"base_uri":"https://localhost:8080/","height":172},"outputId":"2a455678-1c0a-4bff-ee4f-91a812d38c8d"},"source":["hjh"],"id":"Xuh4Qx6-QDyc","execution_count":28,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-d7598be63144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhjh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'hjh' is not defined"]}]},{"cell_type":"code","metadata":{"id":"0d7d4041","executionInfo":{"status":"aborted","timestamp":1639959394511,"user_tz":0,"elapsed":14,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Function to evaluate the model on the test set\n","def evaluate_model(test_dl, model):\n","    predictions, actuals = list(), list()\n","    for i, (inputs, targets) in enumerate(test_dl):\n","        # evaluate the model on the test set\n","        yhat = model(inputs)\n","        # retrieve numpy array\n","        yhat = yhat.detach().numpy()\n","        actual = targets.numpy()\n","        actual = actual.reshape((len(actual), 1))\n","        # round to class values\n","        yhat = yhat.round()\n","        # store\n","        predictions.append(yhat)\n","        actuals.append(actual)\n","    predictions, actuals = vstack(predictions), vstack(actuals)\n","    # calculate accuracy\n","    acc = accuracy_score(actuals, predictions)\n","    return acc"],"id":"0d7d4041","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11a2b616","executionInfo":{"status":"aborted","timestamp":1639959394514,"user_tz":0,"elapsed":17,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["dfdfd"],"id":"11a2b616","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7629056b","executionInfo":{"status":"aborted","timestamp":1639959394517,"user_tz":0,"elapsed":20,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["# Determine model accuracy on the test set\n","test_dl = DataLoader(data['test'], batch_size=params['batch_size'], shuffle=False, num_workers=1)\n","test_acc = evaluate_model(test_dl, model)"],"id":"7629056b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eykpD04sRFEN","executionInfo":{"status":"aborted","timestamp":1639959394520,"user_tz":0,"elapsed":23,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["\n","kjkjk\n","\n","function ClickConnect(){\n","console.log(\"Working\"); \n"," var selector = \"#cell-11a2b616\"\n","document.querySelector(selector).click();\n","  document.querySelector(selector).value = 123;\n","}\n","setInterval(ClickConnect,60000)"],"id":"eykpD04sRFEN","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aopktYv1RGsh","executionInfo":{"status":"aborted","timestamp":1639959394522,"user_tz":0,"elapsed":25,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":[""],"id":"aopktYv1RGsh","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ5-ClnQOFx1","executionInfo":{"status":"aborted","timestamp":1639959394526,"user_tz":0,"elapsed":29,"user":{"displayName":"Raji Ismail","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguYZGvVQsYXabtTaZauJJ2dZO7a31lh0UTA6vW=s64","userId":"17728131508966288199"}}},"source":["dfdf\n","\n","function ClickConnect(){\n","console.log(\"Working\"); \n","document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n","}\n","var clicker = setInterval(ClickConnect,60000);\n","\n","clearInterval(clicker);"],"id":"TQ5-ClnQOFx1","execution_count":null,"outputs":[]}]}